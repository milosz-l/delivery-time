{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "# fact table\n",
    "sessions_df = pd.read_json(\"data/sessions.jsonl\", lines=True)\n",
    "\n",
    "# dimension tables\n",
    "deliveries_df = pd.read_json(\"data/deliveries.jsonl\", lines=True)\n",
    "products_df = pd.read_json(\"data/products.jsonl\", lines=True)\n",
    "users_df = pd.read_json(\"data/users.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_PLOTS = True\n",
    "MAKE_PAIRPLOT = True\n",
    "DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S\"\n",
    "PRICE_TRESHOLD = 100_000    # for outliers\n",
    "WEIGHT_TRESHOLD = 50        # for outliers\n",
    "NUM_OF_HOURS = 12\n",
    "SEED = 42\n",
    "SHOW_ALL_WARNINGS = False\n",
    "SHOW_ONLY_ONE_WARNING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "if SHOW_ONLY_ONE_WARNING:\n",
    "    warnings.filterwarnings(action='once')\n",
    "elif not SHOW_ALL_WARNINGS:\n",
    "    warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "deliveries_df[\"delivery_timestamp\"] = deliveries_df[\"delivery_timestamp\"].str.split('.', expand=True)[0]\n",
    "\n",
    "# 2.\n",
    "deliveries_df[\"purchase_timestamp\"] = pd.to_datetime(deliveries_df[\"purchase_timestamp\"], format=DATE_FORMAT)\n",
    "deliveries_df[\"delivery_timestamp\"] = pd.to_datetime(deliveries_df[\"delivery_timestamp\"], format=DATE_FORMAT)\n",
    "\n",
    "# 3.\n",
    "deliveries_df[\"time_diff\"] = deliveries_df[\"delivery_timestamp\"] - deliveries_df[\"purchase_timestamp\"]\n",
    "\n",
    "# 4.\n",
    "deliveries_df = deliveries_df[deliveries_df[\"time_diff\"].notna()]\n",
    "\n",
    "# 5.\n",
    "# time diff as duration in seconds\n",
    "deliveries_df[\"time_diff\"] = deliveries_df[\"time_diff\"].apply(datetime.timedelta.total_seconds)\n",
    "\n",
    "# 6.\n",
    "# deliveries_df = deliveries_df[deliveries_df[\"time_diff\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where event_type is not equal \"BUY_PRODUCT\"\n",
    "sessions_df = sessions_df[sessions_df[\"event_type\"] == \"BUY_PRODUCT\"]\n",
    "df = deliveries_df.merge(sessions_df, on=\"purchase_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure, that timestamp == purchase_timestamp\n",
    "num_of_rows_before = df.shape[0]\n",
    "df = df[df[\"timestamp\"] == df[\"purchase_timestamp\"]]\n",
    "num_of_rows_after = df.shape[0]\n",
    "\n",
    "assert(num_of_rows_before == num_of_rows_after)\n",
    "\n",
    "# now we can drop timestamp column, as it is redundant\n",
    "df = df.drop(columns=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(users_df, on=\"user_id\", how=\"left\")\n",
    "df = df.merge(products_df, on=\"product_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejecting outliers for given PRICE_TRESHOLD\n",
    "df = df[df[\"price\"] <= PRICE_TRESHOLD]\n",
    "\n",
    "# rejecting outliers for given WEIGHT_TRESHOLD\n",
    "df = df[df[\"weight_kg\"] <= WEIGHT_TRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting rows with prices below 0\n",
    "df = df[df[\"price\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_time_diff_below_0 = df\n",
    "df = df[df[\"time_diff\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['purchase_timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_and_street</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12423</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12424</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12426</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12320 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                city_and_street    city             street\n",
       "0      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "1      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "2      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "3      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "4      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "...                         ...     ...                ...\n",
       "12423   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "12424   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "12425   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "12426   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "12427   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "\n",
       "[12320 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['city_and_street'] = df['city'] + ' ' + df['street']\n",
    "display(df[['city_and_street', 'city', 'street']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['purchase_datetime_delta'] = (df['purchase_timestamp'] - df['purchase_timestamp'].min())  / np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "ADDITIONAL_COLUMNS_TO_DROP = [\"delivery_timestamp\",\n",
    "                              \"session_id\",\n",
    "                              \"purchase_id\",\n",
    "                              \"event_type\",\n",
    "                              \"name\",\n",
    "                              \"city_and_street\",\n",
    "                              \"brand\",\n",
    "                              \"user_id\",\n",
    "                              'product_name',\n",
    "                              'offered_discount']\n",
    "df = df.drop(columns=ADDITIONAL_COLUMNS_TO_DROP)\n",
    "df = df.drop(columns=\"optional_attributes\") # chyba do zmiany - wysokosc itp.\n",
    "df = df.drop(columns=\"purchase_timestamp\") # na pewno do zmiany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_a_col_in_pd(df, col_name):\n",
    "    one_hot = pd.get_dummies(df[col_name], drop_first=True)\n",
    "    df = df.drop(columns=col_name)\n",
    "    df = df.join(one_hot)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_ONE_HOT = [\"delivery_company\", \"city\", \"category_path\", \"street\", 'day_of_week', 'product_id']\n",
    "\n",
    "for col_name in COLUMNS_TO_ONE_HOT:\n",
    "    df = one_hot_encode_a_col_in_pd(df, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12320, 598)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# one-hot encoding took care of missing data, so shape has not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12320 entries, 0 to 12427\n",
      "Columns: 598 entries, time_diff to 1617\n",
      "dtypes: float64(4), uint8(594)\n",
      "memory usage: 7.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify columns for standardization scaling (Z-score normalization)\n",
    "cols_to_std = []\n",
    "\n",
    "# specify columns for min-max scaling\n",
    "# offered_discount, price, weight_kg, purchase_datetime_delta\n",
    "cols_to_min_max = ['price', 'weight_kg', 'purchase_datetime_delta']\n",
    "# cols_to_min_max = ['weight_kg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "for col in cols_to_std:\n",
    "    x = df[col].values\n",
    "    std_scaler = StandardScaler()\n",
    "    x_scaled = std_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    df[col] = x_scaled\n",
    "\n",
    "for col in cols_to_min_max:\n",
    "    x = df[col].values\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    df[col] = x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_diff</th>\n",
       "      <th>price</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>purchase_datetime_delta</th>\n",
       "      <th>516</th>\n",
       "      <th>620</th>\n",
       "      <th>Kraków</th>\n",
       "      <th>Poznań</th>\n",
       "      <th>Radom</th>\n",
       "      <th>Szczecin</th>\n",
       "      <th>...</th>\n",
       "      <th>1464</th>\n",
       "      <th>1475</th>\n",
       "      <th>1487</th>\n",
       "      <th>1535</th>\n",
       "      <th>1547</th>\n",
       "      <th>1558</th>\n",
       "      <th>1562</th>\n",
       "      <th>1588</th>\n",
       "      <th>1597</th>\n",
       "      <th>1617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179997.0</td>\n",
       "      <td>0.162411</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.459102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169885.0</td>\n",
       "      <td>0.043912</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.191164</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164705.0</td>\n",
       "      <td>0.643248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220485.0</td>\n",
       "      <td>0.284985</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0.822567</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138672.0</td>\n",
       "      <td>0.044934</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.343056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 598 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_diff     price  weight_kg  purchase_datetime_delta  516  620  Kraków  \\\n",
       "0   179997.0  0.162411   0.017333                 0.459102    0    1       0   \n",
       "1   169885.0  0.043912   0.000500                 0.191164    0    1       0   \n",
       "2   164705.0  0.643248   0.000000                 0.082217    0    0       0   \n",
       "3   220485.0  0.284985   0.019667                 0.822567    0    1       0   \n",
       "4   138672.0  0.044934   0.008667                 0.343056    1    0       0   \n",
       "\n",
       "   Poznań  Radom  Szczecin  ...  1464  1475  1487  1535  1547  1558  1562  \\\n",
       "0       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "1       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "2       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "3       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "4       1      0         0  ...     0     0     0     0     0     0     1   \n",
       "\n",
       "   1588  1597  1617  \n",
       "0     0     0     0  \n",
       "1     0     0     0  \n",
       "2     0     0     0  \n",
       "3     0     0     0  \n",
       "4     0     0     0  \n",
       "\n",
       "[5 rows x 598 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def split_data(df, target_column=\"time_diff\"):\n",
    "    y = df[\"time_diff\"].to_numpy()\n",
    "    X = df.drop(columns=\"time_diff\")\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(models_list, X_train, y_train):\n",
    "    for model in models_list:\n",
    "        model.fit(X_train, y_train)\n",
    "    return models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_predictions(models_list, X_test, y_test):\n",
    "    y_pred_df = pd.DataFrame()\n",
    "    y_pred_df[\"y_test\"] = y_test\n",
    "    for model in models_list:\n",
    "        y_pred_df[f\"{type(model).__name__} prediction\"] = model.predict(X_test)\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(y_pred_df):\n",
    "    display(y_pred_df.head())\n",
    "    display(y_pred_df.info())\n",
    "    display(y_pred_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(models_list, X_test, y_test):\n",
    "    for model in models_list:\n",
    "        score = model.score(X_test, y_test)\n",
    "        print(f\"{type(model).__name__} score = {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percent_of_good_predictions(models_list, X_test, y_test, error=NUM_OF_HOURS*60*60):\n",
    "    for model in models_list:\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions_time_diff = np.abs(y_test - predictions)\n",
    "        num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "        percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "        print(f'number of good predictions for {type(model).__name__} = {num_of_good_predictions}')\n",
    "        print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# models_list = [Ridge(alpha=0.1),\n",
    "#                Lasso(alpha=0.1),\n",
    "#                DecisionTreeRegressor(random_state=SEED),\n",
    "#                RandomForestRegressor(random_state=SEED)]\n",
    "# models_list = train_models(models_list, X_train, y_train)\n",
    "\n",
    "# y_pred_df = create_df_with_predictions(models_list, X_test, y_test)\n",
    "# # display_predictions(y_pred_df)\n",
    "\n",
    "# print_scores(models_list, X_test, y_test)\n",
    "\n",
    "# print_percent_of_good_predictions(models_list, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autokeras test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 06m 45s]\n",
      "val_loss: 2964773888.0\n",
      "\n",
      "Best val_loss So Far: 2779446784.0\n",
      "Total elapsed time: 00h 57m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "308/308 [==============================] - 12s 12ms/step - loss: 55524978688.0000 - mean_squared_error: 55524978688.0000\n",
      "Epoch 2/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 54191063040.0000 - mean_squared_error: 54191063040.0000\n",
      "Epoch 3/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 49493114880.0000 - mean_squared_error: 49493114880.0000\n",
      "Epoch 4/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 40836476928.0000 - mean_squared_error: 40836476928.0000\n",
      "Epoch 5/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 29647747072.0000 - mean_squared_error: 29647747072.0000\n",
      "Epoch 6/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 18699462656.0000 - mean_squared_error: 18699462656.0000\n",
      "Epoch 7/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 10567519232.0000 - mean_squared_error: 10567519232.0000\n",
      "Epoch 8/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 6249639936.0000 - mean_squared_error: 6249639936.0000\n",
      "Epoch 9/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 4546147840.0000 - mean_squared_error: 4546147840.0000\n",
      "Epoch 10/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 3905065984.0000 - mean_squared_error: 3905065984.0000\n",
      "Epoch 11/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 3580329472.0000 - mean_squared_error: 3580329472.0000\n",
      "Epoch 12/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 3359741440.0000 - mean_squared_error: 3359741440.0000\n",
      "Epoch 13/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 3194138880.0000 - mean_squared_error: 3194138880.0000\n",
      "Epoch 14/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 3064890880.0000 - mean_squared_error: 3064890880.0000\n",
      "Epoch 15/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 2961522944.0000 - mean_squared_error: 2961522944.0000\n",
      "Epoch 16/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 2877304064.0000 - mean_squared_error: 2877304064.0000\n",
      "Epoch 17/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 2807624448.0000 - mean_squared_error: 2807624448.0000\n",
      "Epoch 18/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 2749149184.0000 - mean_squared_error: 2749149184.0000\n",
      "Epoch 19/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 2699415296.0000 - mean_squared_error: 2699415296.0000\n",
      "Epoch 20/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 2656528896.0000 - mean_squared_error: 2656528896.0000\n",
      "Epoch 21/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 2618978048.0000 - mean_squared_error: 2618978048.0000\n",
      "Epoch 22/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 2585731840.0000 - mean_squared_error: 2585731840.0000\n",
      "Epoch 23/200\n",
      "308/308 [==============================] - 8s 28ms/step - loss: 2555963392.0000 - mean_squared_error: 2555963392.0000\n",
      "Epoch 24/200\n",
      "308/308 [==============================] - 10s 33ms/step - loss: 2528892160.0000 - mean_squared_error: 2528892160.0000\n",
      "Epoch 25/200\n",
      "308/308 [==============================] - 12s 38ms/step - loss: 2503990272.0000 - mean_squared_error: 2503990272.0000\n",
      "Epoch 26/200\n",
      "308/308 [==============================] - 11s 36ms/step - loss: 2480951552.0000 - mean_squared_error: 2480951552.0000\n",
      "Epoch 27/200\n",
      "308/308 [==============================] - 8s 26ms/step - loss: 2459565056.0000 - mean_squared_error: 2459565056.0000\n",
      "Epoch 28/200\n",
      "308/308 [==============================] - 7s 24ms/step - loss: 2439550464.0000 - mean_squared_error: 2439550464.0000\n",
      "Epoch 29/200\n",
      "308/308 [==============================] - 8s 26ms/step - loss: 2420716800.0000 - mean_squared_error: 2420716800.0000\n",
      "Epoch 30/200\n",
      "308/308 [==============================] - 6s 21ms/step - loss: 2402836992.0000 - mean_squared_error: 2402836992.0000\n",
      "Epoch 31/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 2385776640.0000 - mean_squared_error: 2385776640.0000\n",
      "Epoch 32/200\n",
      "308/308 [==============================] - 6s 21ms/step - loss: 2369473536.0000 - mean_squared_error: 2369473536.0000\n",
      "Epoch 33/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 2353859584.0000 - mean_squared_error: 2353859584.0000\n",
      "Epoch 34/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 2338854912.0000 - mean_squared_error: 2338854912.0000\n",
      "Epoch 35/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 2324358144.0000 - mean_squared_error: 2324358144.0000\n",
      "Epoch 36/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 2310339584.0000 - mean_squared_error: 2310339584.0000\n",
      "Epoch 37/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 2296733184.0000 - mean_squared_error: 2296733184.0000\n",
      "Epoch 38/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 2283498240.0000 - mean_squared_error: 2283498240.0000\n",
      "Epoch 39/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 2270560768.0000 - mean_squared_error: 2270560768.0000\n",
      "Epoch 40/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 2257910016.0000 - mean_squared_error: 2257910016.0000\n",
      "Epoch 41/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 2245548288.0000 - mean_squared_error: 2245548288.0000\n",
      "Epoch 42/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 2233450496.0000 - mean_squared_error: 2233450496.0000\n",
      "Epoch 43/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 2221596160.0000 - mean_squared_error: 2221596160.0000\n",
      "Epoch 44/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 2209947392.0000 - mean_squared_error: 2209947392.0000\n",
      "Epoch 45/200\n",
      "308/308 [==============================] - 4s 15ms/step - loss: 2198500608.0000 - mean_squared_error: 2198500608.0000\n",
      "Epoch 46/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 2187209728.0000 - mean_squared_error: 2187209728.0000\n",
      "Epoch 47/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 2176081920.0000 - mean_squared_error: 2176081920.0000\n",
      "Epoch 48/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 2165118464.0000 - mean_squared_error: 2165118464.0000\n",
      "Epoch 49/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 2154336512.0000 - mean_squared_error: 2154336512.0000\n",
      "Epoch 50/200\n",
      "308/308 [==============================] - 7s 22ms/step - loss: 2143744256.0000 - mean_squared_error: 2143744256.0000\n",
      "Epoch 51/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 2133272704.0000 - mean_squared_error: 2133272704.0000\n",
      "Epoch 52/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 2122960256.0000 - mean_squared_error: 2122960256.0000\n",
      "Epoch 53/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 2112739840.0000 - mean_squared_error: 2112739840.0000\n",
      "Epoch 54/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 2102628480.0000 - mean_squared_error: 2102628480.0000\n",
      "Epoch 55/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 2092623616.0000 - mean_squared_error: 2092623616.0000\n",
      "Epoch 56/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 2082753920.0000 - mean_squared_error: 2082753920.0000\n",
      "Epoch 57/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 2072982400.0000 - mean_squared_error: 2072982400.0000\n",
      "Epoch 58/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 2063337984.0000 - mean_squared_error: 2063337984.0000\n",
      "Epoch 59/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 2053707392.0000 - mean_squared_error: 2053707392.0000\n",
      "Epoch 60/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 2044162048.0000 - mean_squared_error: 2044162048.0000\n",
      "Epoch 61/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 2034694272.0000 - mean_squared_error: 2034694272.0000\n",
      "Epoch 62/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 2025295232.0000 - mean_squared_error: 2025295232.0000\n",
      "Epoch 63/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 2015991680.0000 - mean_squared_error: 2015991680.0000\n",
      "Epoch 64/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 2006807168.0000 - mean_squared_error: 2006807168.0000\n",
      "Epoch 65/200\n",
      "308/308 [==============================] - 4s 12ms/step - loss: 1997704064.0000 - mean_squared_error: 1997704064.0000\n",
      "Epoch 66/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 1988644224.0000 - mean_squared_error: 1988644224.0000\n",
      "Epoch 67/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1979684736.0000 - mean_squared_error: 1979684736.0000\n",
      "Epoch 68/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 1970795392.0000 - mean_squared_error: 1970795392.0000\n",
      "Epoch 69/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 1961990400.0000 - mean_squared_error: 1961990400.0000\n",
      "Epoch 70/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1953198976.0000 - mean_squared_error: 1953198976.0000\n",
      "Epoch 71/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 1944483968.0000 - mean_squared_error: 1944483968.0000\n",
      "Epoch 72/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1935815168.0000 - mean_squared_error: 1935815168.0000\n",
      "Epoch 73/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1927206144.0000 - mean_squared_error: 1927206144.0000\n",
      "Epoch 74/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1918606592.0000 - mean_squared_error: 1918606592.0000\n",
      "Epoch 75/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1909975680.0000 - mean_squared_error: 1909975680.0000\n",
      "Epoch 76/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1901400064.0000 - mean_squared_error: 1901400064.0000\n",
      "Epoch 77/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1892875648.0000 - mean_squared_error: 1892875648.0000\n",
      "Epoch 78/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1884473600.0000 - mean_squared_error: 1884473600.0000\n",
      "Epoch 79/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1876096768.0000 - mean_squared_error: 1876096768.0000\n",
      "Epoch 80/200\n",
      "308/308 [==============================] - 6s 21ms/step - loss: 1867871744.0000 - mean_squared_error: 1867871744.0000\n",
      "Epoch 81/200\n",
      "308/308 [==============================] - 8s 25ms/step - loss: 1859644416.0000 - mean_squared_error: 1859644416.0000\n",
      "Epoch 82/200\n",
      "308/308 [==============================] - 9s 31ms/step - loss: 1851462656.0000 - mean_squared_error: 1851462656.0000\n",
      "Epoch 83/200\n",
      "308/308 [==============================] - 10s 31ms/step - loss: 1843327232.0000 - mean_squared_error: 1843327232.0000\n",
      "Epoch 84/200\n",
      "308/308 [==============================] - 8s 24ms/step - loss: 1835234560.0000 - mean_squared_error: 1835234560.0000\n",
      "Epoch 85/200\n",
      "308/308 [==============================] - 8s 25ms/step - loss: 1827182208.0000 - mean_squared_error: 1827182208.0000\n",
      "Epoch 86/200\n",
      "308/308 [==============================] - 7s 22ms/step - loss: 1819128448.0000 - mean_squared_error: 1819128448.0000\n",
      "Epoch 87/200\n",
      "308/308 [==============================] - 9s 30ms/step - loss: 1811119488.0000 - mean_squared_error: 1811119488.0000\n",
      "Epoch 88/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1803172352.0000 - mean_squared_error: 1803172352.0000\n",
      "Epoch 89/200\n",
      "308/308 [==============================] - 9s 28ms/step - loss: 1795272576.0000 - mean_squared_error: 1795272576.0000\n",
      "Epoch 90/200\n",
      "308/308 [==============================] - 8s 25ms/step - loss: 1787408384.0000 - mean_squared_error: 1787408384.0000\n",
      "Epoch 91/200\n",
      "308/308 [==============================] - 7s 21ms/step - loss: 1779548544.0000 - mean_squared_error: 1779548544.0000\n",
      "Epoch 92/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1771765504.0000 - mean_squared_error: 1771765504.0000\n",
      "Epoch 93/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1764032256.0000 - mean_squared_error: 1764032256.0000\n",
      "Epoch 94/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1756342016.0000 - mean_squared_error: 1756342016.0000\n",
      "Epoch 95/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1748710272.0000 - mean_squared_error: 1748710272.0000\n",
      "Epoch 96/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1741037056.0000 - mean_squared_error: 1741037056.0000\n",
      "Epoch 97/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1733413632.0000 - mean_squared_error: 1733413632.0000\n",
      "Epoch 98/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 1725847168.0000 - mean_squared_error: 1725847168.0000\n",
      "Epoch 99/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1718323200.0000 - mean_squared_error: 1718323200.0000\n",
      "Epoch 100/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1710745856.0000 - mean_squared_error: 1710745856.0000\n",
      "Epoch 101/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1703218560.0000 - mean_squared_error: 1703218560.0000\n",
      "Epoch 102/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1695652224.0000 - mean_squared_error: 1695652224.0000\n",
      "Epoch 103/200\n",
      "308/308 [==============================] - 7s 22ms/step - loss: 1688215040.0000 - mean_squared_error: 1688215040.0000\n",
      "Epoch 104/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1680669824.0000 - mean_squared_error: 1680669824.0000\n",
      "Epoch 105/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1673240832.0000 - mean_squared_error: 1673240832.0000\n",
      "Epoch 106/200\n",
      "308/308 [==============================] - 6s 21ms/step - loss: 1665859328.0000 - mean_squared_error: 1665859328.0000\n",
      "Epoch 107/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1658537984.0000 - mean_squared_error: 1658537984.0000\n",
      "Epoch 108/200\n",
      "308/308 [==============================] - 7s 23ms/step - loss: 1651261952.0000 - mean_squared_error: 1651261952.0000\n",
      "Epoch 109/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1644008448.0000 - mean_squared_error: 1644008448.0000\n",
      "Epoch 110/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1636765824.0000 - mean_squared_error: 1636765824.0000\n",
      "Epoch 111/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1629615872.0000 - mean_squared_error: 1629615872.0000\n",
      "Epoch 112/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1622397568.0000 - mean_squared_error: 1622397568.0000\n",
      "Epoch 113/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1615282048.0000 - mean_squared_error: 1615282048.0000\n",
      "Epoch 114/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1608214784.0000 - mean_squared_error: 1608214784.0000\n",
      "Epoch 115/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1601209856.0000 - mean_squared_error: 1601209856.0000\n",
      "Epoch 116/200\n",
      "308/308 [==============================] - 4s 14ms/step - loss: 1594303360.0000 - mean_squared_error: 1594303360.0000\n",
      "Epoch 117/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1587507712.0000 - mean_squared_error: 1587507712.0000\n",
      "Epoch 118/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1580714368.0000 - mean_squared_error: 1580714368.0000\n",
      "Epoch 119/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1573948160.0000 - mean_squared_error: 1573948160.0000\n",
      "Epoch 120/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1567219840.0000 - mean_squared_error: 1567219840.0000\n",
      "Epoch 121/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1560576384.0000 - mean_squared_error: 1560576384.0000\n",
      "Epoch 122/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1553982976.0000 - mean_squared_error: 1553982976.0000\n",
      "Epoch 123/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1547355904.0000 - mean_squared_error: 1547355904.0000\n",
      "Epoch 124/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1540809600.0000 - mean_squared_error: 1540809600.0000\n",
      "Epoch 125/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1534243200.0000 - mean_squared_error: 1534243200.0000\n",
      "Epoch 126/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1527702400.0000 - mean_squared_error: 1527702400.0000\n",
      "Epoch 127/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1521207808.0000 - mean_squared_error: 1521207808.0000\n",
      "Epoch 128/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1514705920.0000 - mean_squared_error: 1514705920.0000\n",
      "Epoch 129/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1508222720.0000 - mean_squared_error: 1508222720.0000\n",
      "Epoch 130/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1501700608.0000 - mean_squared_error: 1501700608.0000\n",
      "Epoch 131/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1495250432.0000 - mean_squared_error: 1495250432.0000\n",
      "Epoch 132/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1488824320.0000 - mean_squared_error: 1488824320.0000\n",
      "Epoch 133/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1482343936.0000 - mean_squared_error: 1482343936.0000\n",
      "Epoch 134/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1475894144.0000 - mean_squared_error: 1475894144.0000\n",
      "Epoch 135/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1469404288.0000 - mean_squared_error: 1469404288.0000\n",
      "Epoch 136/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1462937728.0000 - mean_squared_error: 1462937728.0000\n",
      "Epoch 137/200\n",
      "308/308 [==============================] - 6s 21ms/step - loss: 1456550528.0000 - mean_squared_error: 1456550528.0000\n",
      "Epoch 138/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1450151552.0000 - mean_squared_error: 1450151552.0000\n",
      "Epoch 139/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1443804544.0000 - mean_squared_error: 1443804544.0000\n",
      "Epoch 140/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1437476736.0000 - mean_squared_error: 1437476736.0000\n",
      "Epoch 141/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1431133312.0000 - mean_squared_error: 1431133312.0000\n",
      "Epoch 142/200\n",
      "308/308 [==============================] - 7s 22ms/step - loss: 1424772352.0000 - mean_squared_error: 1424772352.0000\n",
      "Epoch 143/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1418413696.0000 - mean_squared_error: 1418413696.0000\n",
      "Epoch 144/200\n",
      "308/308 [==============================] - 7s 22ms/step - loss: 1412119808.0000 - mean_squared_error: 1412119808.0000\n",
      "Epoch 145/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1405768704.0000 - mean_squared_error: 1405768704.0000\n",
      "Epoch 146/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1399458816.0000 - mean_squared_error: 1399458816.0000\n",
      "Epoch 147/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1393255808.0000 - mean_squared_error: 1393255808.0000\n",
      "Epoch 148/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1387019776.0000 - mean_squared_error: 1387019776.0000\n",
      "Epoch 149/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1380774784.0000 - mean_squared_error: 1380774784.0000\n",
      "Epoch 150/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1374526592.0000 - mean_squared_error: 1374526592.0000\n",
      "Epoch 151/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1368291712.0000 - mean_squared_error: 1368291712.0000\n",
      "Epoch 152/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1362070912.0000 - mean_squared_error: 1362070912.0000\n",
      "Epoch 153/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1355838464.0000 - mean_squared_error: 1355838464.0000\n",
      "Epoch 154/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1349640576.0000 - mean_squared_error: 1349640576.0000\n",
      "Epoch 155/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1343468672.0000 - mean_squared_error: 1343468672.0000\n",
      "Epoch 156/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1337400320.0000 - mean_squared_error: 1337400320.0000\n",
      "Epoch 157/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1331370368.0000 - mean_squared_error: 1331370368.0000\n",
      "Epoch 158/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1325297152.0000 - mean_squared_error: 1325297152.0000\n",
      "Epoch 159/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1319216128.0000 - mean_squared_error: 1319216128.0000\n",
      "Epoch 160/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1313346944.0000 - mean_squared_error: 1313346944.0000\n",
      "Epoch 161/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1307347712.0000 - mean_squared_error: 1307347712.0000\n",
      "Epoch 162/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1301482496.0000 - mean_squared_error: 1301482496.0000\n",
      "Epoch 163/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1295654912.0000 - mean_squared_error: 1295654912.0000\n",
      "Epoch 164/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1289838336.0000 - mean_squared_error: 1289838336.0000\n",
      "Epoch 165/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1284105216.0000 - mean_squared_error: 1284105216.0000\n",
      "Epoch 166/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1278319232.0000 - mean_squared_error: 1278319232.0000\n",
      "Epoch 167/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1272613376.0000 - mean_squared_error: 1272613376.0000\n",
      "Epoch 168/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1267003392.0000 - mean_squared_error: 1267003392.0000\n",
      "Epoch 169/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1261521152.0000 - mean_squared_error: 1261521152.0000\n",
      "Epoch 170/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1255982080.0000 - mean_squared_error: 1255982080.0000\n",
      "Epoch 171/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1250520832.0000 - mean_squared_error: 1250520832.0000\n",
      "Epoch 172/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1245016064.0000 - mean_squared_error: 1245016064.0000\n",
      "Epoch 173/200\n",
      "308/308 [==============================] - 4s 13ms/step - loss: 1239489536.0000 - mean_squared_error: 1239489536.0000\n",
      "Epoch 174/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1234022016.0000 - mean_squared_error: 1234022016.0000\n",
      "Epoch 175/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1228435328.0000 - mean_squared_error: 1228435328.0000\n",
      "Epoch 176/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1222883584.0000 - mean_squared_error: 1222883584.0000\n",
      "Epoch 177/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1217358592.0000 - mean_squared_error: 1217358592.0000\n",
      "Epoch 178/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1211739520.0000 - mean_squared_error: 1211739520.0000\n",
      "Epoch 179/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1206127232.0000 - mean_squared_error: 1206127232.0000\n",
      "Epoch 180/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1200505088.0000 - mean_squared_error: 1200505088.0000\n",
      "Epoch 181/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1194960384.0000 - mean_squared_error: 1194960384.0000\n",
      "Epoch 182/200\n",
      "308/308 [==============================] - 5s 16ms/step - loss: 1189336192.0000 - mean_squared_error: 1189336192.0000\n",
      "Epoch 183/200\n",
      "308/308 [==============================] - 5s 15ms/step - loss: 1183737216.0000 - mean_squared_error: 1183737216.0000\n",
      "Epoch 184/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1177937408.0000 - mean_squared_error: 1177937408.0000\n",
      "Epoch 185/200\n",
      "308/308 [==============================] - 7s 22ms/step - loss: 1172044672.0000 - mean_squared_error: 1172044672.0000\n",
      "Epoch 186/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1166219520.0000 - mean_squared_error: 1166219520.0000\n",
      "Epoch 187/200\n",
      "308/308 [==============================] - 5s 17ms/step - loss: 1160397568.0000 - mean_squared_error: 1160397568.0000\n",
      "Epoch 188/200\n",
      "308/308 [==============================] - 6s 18ms/step - loss: 1154515200.0000 - mean_squared_error: 1154515200.0000\n",
      "Epoch 189/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1148653952.0000 - mean_squared_error: 1148653952.0000\n",
      "Epoch 190/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1142967040.0000 - mean_squared_error: 1142967040.0000\n",
      "Epoch 191/200\n",
      "308/308 [==============================] - 7s 22ms/step - loss: 1137065728.0000 - mean_squared_error: 1137065728.0000\n",
      "Epoch 192/200\n",
      "308/308 [==============================] - 6s 20ms/step - loss: 1131145984.0000 - mean_squared_error: 1131145984.0000\n",
      "Epoch 193/200\n",
      "308/308 [==============================] - 5s 18ms/step - loss: 1125211520.0000 - mean_squared_error: 1125211520.0000\n",
      "Epoch 194/200\n",
      "308/308 [==============================] - 9s 28ms/step - loss: 1119415040.0000 - mean_squared_error: 1119415040.0000\n",
      "Epoch 195/200\n",
      "308/308 [==============================] - 8s 25ms/step - loss: 1113732096.0000 - mean_squared_error: 1113732096.0000\n",
      "Epoch 196/200\n",
      "308/308 [==============================] - 7s 24ms/step - loss: 1107760896.0000 - mean_squared_error: 1107760896.0000\n",
      "Epoch 197/200\n",
      "308/308 [==============================] - 6s 19ms/step - loss: 1101713152.0000 - mean_squared_error: 1101713152.0000\n",
      "Epoch 198/200\n",
      "308/308 [==============================] - 8s 25ms/step - loss: 1095645056.0000 - mean_squared_error: 1095645056.0000\n",
      "Epoch 199/200\n",
      "308/308 [==============================] - 9s 30ms/step - loss: 1089503488.0000 - mean_squared_error: 1089503488.0000\n",
      "Epoch 200/200\n",
      "308/308 [==============================] - 7s 24ms/step - loss: 1083405312.0000 - mean_squared_error: 1083405312.0000\n",
      "INFO:tensorflow:Assets written to: .\\structured_data_regressor\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28200f8f6a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "clf = ak.StructuredDataRegressor(max_trials=5)\n",
    "clf.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 9s 34ms/step\n",
      "77/77 [==============================] - 2s 31ms/step\n",
      "number of good predictions for autokeras = 2342674\n",
      "which is 95076.05519480519%\n"
     ]
    }
   ],
   "source": [
    "error = NUM_OF_HOURS * 60 * 60\n",
    "predictions = clf.predict(X_test)\n",
    "# predictions = np.squeeze(predictions)\n",
    "predictions_time_diff = np.abs(y_test - predictions)\n",
    "num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "print(f'number of good predictions for autokeras = {num_of_good_predictions}')\n",
    "print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of good predictions for autokeras = 1412\n",
      "which is 57.3051948051948%\n"
     ]
    }
   ],
   "source": [
    "predictions = np.squeeze(predictions)\n",
    "predictions_time_diff = np.abs(y_test - predictions)\n",
    "num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "print(f'number of good predictions for autokeras = {num_of_good_predictions}')\n",
    "print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 2 * NUM_OF_HOURS * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of good predictions for autokeras = 2171\n",
      "which is 88.10876623376623%\n"
     ]
    }
   ],
   "source": [
    "predictions = np.squeeze(predictions)\n",
    "predictions_time_diff = np.abs(y_test - predictions)\n",
    "num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "print(f'number of good predictions for autokeras = {num_of_good_predictions}')\n",
    "print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 597)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 597)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 597)              1195      \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                19136     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " regression_head_1 (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,420\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 1,195\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autokeras_model = clf.export_model()\n",
    "autokeras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(autokeras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Milosz\\Documents\\PW_sem5\\IUM\\PROJEKT\\auto_keras_test.ipynb Cell 38'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Milosz/Documents/PW_sem5/IUM/PROJEKT/auto_keras_test.ipynb#ch0000040?line=0'>1</a>\u001b[0m autokeras_model\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39;49m\u001b[39m/regression_model\u001b[39;49m\u001b[39m'\u001b[39;49m,save_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:2435\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/engine/training.py?line=2392'>2393</a>\u001b[0m \u001b[39m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/engine/training.py?line=2393'>2394</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/engine/training.py?line=2394'>2395</a>\u001b[0m \u001b[39mPlease see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/engine/training.py?line=2431'>2432</a>\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/engine/training.py?line=2432'>2433</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/engine/training.py?line=2433'>2434</a>\u001b[0m \u001b[39m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/engine/training.py?line=2434'>2435</a>\u001b[0m save\u001b[39m.\u001b[39;49msave_model(\u001b[39mself\u001b[39;49m, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/engine/training.py?line=2435'>2436</a>\u001b[0m                 signatures, options, save_traces)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\saving\\save.py:153\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/save.py?line=150'>151</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/save.py?line=151'>152</a>\u001b[0m   \u001b[39mwith\u001b[39;00m generic_utils\u001b[39m.\u001b[39mSharedObjectSavingScope():\n\u001b[1;32m--> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/save.py?line=152'>153</a>\u001b[0m     saved_model_save\u001b[39m.\u001b[39;49msave(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/save.py?line=153'>154</a>\u001b[0m                           signatures, options, save_traces)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\saving\\saved_model\\save.py:93\u001b[0m, in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/saved_model/save.py?line=90'>91</a>\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mdeprecated_internal_learning_phase_scope(\u001b[39m0\u001b[39m):\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/saved_model/save.py?line=91'>92</a>\u001b[0m   \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39mkeras_option_scope(save_traces):\n\u001b[1;32m---> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/saved_model/save.py?line=92'>93</a>\u001b[0m     saved_nodes, node_paths \u001b[39m=\u001b[39m save_lib\u001b[39m.\u001b[39;49msave_and_return_nodes(\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/saved_model/save.py?line=93'>94</a>\u001b[0m         model, filepath, signatures, options)\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/saved_model/save.py?line=95'>96</a>\u001b[0m   \u001b[39m# Save all metadata to a separate file in the SavedModel directory.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/keras/saving/saved_model/save.py?line=96'>97</a>\u001b[0m   metadata \u001b[39m=\u001b[39m generate_keras_metadata(saved_nodes, node_paths)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\save.py:1325\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1320'>1321</a>\u001b[0m saved_model \u001b[39m=\u001b[39m saved_model_pb2\u001b[39m.\u001b[39mSavedModel()\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1321'>1322</a>\u001b[0m meta_graph_def \u001b[39m=\u001b[39m saved_model\u001b[39m.\u001b[39mmeta_graphs\u001b[39m.\u001b[39madd()\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1323'>1324</a>\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[39m=\u001b[39m (\n\u001b[1;32m-> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1324'>1325</a>\u001b[0m     _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1325'>1326</a>\u001b[0m saved_model\u001b[39m.\u001b[39msaved_model_schema_version \u001b[39m=\u001b[39m (\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1326'>1327</a>\u001b[0m     constants\u001b[39m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1328'>1329</a>\u001b[0m \u001b[39m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1329'>1330</a>\u001b[0m \u001b[39m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\save.py:1491\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1465'>1466</a>\u001b[0m \u001b[39m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1466'>1467</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1467'>1468</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1486'>1487</a>\u001b[0m \u001b[39m  asset_info: `_AssetInfo` tuple containing external assets in the `obj`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1487'>1488</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1489'>1490</a>\u001b[0m \u001b[39mwith\u001b[39;00m save_context\u001b[39m.\u001b[39msave_context(options):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1490'>1491</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _build_meta_graph_impl(obj, signatures, options, meta_graph_def)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\save.py:1445\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1442'>1443</a>\u001b[0m saveable_view \u001b[39m=\u001b[39m _SaveableView(augmented_graph_view, options)\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1443'>1444</a>\u001b[0m object_saver \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mTrackableSaver(augmented_graph_view)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1444'>1445</a>\u001b[0m asset_info, exported_graph \u001b[39m=\u001b[39m _fill_meta_graph_def(\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1445'>1446</a>\u001b[0m     meta_graph_def, saveable_view, signatures,\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1446'>1447</a>\u001b[0m     options\u001b[39m.\u001b[39;49mnamespace_whitelist, options\u001b[39m.\u001b[39;49mexperimental_custom_gradients)\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1447'>1448</a>\u001b[0m \u001b[39mif\u001b[39;00m options\u001b[39m.\u001b[39mfunction_aliases:\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=1448'>1449</a>\u001b[0m   function_aliases \u001b[39m=\u001b[39m meta_graph_def\u001b[39m.\u001b[39mmeta_info_def\u001b[39m.\u001b[39mfunction_aliases\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\save.py:903\u001b[0m, in \u001b[0;36m_fill_meta_graph_def\u001b[1;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist, save_custom_gradients)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=900'>901</a>\u001b[0m signatures \u001b[39m=\u001b[39m _generate_signatures(signature_functions, tensor_map)\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=901'>902</a>\u001b[0m \u001b[39mfor\u001b[39;00m concrete_function \u001b[39min\u001b[39;00m saveable_view\u001b[39m.\u001b[39mconcrete_functions:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=902'>903</a>\u001b[0m   concrete_function\u001b[39m.\u001b[39;49madd_to_graph()\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=903'>904</a>\u001b[0m \u001b[39mif\u001b[39;00m save_custom_gradients:\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/saved_model/save.py?line=904'>905</a>\u001b[0m   _trace_gradient_functions(exported_graph, saveable_view)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2105\u001b[0m, in \u001b[0;36mConcreteFunction.add_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/eager/function.py?line=2102'>2103</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m g:\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/eager/function.py?line=2103'>2104</a>\u001b[0m   g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m-> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/eager/function.py?line=2104'>2105</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_delayed_rewrite_functions\u001b[39m.\u001b[39;49mforward()\u001b[39m.\u001b[39;49madd_to_graph(g)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:446\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.add_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/eager/function.py?line=443'>444</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/eager/function.py?line=444'>445</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m g\u001b[39m.\u001b[39m_is_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/eager/function.py?line=445'>446</a>\u001b[0m     g\u001b[39m.\u001b[39;49m_add_function(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/eager/function.py?line=446'>447</a>\u001b[0m   \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_functions\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/eager/function.py?line=447'>448</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m g\u001b[39m.\u001b[39m_is_function(f\u001b[39m.\u001b[39mname):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:3621\u001b[0m, in \u001b[0;36mGraph._add_function\u001b[1;34m(self, function)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/framework/ops.py?line=3618'>3619</a>\u001b[0m       pywrap_tf_session\u001b[39m.\u001b[39mTF_GraphCopyFunction(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_graph, func, gradient)\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/framework/ops.py?line=3619'>3620</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/framework/ops.py?line=3620'>3621</a>\u001b[0m     pywrap_tf_session\u001b[39m.\u001b[39;49mTF_GraphCopyFunction(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_graph, func, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/framework/ops.py?line=3621'>3622</a>\u001b[0m \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Milosz/AppData/Roaming/Python/Python310/site-packages/tensorflow/python/framework/ops.py?line=3623'>3624</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_functions[compat\u001b[39m.\u001b[39mas_str(name)] \u001b[39m=\u001b[39m function\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autokeras_model.save('/regression_model',save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 61303406592.0000 - mae: 233520.8906 - val_loss: 59726385152.0000 - val_mae: 231063.7344\n",
      "Epoch 2/200\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 61231878144.0000 - mae: 233441.3125 - val_loss: 59619422208.0000 - val_mae: 230935.1562\n",
      "Epoch 3/200\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 61098082304.0000 - mae: 233265.1875 - val_loss: 59474092032.0000 - val_mae: 230763.3438\n",
      "Epoch 4/200\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 60901965824.0000 - mae: 232988.5000 - val_loss: 59266252800.0000 - val_mae: 230473.1250\n",
      "Epoch 5/200\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 60645527552.0000 - mae: 232614.1250 - val_loss: 58933420032.0000 - val_mae: 229940.9062\n",
      "Epoch 6/200\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 60329672704.0000 - mae: 232144.4062 - val_loss: 58550972416.0000 - val_mae: 229304.2031\n",
      "Epoch 7/200\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 59958157312.0000 - mae: 231586.4844 - val_loss: 58147016704.0000 - val_mae: 228685.6719\n",
      "Epoch 8/200\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 59535699968.0000 - mae: 230943.0312 - val_loss: 57369677824.0000 - val_mae: 227270.1719\n",
      "Epoch 9/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 59065970688.0000 - mae: 230218.9375 - val_loss: 56606228480.0000 - val_mae: 225900.6094\n",
      "Epoch 10/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 58557091840.0000 - mae: 229416.5625 - val_loss: 56052998144.0000 - val_mae: 224967.5312\n",
      "Epoch 11/200\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 58003890176.0000 - mae: 228543.0312 - val_loss: 55288340480.0000 - val_mae: 223538.5156\n",
      "Epoch 12/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 57418989568.0000 - mae: 227598.7656 - val_loss: 54971858944.0000 - val_mae: 223244.5000\n",
      "Epoch 13/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 56796655616.0000 - mae: 226590.6406 - val_loss: 54357430272.0000 - val_mae: 222201.9844\n",
      "Epoch 14/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 56145301504.0000 - mae: 225519.8438 - val_loss: 53494951936.0000 - val_mae: 220627.1094\n",
      "Epoch 15/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 55455977472.0000 - mae: 224378.7969 - val_loss: 52634710016.0000 - val_mae: 219103.4844\n",
      "Epoch 16/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 54749421568.0000 - mae: 223181.5312 - val_loss: 51766046720.0000 - val_mae: 217369.2969\n",
      "Epoch 17/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 54014033920.0000 - mae: 221933.7344 - val_loss: 50530320384.0000 - val_mae: 214866.2188\n",
      "Epoch 18/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 53254512640.0000 - mae: 220629.6562 - val_loss: 49786490880.0000 - val_mae: 213475.1875\n",
      "Epoch 19/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 52479864832.0000 - mae: 219277.5781 - val_loss: 49371148288.0000 - val_mae: 212924.5625\n",
      "Epoch 20/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 51672965120.0000 - mae: 217861.4688 - val_loss: 48742817792.0000 - val_mae: 211763.5625\n",
      "Epoch 21/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 50863656960.0000 - mae: 216400.5000 - val_loss: 47423381504.0000 - val_mae: 208969.9375\n",
      "Epoch 22/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 50026700800.0000 - mae: 214889.2031 - val_loss: 45788192768.0000 - val_mae: 205363.7500\n",
      "Epoch 23/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 49185501184.0000 - mae: 213332.7656 - val_loss: 45949599744.0000 - val_mae: 205951.8594\n",
      "Epoch 24/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 48336543744.0000 - mae: 211751.1250 - val_loss: 44533698560.0000 - val_mae: 202815.6406\n",
      "Epoch 25/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 47454285824.0000 - mae: 210100.0156 - val_loss: 44084498432.0000 - val_mae: 202100.5938\n",
      "Epoch 26/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 46575063040.0000 - mae: 208413.0938 - val_loss: 43094577152.0000 - val_mae: 199725.6094\n",
      "Epoch 27/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 45682765824.0000 - mae: 206695.8125 - val_loss: 41674924032.0000 - val_mae: 196491.3594\n",
      "Epoch 28/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 44771729408.0000 - mae: 204907.8125 - val_loss: 41481179136.0000 - val_mae: 196178.5156\n",
      "Epoch 29/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 43862884352.0000 - mae: 203078.9219 - val_loss: 40575447040.0000 - val_mae: 194001.1719\n",
      "Epoch 30/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 42964533248.0000 - mae: 201241.0938 - val_loss: 39220428800.0000 - val_mae: 190683.4688\n",
      "Epoch 31/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 42043400192.0000 - mae: 199339.3594 - val_loss: 39375912960.0000 - val_mae: 191141.5938\n",
      "Epoch 32/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 41135820800.0000 - mae: 197437.6406 - val_loss: 36935081984.0000 - val_mae: 184763.0469\n",
      "Epoch 33/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 40195317760.0000 - mae: 195456.9844 - val_loss: 36456603648.0000 - val_mae: 183436.5781\n",
      "Epoch 34/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 39270105088.0000 - mae: 193435.4531 - val_loss: 34936762368.0000 - val_mae: 179405.6250\n",
      "Epoch 35/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 38375788544.0000 - mae: 191418.0781 - val_loss: 35162234880.0000 - val_mae: 180026.5000\n",
      "Epoch 36/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 37432315904.0000 - mae: 189339.4375 - val_loss: 34052188160.0000 - val_mae: 176806.7500\n",
      "Epoch 37/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 36522573824.0000 - mae: 187218.0469 - val_loss: 32883435520.0000 - val_mae: 173320.1719\n",
      "Epoch 38/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 35611770880.0000 - mae: 185086.7656 - val_loss: 32833396736.0000 - val_mae: 173021.4688\n",
      "Epoch 39/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 34700562432.0000 - mae: 182905.2969 - val_loss: 31276236800.0000 - val_mae: 168311.7656\n",
      "Epoch 40/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 33777235968.0000 - mae: 180689.0469 - val_loss: 30748661760.0000 - val_mae: 166563.9531\n",
      "Epoch 41/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 32870574080.0000 - mae: 178431.8125 - val_loss: 29307836416.0000 - val_mae: 161730.9062\n",
      "Epoch 42/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 31989497856.0000 - mae: 176172.7969 - val_loss: 28810149888.0000 - val_mae: 159866.7500\n",
      "Epoch 43/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 31119982592.0000 - mae: 173871.5469 - val_loss: 27764144128.0000 - val_mae: 156562.0000\n",
      "Epoch 44/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 30182289408.0000 - mae: 171490.4531 - val_loss: 28044709888.0000 - val_mae: 157244.6562\n",
      "Epoch 45/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 29325150208.0000 - mae: 169125.8906 - val_loss: 27035035648.0000 - val_mae: 153524.2500\n",
      "Epoch 46/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 28436332544.0000 - mae: 166737.7500 - val_loss: 25023971328.0000 - val_mae: 146339.0156\n",
      "Epoch 47/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 27611641856.0000 - mae: 164318.4844 - val_loss: 25934229504.0000 - val_mae: 149269.6094\n",
      "Epoch 48/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 26768275456.0000 - mae: 161876.8438 - val_loss: 24863940608.0000 - val_mae: 145179.6719\n",
      "Epoch 49/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 25934874624.0000 - mae: 159373.8125 - val_loss: 24450002944.0000 - val_mae: 143392.4375\n",
      "Epoch 50/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 25109825536.0000 - mae: 156859.0312 - val_loss: 22957887488.0000 - val_mae: 137452.3281\n",
      "Epoch 51/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 24286703616.0000 - mae: 154356.4844 - val_loss: 21583947776.0000 - val_mae: 132504.1875\n",
      "Epoch 52/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 23460898816.0000 - mae: 151730.4375 - val_loss: 23221434368.0000 - val_mae: 138310.9062\n",
      "Epoch 53/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 22703142912.0000 - mae: 149200.5156 - val_loss: 22542149632.0000 - val_mae: 135701.5781\n",
      "Epoch 54/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 21902129152.0000 - mae: 146583.4219 - val_loss: 21856718848.0000 - val_mae: 132872.4375\n",
      "Epoch 55/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 21097865216.0000 - mae: 143873.8906 - val_loss: 21430216704.0000 - val_mae: 130715.8672\n",
      "Epoch 56/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 20355143680.0000 - mae: 141276.1875 - val_loss: 19777705984.0000 - val_mae: 124211.7812\n",
      "Epoch 57/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 19562033152.0000 - mae: 138531.5156 - val_loss: 19721363456.0000 - val_mae: 123774.2500\n",
      "Epoch 58/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 18819151872.0000 - mae: 135754.4531 - val_loss: 18568873984.0000 - val_mae: 119143.7031\n",
      "Epoch 59/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 18147221504.0000 - mae: 133080.5156 - val_loss: 17624109056.0000 - val_mae: 115143.7344\n",
      "Epoch 60/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 17373681664.0000 - mae: 130250.1406 - val_loss: 18006720512.0000 - val_mae: 117231.5703\n",
      "Epoch 61/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 16675193856.0000 - mae: 127519.8906 - val_loss: 17466077184.0000 - val_mae: 115007.9688\n",
      "Epoch 62/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 15916920832.0000 - mae: 124660.8125 - val_loss: 16901440512.0000 - val_mae: 112700.0938\n",
      "Epoch 63/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 15256017920.0000 - mae: 121812.6484 - val_loss: 15936858112.0000 - val_mae: 109022.3203\n",
      "Epoch 64/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 14517583872.0000 - mae: 118923.7500 - val_loss: 14943462400.0000 - val_mae: 104928.0234\n",
      "Epoch 65/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 13843874816.0000 - mae: 115961.8516 - val_loss: 14425061376.0000 - val_mae: 102814.9141\n",
      "Epoch 66/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 13135969280.0000 - mae: 113021.1875 - val_loss: 14302259200.0000 - val_mae: 102325.1641\n",
      "Epoch 67/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 12487911424.0000 - mae: 110185.4688 - val_loss: 14070880256.0000 - val_mae: 102042.2656\n",
      "Epoch 68/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 11829972992.0000 - mae: 107135.2812 - val_loss: 12695071744.0000 - val_mae: 95621.7578\n",
      "Epoch 69/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 11197657088.0000 - mae: 104104.7500 - val_loss: 12796138496.0000 - val_mae: 96290.6484\n",
      "Epoch 70/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 10583543808.0000 - mae: 101150.9219 - val_loss: 12072876032.0000 - val_mae: 92694.1172\n",
      "Epoch 71/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 9975668736.0000 - mae: 98134.9922 - val_loss: 11632596992.0000 - val_mae: 90908.2031\n",
      "Epoch 72/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 9419886592.0000 - mae: 95074.0938 - val_loss: 10591550464.0000 - val_mae: 85616.1875\n",
      "Epoch 73/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 8808646656.0000 - mae: 91988.1875 - val_loss: 10112488448.0000 - val_mae: 83109.1719\n",
      "Epoch 74/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 8274590720.0000 - mae: 88997.1172 - val_loss: 10100411392.0000 - val_mae: 83584.9766\n",
      "Epoch 75/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 7730818560.0000 - mae: 85898.5078 - val_loss: 9597518848.0000 - val_mae: 81074.4609\n",
      "Epoch 76/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 7215530496.0000 - mae: 82892.1094 - val_loss: 9214668800.0000 - val_mae: 78943.5391\n",
      "Epoch 77/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 6728545280.0000 - mae: 79817.2891 - val_loss: 8755848192.0000 - val_mae: 76900.3906\n",
      "Epoch 78/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 6252731392.0000 - mae: 76832.3594 - val_loss: 8233421312.0000 - val_mae: 74083.3750\n",
      "Epoch 79/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 5789022208.0000 - mae: 73711.2969 - val_loss: 7967487488.0000 - val_mae: 72487.7500\n",
      "Epoch 80/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 5336342528.0000 - mae: 70688.9453 - val_loss: 7913566720.0000 - val_mae: 72470.3516\n",
      "Epoch 81/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 4939350016.0000 - mae: 67688.2031 - val_loss: 7488356864.0000 - val_mae: 69815.0000\n",
      "Epoch 82/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 4522277888.0000 - mae: 64646.9062 - val_loss: 7067824128.0000 - val_mae: 67510.8047\n",
      "Epoch 83/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 4177781504.0000 - mae: 61657.2188 - val_loss: 7027095552.0000 - val_mae: 67270.3750\n",
      "Epoch 84/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 3802526976.0000 - mae: 58734.7148 - val_loss: 6555123712.0000 - val_mae: 64672.6992\n",
      "Epoch 85/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 3461008384.0000 - mae: 55750.4141 - val_loss: 6131834880.0000 - val_mae: 62260.2930\n",
      "Epoch 86/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 3112945920.0000 - mae: 52808.4727 - val_loss: 5895775232.0000 - val_mae: 60891.7930\n",
      "Epoch 87/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 2836256768.0000 - mae: 50055.6836 - val_loss: 5634519552.0000 - val_mae: 59391.3281\n",
      "Epoch 88/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 2555975680.0000 - mae: 47111.4453 - val_loss: 5379294720.0000 - val_mae: 57971.2031\n",
      "Epoch 89/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 2286775552.0000 - mae: 44282.8477 - val_loss: 5119579136.0000 - val_mae: 56454.4023\n",
      "Epoch 90/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 2069620096.0000 - mae: 41581.4648 - val_loss: 4930717696.0000 - val_mae: 55033.7148\n",
      "Epoch 91/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 1830080256.0000 - mae: 38984.3828 - val_loss: 4766227968.0000 - val_mae: 54273.5234\n",
      "Epoch 92/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 1641283840.0000 - mae: 36445.3945 - val_loss: 4717854208.0000 - val_mae: 53936.5781\n",
      "Epoch 93/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 1453257472.0000 - mae: 33993.9727 - val_loss: 4454105088.0000 - val_mae: 52338.8438\n",
      "Epoch 94/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 1309221760.0000 - mae: 31750.0273 - val_loss: 4415239168.0000 - val_mae: 51929.0508\n",
      "Epoch 95/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 1134436352.0000 - mae: 29378.4316 - val_loss: 4356090880.0000 - val_mae: 51941.3359\n",
      "Epoch 96/200\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 994579520.0000 - mae: 27106.7676 - val_loss: 4268398336.0000 - val_mae: 51527.2344\n",
      "Epoch 97/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 887537600.0000 - mae: 25369.5039 - val_loss: 4195727872.0000 - val_mae: 50909.5898\n",
      "Epoch 98/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 785961024.0000 - mae: 23520.9473 - val_loss: 4033631744.0000 - val_mae: 49692.7305\n",
      "Epoch 99/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 703407232.0000 - mae: 21917.9102 - val_loss: 4024489472.0000 - val_mae: 49772.9062\n",
      "Epoch 100/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 640507520.0000 - mae: 20736.1777 - val_loss: 4062550016.0000 - val_mae: 50136.2656\n",
      "Epoch 101/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 581049984.0000 - mae: 19496.4805 - val_loss: 4004616960.0000 - val_mae: 49636.9453\n",
      "Epoch 102/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 523385216.0000 - mae: 18261.7500 - val_loss: 3932785408.0000 - val_mae: 49338.8555\n",
      "Epoch 103/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 479441888.0000 - mae: 17434.0391 - val_loss: 3976512000.0000 - val_mae: 49467.2891\n",
      "Epoch 104/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 451931136.0000 - mae: 16818.1621 - val_loss: 3991811072.0000 - val_mae: 49526.9336\n",
      "Epoch 105/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 429752640.0000 - mae: 16433.4004 - val_loss: 3890077952.0000 - val_mae: 49125.4883\n",
      "Epoch 106/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 398211392.0000 - mae: 15644.5107 - val_loss: 4113345280.0000 - val_mae: 50588.6094\n",
      "Epoch 107/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 388737888.0000 - mae: 15277.4248 - val_loss: 3977261312.0000 - val_mae: 49730.0820\n",
      "Epoch 108/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 388354272.0000 - mae: 15431.1973 - val_loss: 4024096000.0000 - val_mae: 50055.5781\n",
      "Epoch 109/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 352662016.0000 - mae: 14781.3145 - val_loss: 3924605440.0000 - val_mae: 49479.9219\n",
      "Epoch 110/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 336889408.0000 - mae: 14397.1729 - val_loss: 3954046208.0000 - val_mae: 49772.6680\n",
      "Epoch 111/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 349202464.0000 - mae: 14728.9395 - val_loss: 4026571776.0000 - val_mae: 49962.9023\n",
      "Epoch 112/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 362414528.0000 - mae: 14974.4551 - val_loss: 3800711424.0000 - val_mae: 48644.6953\n",
      "Epoch 113/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 307892544.0000 - mae: 13668.8398 - val_loss: 3967930112.0000 - val_mae: 49561.9414\n",
      "Epoch 114/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 311502816.0000 - mae: 13818.5371 - val_loss: 3992029952.0000 - val_mae: 49984.9453\n",
      "Epoch 115/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 303531392.0000 - mae: 13687.5166 - val_loss: 4057694464.0000 - val_mae: 50200.7383\n",
      "Epoch 116/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 319107904.0000 - mae: 13921.6553 - val_loss: 3817114112.0000 - val_mae: 48806.7461\n",
      "Epoch 117/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 328536128.0000 - mae: 14189.0361 - val_loss: 4010368512.0000 - val_mae: 49918.7773\n",
      "Epoch 118/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 312851616.0000 - mae: 13852.0732 - val_loss: 4085339136.0000 - val_mae: 50394.2852\n",
      "Epoch 119/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 336545984.0000 - mae: 14378.9121 - val_loss: 3874439424.0000 - val_mae: 48907.3516\n",
      "Epoch 120/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 331794688.0000 - mae: 14368.1201 - val_loss: 3904198400.0000 - val_mae: 49019.4023\n",
      "Epoch 121/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 322468160.0000 - mae: 14011.6182 - val_loss: 3724409856.0000 - val_mae: 48145.8828\n",
      "Epoch 122/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 289943584.0000 - mae: 13380.4395 - val_loss: 3828303872.0000 - val_mae: 48908.6953\n",
      "Epoch 123/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 308873344.0000 - mae: 13778.1953 - val_loss: 3919150336.0000 - val_mae: 49414.4922\n",
      "Epoch 124/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 309172960.0000 - mae: 13726.7568 - val_loss: 3745856256.0000 - val_mae: 48458.6367\n",
      "Epoch 125/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 331963648.0000 - mae: 14116.0908 - val_loss: 4045716736.0000 - val_mae: 50307.7070\n",
      "Epoch 126/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 317012736.0000 - mae: 13906.7822 - val_loss: 3667472384.0000 - val_mae: 47814.5039\n",
      "Epoch 127/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 327747424.0000 - mae: 14146.6396 - val_loss: 3920807424.0000 - val_mae: 49334.2109\n",
      "Epoch 128/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 311525632.0000 - mae: 13787.6348 - val_loss: 3823155712.0000 - val_mae: 48890.4492\n",
      "Epoch 129/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 327133824.0000 - mae: 14147.5898 - val_loss: 3847426816.0000 - val_mae: 49164.1875\n",
      "Epoch 130/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 322939520.0000 - mae: 14110.9453 - val_loss: 3682255104.0000 - val_mae: 47910.8906\n",
      "Epoch 131/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 315619200.0000 - mae: 13945.0352 - val_loss: 3686343936.0000 - val_mae: 47881.4648\n",
      "Epoch 132/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 307015424.0000 - mae: 13750.3057 - val_loss: 3705156864.0000 - val_mae: 48137.5430\n",
      "Epoch 133/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 304214208.0000 - mae: 13728.6172 - val_loss: 3589878528.0000 - val_mae: 47202.8477\n",
      "Epoch 134/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 299788992.0000 - mae: 13541.7402 - val_loss: 3745224960.0000 - val_mae: 48393.7031\n",
      "Epoch 135/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 307992992.0000 - mae: 13720.5967 - val_loss: 3776613888.0000 - val_mae: 48733.3984\n",
      "Epoch 136/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 324398816.0000 - mae: 14066.7344 - val_loss: 3670554112.0000 - val_mae: 47814.1094\n",
      "Epoch 137/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 322997408.0000 - mae: 14126.0449 - val_loss: 3541664768.0000 - val_mae: 47141.2031\n",
      "Epoch 138/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 317925248.0000 - mae: 13896.4268 - val_loss: 3769360896.0000 - val_mae: 48598.0430\n",
      "Epoch 139/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 298829120.0000 - mae: 13594.2822 - val_loss: 3544507904.0000 - val_mae: 46933.4766\n",
      "Epoch 140/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 284204480.0000 - mae: 13195.3564 - val_loss: 3555084544.0000 - val_mae: 47092.9297\n",
      "Epoch 141/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 303994528.0000 - mae: 13411.9922 - val_loss: 3646386432.0000 - val_mae: 47775.1094\n",
      "Epoch 142/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 281468064.0000 - mae: 13116.9463 - val_loss: 3502040320.0000 - val_mae: 46711.1211\n",
      "Epoch 143/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 293206208.0000 - mae: 13409.2393 - val_loss: 3554408192.0000 - val_mae: 47058.2852\n",
      "Epoch 144/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 316355040.0000 - mae: 13942.5283 - val_loss: 3744570880.0000 - val_mae: 48437.3125\n",
      "Epoch 145/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 315776128.0000 - mae: 13971.5830 - val_loss: 3572316672.0000 - val_mae: 47135.4336\n",
      "Epoch 146/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 315931040.0000 - mae: 13887.8369 - val_loss: 3636113664.0000 - val_mae: 47558.9102\n",
      "Epoch 147/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 306418400.0000 - mae: 13662.9531 - val_loss: 3551523328.0000 - val_mae: 47006.2188\n",
      "Epoch 148/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 310536896.0000 - mae: 13846.4209 - val_loss: 3550582016.0000 - val_mae: 47114.7930\n",
      "Epoch 149/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 298342176.0000 - mae: 13503.8965 - val_loss: 3554582272.0000 - val_mae: 47021.0977\n",
      "Epoch 150/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 294593696.0000 - mae: 13409.9062 - val_loss: 3535670272.0000 - val_mae: 46790.0078\n",
      "Epoch 151/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 303949664.0000 - mae: 13678.2246 - val_loss: 3500589056.0000 - val_mae: 46905.2383\n",
      "Epoch 152/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 277978272.0000 - mae: 13157.9316 - val_loss: 3585167872.0000 - val_mae: 47329.3516\n",
      "Epoch 153/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 287949984.0000 - mae: 13287.4756 - val_loss: 3470250240.0000 - val_mae: 46683.8125\n",
      "Epoch 154/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 285286272.0000 - mae: 13287.8682 - val_loss: 3438136832.0000 - val_mae: 46437.2148\n",
      "Epoch 155/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 299689376.0000 - mae: 13618.2910 - val_loss: 3345284352.0000 - val_mae: 45690.4375\n",
      "Epoch 156/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 307518304.0000 - mae: 13705.7109 - val_loss: 3465767168.0000 - val_mae: 46490.0742\n",
      "Epoch 157/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 324478272.0000 - mae: 14213.6738 - val_loss: 3516518912.0000 - val_mae: 46925.3281\n",
      "Epoch 158/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 292394496.0000 - mae: 13315.0469 - val_loss: 3385264896.0000 - val_mae: 46011.6602\n",
      "Epoch 159/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 312070368.0000 - mae: 13722.6211 - val_loss: 3377907712.0000 - val_mae: 45731.8867\n",
      "Epoch 160/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 294836800.0000 - mae: 13522.9346 - val_loss: 3385190144.0000 - val_mae: 45744.5469\n",
      "Epoch 161/200\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 275558496.0000 - mae: 12993.3008 - val_loss: 3449128704.0000 - val_mae: 46108.2383\n",
      "Epoch 162/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 299130112.0000 - mae: 13515.5889 - val_loss: 3324866816.0000 - val_mae: 45421.4609\n",
      "Epoch 163/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 308494752.0000 - mae: 13756.1162 - val_loss: 3246168064.0000 - val_mae: 44869.4531\n",
      "Epoch 164/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 301388352.0000 - mae: 13687.9492 - val_loss: 3205029376.0000 - val_mae: 44361.7852\n",
      "Epoch 165/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 281690144.0000 - mae: 13255.2852 - val_loss: 3412363520.0000 - val_mae: 46056.0117\n",
      "Epoch 166/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 289443328.0000 - mae: 13394.5830 - val_loss: 3403328512.0000 - val_mae: 45767.3398\n",
      "Epoch 167/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 280790560.0000 - mae: 13004.2510 - val_loss: 3274312704.0000 - val_mae: 45022.1797\n",
      "Epoch 168/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 252112096.0000 - mae: 12452.5928 - val_loss: 3327512320.0000 - val_mae: 45416.8125\n",
      "Epoch 169/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 289919840.0000 - mae: 13463.7461 - val_loss: 3381540608.0000 - val_mae: 45740.1289\n",
      "Epoch 170/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 297818304.0000 - mae: 13566.1465 - val_loss: 3248222464.0000 - val_mae: 44910.3672\n",
      "Epoch 171/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 311269312.0000 - mae: 13766.9551 - val_loss: 3362002176.0000 - val_mae: 45720.7773\n",
      "Epoch 172/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 286649440.0000 - mae: 13296.0254 - val_loss: 3229957120.0000 - val_mae: 44687.1562\n",
      "Epoch 173/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 294303008.0000 - mae: 13420.3340 - val_loss: 3413210624.0000 - val_mae: 46083.7773\n",
      "Epoch 174/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 267734368.0000 - mae: 12784.4229 - val_loss: 3335122688.0000 - val_mae: 45396.8164\n",
      "Epoch 175/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 306786848.0000 - mae: 13641.6221 - val_loss: 3209861120.0000 - val_mae: 44341.6562\n",
      "Epoch 176/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 295910496.0000 - mae: 13546.1465 - val_loss: 3245997824.0000 - val_mae: 44773.8281\n",
      "Epoch 177/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 282674240.0000 - mae: 13203.5850 - val_loss: 3335242240.0000 - val_mae: 45360.9023\n",
      "Epoch 178/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 309205504.0000 - mae: 13759.2607 - val_loss: 3333478656.0000 - val_mae: 45305.1562\n",
      "Epoch 179/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 296567328.0000 - mae: 13472.3135 - val_loss: 3327750144.0000 - val_mae: 45299.3086\n",
      "Epoch 180/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 264233136.0000 - mae: 12726.5898 - val_loss: 3262584320.0000 - val_mae: 44945.5156\n",
      "Epoch 181/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 275677792.0000 - mae: 13034.6553 - val_loss: 3277079296.0000 - val_mae: 45052.8203\n",
      "Epoch 182/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 258381712.0000 - mae: 12644.7051 - val_loss: 3335523328.0000 - val_mae: 45507.3672\n",
      "Epoch 183/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 294022944.0000 - mae: 13427.3926 - val_loss: 3218578432.0000 - val_mae: 44660.5273\n",
      "Epoch 184/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 262937232.0000 - mae: 12732.8545 - val_loss: 3204160512.0000 - val_mae: 44587.6016\n",
      "Epoch 185/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 284279808.0000 - mae: 13246.4248 - val_loss: 3280134656.0000 - val_mae: 45255.4727\n",
      "Epoch 186/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 283120832.0000 - mae: 13261.8447 - val_loss: 3260938496.0000 - val_mae: 45107.7539\n",
      "Epoch 187/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 280345344.0000 - mae: 12998.5078 - val_loss: 3161430272.0000 - val_mae: 44087.9062\n",
      "Epoch 188/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 274564384.0000 - mae: 12987.5107 - val_loss: 3189823744.0000 - val_mae: 44402.6211\n",
      "Epoch 189/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 270514368.0000 - mae: 12855.2129 - val_loss: 3265613824.0000 - val_mae: 45173.0000\n",
      "Epoch 190/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 274923392.0000 - mae: 13006.6553 - val_loss: 3193651712.0000 - val_mae: 44591.9141\n",
      "Epoch 191/200\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 277057184.0000 - mae: 13025.3428 - val_loss: 3270401536.0000 - val_mae: 45134.8398\n",
      "Epoch 192/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 303948256.0000 - mae: 13761.6670 - val_loss: 3233076736.0000 - val_mae: 44810.9844\n",
      "Epoch 193/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 283887424.0000 - mae: 13150.2090 - val_loss: 3249700096.0000 - val_mae: 45196.9453\n",
      "Epoch 194/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 288690336.0000 - mae: 13353.9922 - val_loss: 3255437824.0000 - val_mae: 45058.7266\n",
      "Epoch 195/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 266311488.0000 - mae: 12776.2041 - val_loss: 3234725888.0000 - val_mae: 44880.6797\n",
      "Epoch 196/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 307177792.0000 - mae: 13781.6240 - val_loss: 3263265024.0000 - val_mae: 45171.6289\n",
      "Epoch 197/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 300979936.0000 - mae: 13551.6143 - val_loss: 3225459712.0000 - val_mae: 44681.6562\n",
      "Epoch 198/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 286452064.0000 - mae: 13301.6416 - val_loss: 3197388032.0000 - val_mae: 44474.5039\n",
      "Epoch 199/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 263772064.0000 - mae: 12699.3066 - val_loss: 3217687808.0000 - val_mae: 44639.0469\n",
      "Epoch 200/200\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 266141344.0000 - mae: 12744.7891 - val_loss: 3301188608.0000 - val_mae: 45238.4961\n",
      "Minimum validation loss: 3161430272.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers, callbacks\n",
    "\n",
    "\n",
    "# early_stopping = callbacks.EarlyStopping(\n",
    "#     min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "#     patience=20, # how many epochs to wait before stopping\n",
    "#     restore_best_weights=True,\n",
    "# )\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     layers.BatchNormalization(input_shape=[input_shape]),\n",
    "\n",
    "#     layers.Dense(1024, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.3),\n",
    "\n",
    "#     layers.Dense(1024, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.3),\n",
    "\n",
    "#     layers.Dense(1),\n",
    "# ])\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='mean_squared_error',\n",
    "#     metrics=['mae']\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     batch_size=64,\n",
    "#     epochs=200,\n",
    "#     callbacks=[early_stopping], # put your callbacks in a list\n",
    "#     # verbose=0,  # turn off training log\n",
    "# )\n",
    "\n",
    "# history_df = pd.DataFrame(history.history)\n",
    "# history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "# print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 4ms/step\n",
      "number of good predictions for Sequential = 1264\n",
      "which is 55.85505965532479%\n"
     ]
    }
   ],
   "source": [
    "error = NUM_OF_HOURS * 60 * 60\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.squeeze(predictions)\n",
    "predictions_time_diff = np.abs(y_test - predictions)\n",
    "num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "print(f'number of good predictions for {type(model).__name__} = {num_of_good_predictions}')\n",
    "print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
