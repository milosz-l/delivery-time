{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# imports and loading DataFrame"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 941,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "import scipy.stats as ss\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import datetime\n",
                "\n",
                "\n",
                "# fact table\n",
                "sessions_df = pd.read_json(\"data/sessions.jsonl\", lines=True)\n",
                "\n",
                "# dimension tables\n",
                "deliveries_df = pd.read_json(\"data/deliveries.jsonl\", lines=True)\n",
                "products_df = pd.read_json(\"data/products.jsonl\", lines=True)\n",
                "users_df = pd.read_json(\"data/users.jsonl\", lines=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# constant values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 942,
            "metadata": {},
            "outputs": [],
            "source": [
                "MAKE_PLOTS = False\n",
                "DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S\"\n",
                "PRICE_TRESHOLD = 100_000    # for outliers\n",
                "WEIGHT_TRESHOLD = 50        # for outliers\n",
                "COLUMNS_TO_DROP = [\"delivery_timestamp\", \"session_id\", \"purchase_id\", \"event_type\", \"name\", \"street\", \"product_id\", \"offered_discount\"]\n",
                "COLUMNS_TO_ONE_HOT = [\"delivery_company\", \"user_id\", \"city\", \"product_name\", \"category_path\", \"brand\"]\n",
                "SEED = 42"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# merging all data into one Datafram and other transformations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## adding a column with time difference in deliveries\n",
                "adding a column with time difference between purchase_timestamp and delivery_timestamp in deliveries table\n",
                "\n",
                "1. Cut microseconds from delivery_timestamp, so it will be the same format as purchase_timestamp, because there are no microseconds in purchase_timestamp (using \".\" as a separator).\n",
                "2. Change columns format to datetime\n",
                "3. Add time_diff column (as timedelta64 object).\n",
                "4. Drop rows where time_diff is null (which means that delivery_timestamp was null).\n",
                "5. Change type of time_diff from timedelta64 to seconds in float.\n",
                "6. Drop rows where time_diff is below 0. THIS STEP IS MADE IN ### without time_diff below 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 943,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.\n",
                "deliveries_df[\"delivery_timestamp\"] = deliveries_df[\"delivery_timestamp\"].str.split('.', expand=True)[0]\n",
                "\n",
                "# 2.\n",
                "deliveries_df[\"purchase_timestamp\"] = pd.to_datetime(deliveries_df[\"purchase_timestamp\"], format=DATE_FORMAT)\n",
                "deliveries_df[\"delivery_timestamp\"] = pd.to_datetime(deliveries_df[\"delivery_timestamp\"], format=DATE_FORMAT)\n",
                "\n",
                "# 3.\n",
                "deliveries_df[\"time_diff\"] = deliveries_df[\"delivery_timestamp\"] - deliveries_df[\"purchase_timestamp\"]\n",
                "\n",
                "# 4.\n",
                "deliveries_df = deliveries_df[deliveries_df[\"time_diff\"].notna()]\n",
                "\n",
                "# 5.\n",
                "# time diff as duration in seconds\n",
                "deliveries_df[\"time_diff\"] = deliveries_df[\"time_diff\"].apply(datetime.timedelta.total_seconds)\n",
                "\n",
                "# 6.\n",
                "# deliveries_df = deliveries_df[deliveries_df[\"time_diff\"] >= 0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## join deliveries with sessions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 944,
            "metadata": {},
            "outputs": [],
            "source": [
                "# drop rows where event_type is not equal \"BUY_PRODUCT\"\n",
                "sessions_df = sessions_df[sessions_df[\"event_type\"] == \"BUY_PRODUCT\"]\n",
                "df = deliveries_df.merge(sessions_df, on=\"purchase_id\", how=\"left\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 945,
            "metadata": {},
            "outputs": [],
            "source": [
                "# making sure, that timestamp == purchase_timestamp\n",
                "num_of_rows_before = df.shape[0]\n",
                "df = df[df[\"timestamp\"] == df[\"purchase_timestamp\"]]\n",
                "num_of_rows_after = df.shape[0]\n",
                "\n",
                "assert(num_of_rows_before == num_of_rows_after)\n",
                "\n",
                "# now we can drop timestamp column, as it is redundant\n",
                "df = df.drop(columns=\"timestamp\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## join with other tables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 946,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.merge(users_df, on=\"user_id\", how=\"left\")\n",
                "df = df.merge(products_df, on=\"product_id\", how=\"left\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# missing data analysis - MCAR, MAR, MNAR\n",
                "\n",
                "made without outliers but with prices below zero (on copy of df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 947,
            "metadata": {},
            "outputs": [],
            "source": [
                "missing_data_df = df.copy(deep=False)\n",
                "missing_data_df[\"delivery_company_is_missing\"] = missing_data_df[\"delivery_company\"].isna()\n",
                "missing_data_df[\"user_id_is_missing\"] = missing_data_df[\"user_id\"].isna()\n",
                "missing_data_df[\"product_id_is_missing\"] = missing_data_df[\"product_id\"].isna()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 948,
            "metadata": {},
            "outputs": [],
            "source": [
                "# rejecting outliers for given PRICE_TRESHOLD\n",
                "missing_data_df = missing_data_df[missing_data_df[\"price\"] <= PRICE_TRESHOLD]\n",
                "\n",
                "# rejecting outliers for given WEIGHT_TRESHOLD\n",
                "missing_data_df = missing_data_df[missing_data_df[\"weight_kg\"] <= WEIGHT_TRESHOLD]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 949,
            "metadata": {},
            "outputs": [],
            "source": [
                "NUM_BINS_MISSING = 50\n",
                "\n",
                "def compare_histograms_for_missing(input_df1, input_df2, end_of_title1=\"\", end_of_title2=\"\"):\n",
                "    fig, ax = plt.subplots(4, 2)\n",
                "    \n",
                "    def plot_histograms_missing(input_df, plot_column, end_of_title=\"\"):\n",
                "\n",
                "        def plot_hist_missing(x, y, col_name, num_bins=None):\n",
                "            if num_bins:\n",
                "                ax[x, y].hist(input_df[col_name], bins=num_bins)\n",
                "            else:\n",
                "                ax[x, y].hist(input_df[col_name])\n",
                "            ax[x, y].set_title(f\"histogram of {col_name}\" + end_of_title)\n",
                "            ax[x, y].set_xlabel(col_name)\n",
                "            ax[x, y].set_ylabel(\"# of observations\")\n",
                "\n",
                "        plot_hist_missing(0, plot_column, \"time_diff\", NUM_BINS_MISSING)\n",
                "        plot_hist_missing(1, plot_column, \"offered_discount\", NUM_BINS_MISSING)\n",
                "        plot_hist_missing(2, plot_column, \"price\", NUM_BINS_MISSING)\n",
                "        plot_hist_missing(3, plot_column, \"weight_kg\", NUM_BINS_MISSING)\n",
                "\n",
                "    plot_histograms_missing(input_df1, 0, end_of_title1)\n",
                "    plot_histograms_missing(input_df2, 1, end_of_title2)\n",
                "\n",
                "    fig.set_size_inches([24, 21])\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## delivery_company missing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 950,
            "metadata": {},
            "outputs": [],
            "source": [
                "no_missing_delivery_company = missing_data_df[missing_data_df[\"delivery_company_is_missing\"] == False]\n",
                "missing_delivery_company = missing_data_df[missing_data_df[\"delivery_company_is_missing\"] == True]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 951,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    compare_histograms_for_missing(no_missing_delivery_company, missing_delivery_company, \" without missing data for delivery_company\", \" with missing delivery_company\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## user_id missing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 952,
            "metadata": {},
            "outputs": [],
            "source": [
                "no_missing_user_id = missing_data_df[missing_data_df[\"user_id_is_missing\"] == False]\n",
                "missing_user_id = missing_data_df[missing_data_df[\"user_id_is_missing\"] == True]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 953,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    compare_histograms_for_missing(no_missing_user_id, missing_user_id, \" without missing data for user_id\", \" with missing user_id\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## product_id missing\n",
                "this analysis doesn't make sense"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 954,
            "metadata": {},
            "outputs": [],
            "source": [
                "no_missing_product_id = missing_data_df[missing_data_df[\"product_id_is_missing\"] == False]\n",
                "missing_product_id = missing_data_df[missing_data_df[\"product_id_is_missing\"] == True]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 955,
            "metadata": {},
            "outputs": [],
            "source": [
                "# if MAKE_PLOTS:\n",
                "#     compare_histograms_for_missing(no_missing_product_id, missing_product_id, \" without missing data for product_id\", \" with missing product_id\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# visualizations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## time_diff histogram and log-normal distribution test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 956,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    fig, ax = plt.subplots(1, 2)\n",
                "\n",
                "    def plot_hist(x, num_bins=50, func=None):\n",
                "        if func:\n",
                "            ax[x].hist(func(df[\"time_diff\"]), bins=num_bins)\n",
                "            ax[x].set_title(f\"with {func} function\")\n",
                "        else:\n",
                "            ax[x].hist(df[\"time_diff\"], bins=num_bins)\n",
                "            ax[x].set_title(f\"without function\")\n",
                "        ax[x].set_xlabel(\"time difference [seconds]\")\n",
                "        ax[x].set_ylabel(\"# of observations\")\n",
                "\n",
                "    plot_hist(0)\n",
                "    plot_hist(1, func=np.log)\n",
                "    # plot_hist(1, 0, func=np.log2)\n",
                "    # plot_hist(1, 1, func=np.log10)\n",
                "\n",
                "    fig.set_size_inches([12, 6])\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## histograms of continuous variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 957,
            "metadata": {},
            "outputs": [],
            "source": [
                "NUM_BINS = 50\n",
                "\n",
                "\n",
                "def plot_histograms(input_df):\n",
                "    fig, ax = plt.subplots(2, 2)\n",
                "\n",
                "    def plot_hist(x, y, col_name, num_bins=None):\n",
                "        if num_bins:\n",
                "            ax[x, y].hist(input_df[col_name], bins=num_bins)\n",
                "        else:\n",
                "            ax[x, y].hist(input_df[col_name])\n",
                "        ax[x, y].set_title(f\"histogram of {col_name}\")\n",
                "        ax[x, y].set_xlabel(col_name)\n",
                "        ax[x, y].set_ylabel(\"# of observations\")\n",
                "\n",
                "    plot_hist(0, 0, \"time_diff\", NUM_BINS)\n",
                "    plot_hist(0, 1, \"offered_discount\", NUM_BINS)\n",
                "    plot_hist(1, 0, \"price\", NUM_BINS)\n",
                "    plot_hist(1, 1, \"weight_kg\", NUM_BINS)\n",
                "\n",
                "    fig.set_size_inches([12, 12])\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### with outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 958,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    plot_histograms(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### without outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 959,
            "metadata": {},
            "outputs": [],
            "source": [
                "# rejecting outliers for given PRICE_TRESHOLD\n",
                "df = df[df[\"price\"] <= PRICE_TRESHOLD]\n",
                "\n",
                "# rejecting outliers for given WEIGHT_TRESHOLD\n",
                "df = df[df[\"weight_kg\"] <= WEIGHT_TRESHOLD]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 960,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    plot_histograms(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### without prices below 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 961,
            "metadata": {},
            "outputs": [],
            "source": [
                "# deleting rows with prices below 0\n",
                "df = df[df[\"price\"] >= 0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 962,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    plot_histograms(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### without time_diff below 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 963,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_with_time_diff_below_0 = df\n",
                "df = df[df[\"time_diff\"] >= 0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 964,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    plot_histograms(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## heatmap"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### with time_diff below zero"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 965,
            "metadata": {},
            "outputs": [],
            "source": [
                "def update_list_of_columns():\n",
                "    banned_list_of_columns = [\"purchase_id\", \"delivery_company\", \"session_id\", \"user_id\", \"product_id\"]\n",
                "    columns_list = [col for col in df.columns.values.tolist() if col not in banned_list_of_columns]\n",
                "    return columns_list\n",
                "\n",
                "columns_list = update_list_of_columns()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 966,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    print(df_with_time_diff_below_0.shape)\n",
                "    ax = sns.heatmap(df_with_time_diff_below_0[columns_list].corr(), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### without time_diff below zero"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### pearson"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 967,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    print(df.shape)\n",
                "    ax = sns.heatmap(df[columns_list].corr('pearson'), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### spearman"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 968,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    print(df.shape)\n",
                "    ax = sns.heatmap(df[columns_list].corr('spearman'), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### kendall"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 969,
            "metadata": {},
            "outputs": [],
            "source": [
                "# if MAKE_PLOTS:\n",
                "#     print(df.shape)\n",
                "#     ax = sns.heatmap(df[columns_list].corr('kendall'), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# dropping columns (choosing attributes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 970,
            "metadata": {},
            "outputs": [],
            "source": [
                "# drop columns\n",
                "df = df.drop(columns=COLUMNS_TO_DROP)\n",
                "df = df.drop(columns=\"optional_attributes\") # chyba do zmiany - wysokosc itp.\n",
                "df = df.drop(columns=\"purchase_timestamp\") # na pewno do zmiany"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 971,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['delivery_company', 'time_diff', 'user_id', 'city', 'product_name',\n",
                            "       'category_path', 'price', 'brand', 'weight_kg'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 971,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# one-hot encoding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 972,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df.to_excel(\"data_before_one_hot_encoding.xlsx\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 973,
            "metadata": {},
            "outputs": [],
            "source": [
                "def one_hot_encode_a_col_in_pd(df, col_name):\n",
                "    one_hot = pd.get_dummies(df[col_name])\n",
                "    df = df.drop(columns=col_name)\n",
                "    df = df.join(one_hot)\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 974,
            "metadata": {},
            "outputs": [],
            "source": [
                "for col_name in COLUMNS_TO_ONE_HOT:\n",
                "    df = one_hot_encode_a_col_in_pd(df, col_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### testy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 975,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # test only for given attributes\n",
                "# attributes_names = [\"city\", \"street\"]\n",
                "# df = df[[\"time_diff\", *attributes_names]]\n",
                "# for name in attributes_names:  \n",
                "#     df = one_hot_encode_a_col_in_pd(df, name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 976,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from sklearn.ensemble import RandomForestRegressor\n",
                "# from sklearn.model_selection import train_test_split\n",
                "# from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# SEED = 42\n",
                "\n",
                "# y = df[\"time_diff\"].to_numpy()\n",
                "# X = df.drop(columns=\"time_diff\")\n",
                "\n",
                "# # standardize features\n",
                "# scaler = StandardScaler()\n",
                "# X_std = scaler.fit_transform(X)\n",
                "\n",
                "# X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=SEED)\n",
                "\n",
                "# model = RandomForestRegressor(random_state=SEED)\n",
                "\n",
                "# model.fit(X_train, y_train)\n",
                "# y_pred_df = pd.DataFrame()\n",
                "# y_pred_df[\"y_test\"] = y_test\n",
                "# y_pred_df[\"prediction\"] = model.predict(X_test)\n",
                "# y_pred_df[\"mean of time_diff\"] = np.full(675, df[\"time_diff\"].mean())\n",
                "# print(y_pred_df.head())\n",
                "# print(y_pred_df.info())\n",
                "# print(y_pred_df.describe())\n",
                "\n",
                "# score = model.score(X_test, y_test)\n",
                "# print(f\"model score = {score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 977,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from sklearn.tree import DecisionTreeRegressor\n",
                "# from sklearn.model_selection import train_test_split\n",
                "# from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# SEED = 42\n",
                "\n",
                "# y = df[\"time_diff\"].to_numpy()\n",
                "# X = df.drop(columns=\"time_diff\")\n",
                "\n",
                "# # standardize features\n",
                "# scaler = StandardScaler()\n",
                "# X_std = scaler.fit_transform(X)\n",
                "\n",
                "# X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=SEED)\n",
                "\n",
                "# model = DecisionTreeRegressor(random_state=SEED)\n",
                "\n",
                "# model.fit(X_train, y_train)\n",
                "# y_pred_df = pd.DataFrame()\n",
                "# y_pred_df[\"y_test\"] = y_test\n",
                "# y_pred_df[\"prediction\"] = model.predict(X_test)\n",
                "# y_pred_df[\"mean of time_diff\"] = np.full(675, df[\"time_diff\"].mean())\n",
                "# print(y_pred_df.head())\n",
                "# print(y_pred_df.info())\n",
                "# print(y_pred_df.describe())\n",
                "\n",
                "# score = model.score(X_test, y_test)\n",
                "# print(f\"model score = {score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 978,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
                "# from sklearn.model_selection import train_test_split\n",
                "# from sklearn.preprocessing import StandardScaler\n",
                "# from sklearn.linear_model import RidgeCV\n",
                "\n",
                "# SEED = 42\n",
                "\n",
                "# y = df[\"time_diff\"].to_numpy()\n",
                "# X = df.drop(columns=\"time_diff\")\n",
                "\n",
                "# # standardize features\n",
                "# scaler = StandardScaler()\n",
                "# X_std = scaler.fit_transform(X)\n",
                "\n",
                "# # find best alpha value\n",
                "# alphas_list_to_try = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
                "# reg_cv = RidgeCV(alphas=alphas_list_to_try)\n",
                "# model_cv = reg_cv.fit(X_std, y)\n",
                "# best_found_alpha = model_cv.alpha_\n",
                "\n",
                "# X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=SEED)\n",
                "\n",
                "\n",
                "# # reg = LinearRegression()\n",
                "# reg = Ridge(alpha=best_found_alpha)\n",
                "# # reg = Lasso(alpha=0.1)\n",
                "\n",
                "# reg.fit(X_train, y_train)\n",
                "# y_pred_df = pd.DataFrame()\n",
                "# y_pred_df[\"y_test\"] = y_test\n",
                "# y_pred_df[\"prediction\"] = reg.predict(X_test)\n",
                "# y_pred_df[\"mean of time_diff\"] = np.full(675, df[\"time_diff\"].mean())\n",
                "# print(y_pred_df.head())\n",
                "# print(y_pred_df.info())\n",
                "# print(y_pred_df.describe())\n",
                "\n",
                "# score = reg.score(X_test, y_test)\n",
                "# print(f\"R^2 score = {score}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### kontynuacja"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### checking df shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 979,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(3375, 430)\n"
                    ]
                }
            ],
            "source": [
                "print(df.shape)\n",
                "columns_list = update_list_of_columns()\n",
                "# ax = sns.heatmap(df[columns_list].corr(), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 980,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(3375, 430)\n"
                    ]
                }
            ],
            "source": [
                "df = df.dropna()\n",
                "print(df.shape)\n",
                "# one-hot encoding took care of missing data, so shape has not changed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# test of linear regression models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 981,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "def split_data_and_standardize(df, target_column=\"time_diff\"):\n",
                "    y = df[\"time_diff\"].to_numpy()\n",
                "    X = df.drop(columns=\"time_diff\")\n",
                "    # standardize features\n",
                "    scaler = StandardScaler()\n",
                "    X_std = scaler.fit_transform(X)\n",
                "    return train_test_split(X_std, y, test_size=0.2, random_state=SEED)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 982,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_models(models_list):\n",
                "    for model in models_list:\n",
                "        model.fit(X_train, y_train)\n",
                "    return models_list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 983,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_df_with_predictions(models_list, y_test):\n",
                "    y_pred_df = pd.DataFrame()\n",
                "    y_pred_df[\"y_test\"] = y_test\n",
                "    for model in models_list:\n",
                "        y_pred_df[f\"{type(model).__name__} prediction\"] = model.predict(X_test)\n",
                "    return y_pred_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 984,
            "metadata": {},
            "outputs": [],
            "source": [
                "def display_predictions(y_pred_df):\n",
                "    display(y_pred_df.head())\n",
                "    display(y_pred_df.info())\n",
                "    display(y_pred_df.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 985,
            "metadata": {},
            "outputs": [],
            "source": [
                "def print_scores(models_list):\n",
                "    for model in models_list:\n",
                "        score = model.score(X_test, y_test)\n",
                "        print(f\"{type(model).__name__} score = {score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 986,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\Milosz\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['float', 'str']. An error will be raised in 1.2.\n",
                        "  warnings.warn(\n",
                        "C:\\Users\\Milosz\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['float', 'str']. An error will be raised in 1.2.\n",
                        "  warnings.warn(\n",
                        "C:\\Users\\Milosz\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e+13, tolerance: 3.833e+09\n",
                        "  model = cd_fast.enet_coordinate_descent(\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>y_test</th>\n",
                            "      <th>Ridge prediction</th>\n",
                            "      <th>Lasso prediction</th>\n",
                            "      <th>DecisionTreeRegressor prediction</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>213361.0</td>\n",
                            "      <td>123079.698983</td>\n",
                            "      <td>123081.152876</td>\n",
                            "      <td>206795.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>292992.0</td>\n",
                            "      <td>178863.041549</td>\n",
                            "      <td>178876.571020</td>\n",
                            "      <td>355226.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>69756.0</td>\n",
                            "      <td>146516.000928</td>\n",
                            "      <td>146521.786450</td>\n",
                            "      <td>61822.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>105882.0</td>\n",
                            "      <td>165487.852799</td>\n",
                            "      <td>165497.798867</td>\n",
                            "      <td>70518.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>27516.0</td>\n",
                            "      <td>174459.151645</td>\n",
                            "      <td>174460.668145</td>\n",
                            "      <td>143221.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "     y_test  Ridge prediction  Lasso prediction  \\\n",
                            "0  213361.0     123079.698983     123081.152876   \n",
                            "1  292992.0     178863.041549     178876.571020   \n",
                            "2   69756.0     146516.000928     146521.786450   \n",
                            "3  105882.0     165487.852799     165497.798867   \n",
                            "4   27516.0     174459.151645     174460.668145   \n",
                            "\n",
                            "   DecisionTreeRegressor prediction  \n",
                            "0                          206795.0  \n",
                            "1                          355226.0  \n",
                            "2                           61822.0  \n",
                            "3                           70518.0  \n",
                            "4                          143221.0  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 675 entries, 0 to 674\n",
                        "Data columns (total 4 columns):\n",
                        " #   Column                            Non-Null Count  Dtype  \n",
                        "---  ------                            --------------  -----  \n",
                        " 0   y_test                            675 non-null    float64\n",
                        " 1   Ridge prediction                  675 non-null    float64\n",
                        " 2   Lasso prediction                  675 non-null    float64\n",
                        " 3   DecisionTreeRegressor prediction  675 non-null    float64\n",
                        "dtypes: float64(4)\n",
                        "memory usage: 21.2 KB\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "None"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>y_test</th>\n",
                            "      <th>Ridge prediction</th>\n",
                            "      <th>Lasso prediction</th>\n",
                            "      <th>DecisionTreeRegressor prediction</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>count</th>\n",
                            "      <td>675.000000</td>\n",
                            "      <td>675.000000</td>\n",
                            "      <td>675.000000</td>\n",
                            "      <td>675.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>mean</th>\n",
                            "      <td>174414.380741</td>\n",
                            "      <td>175450.003683</td>\n",
                            "      <td>175447.625746</td>\n",
                            "      <td>171114.642222</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>std</th>\n",
                            "      <td>123556.467558</td>\n",
                            "      <td>45037.288072</td>\n",
                            "      <td>45038.267265</td>\n",
                            "      <td>118266.522832</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>min</th>\n",
                            "      <td>286.000000</td>\n",
                            "      <td>24484.452485</td>\n",
                            "      <td>24497.135111</td>\n",
                            "      <td>222.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25%</th>\n",
                            "      <td>78062.500000</td>\n",
                            "      <td>148008.457770</td>\n",
                            "      <td>148014.215556</td>\n",
                            "      <td>75923.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50%</th>\n",
                            "      <td>154073.000000</td>\n",
                            "      <td>171755.537835</td>\n",
                            "      <td>171749.948250</td>\n",
                            "      <td>154090.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75%</th>\n",
                            "      <td>246080.000000</td>\n",
                            "      <td>198597.653873</td>\n",
                            "      <td>198600.770873</td>\n",
                            "      <td>240018.750000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>max</th>\n",
                            "      <td>818364.000000</td>\n",
                            "      <td>389730.744819</td>\n",
                            "      <td>389728.139185</td>\n",
                            "      <td>598516.000000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "              y_test  Ridge prediction  Lasso prediction  \\\n",
                            "count     675.000000        675.000000        675.000000   \n",
                            "mean   174414.380741     175450.003683     175447.625746   \n",
                            "std    123556.467558      45037.288072      45038.267265   \n",
                            "min       286.000000      24484.452485      24497.135111   \n",
                            "25%     78062.500000     148008.457770     148014.215556   \n",
                            "50%    154073.000000     171755.537835     171749.948250   \n",
                            "75%    246080.000000     198597.653873     198600.770873   \n",
                            "max    818364.000000     389730.744819     389728.139185   \n",
                            "\n",
                            "       DecisionTreeRegressor prediction  \n",
                            "count                        675.000000  \n",
                            "mean                      171114.642222  \n",
                            "std                       118266.522832  \n",
                            "min                          222.000000  \n",
                            "25%                        75923.000000  \n",
                            "50%                       154090.000000  \n",
                            "75%                       240018.750000  \n",
                            "max                       598516.000000  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ridge score = -0.15995213529471752\n",
                        "Lasso score = -0.16004478311517234\n",
                        "DecisionTreeRegressor score = -0.925148966035179\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "\n",
                "\n",
                "X_train, X_test, y_train, y_test = split_data_and_standardize(df)\n",
                "\n",
                "models_list = [Ridge(alpha=0.1),\n",
                "                Lasso(alpha=0.1),\n",
                "                DecisionTreeRegressor(random_state=SEED)]\n",
                "models_list = train_models(models_list)\n",
                "\n",
                "y_pred_df = create_df_with_predictions(models_list, y_test)\n",
                "display_predictions(y_pred_df)\n",
                "\n",
                "print_scores(models_list)\n"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
        },
        "kernelspec": {
            "display_name": "Python 3.10.1 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.1"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
