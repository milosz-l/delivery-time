{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# imports and loading DataFrame"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 803,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "import scipy.stats as ss\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import datetime\n",
                "\n",
                "\n",
                "# fact table\n",
                "sessions_df = pd.read_json(\"data/sessions.jsonl\", lines=True)\n",
                "\n",
                "# dimension tables\n",
                "deliveries_df = pd.read_json(\"data/deliveries.jsonl\", lines=True)\n",
                "products_df = pd.read_json(\"data/products.jsonl\", lines=True)\n",
                "users_df = pd.read_json(\"data/users.jsonl\", lines=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# constant values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 804,
            "metadata": {},
            "outputs": [],
            "source": [
                "MAKE_PLOTS = False\n",
                "DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S\"\n",
                "PRICE_TRESHOLD = 100_000    # for outliers\n",
                "WEIGHT_TRESHOLD = 50        # for outliers\n",
                "COLUMNS_TO_DROP = [\"delivery_timestamp\", \"session_id\", \"purchase_id\", \"event_type\", \"name\", \"street\", \"product_id\", \"offered_discount\"]\n",
                "COLUMNS_TO_ONE_HOT = [\"delivery_company\", \"user_id\", \"city\", \"product_name\", \"category_path\", \"brand\"]\n",
                "SEED = 42"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# merging all data into one Datafram and other transformations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## adding a column with time difference in deliveries\n",
                "adding a column with time difference between purchase_timestamp and delivery_timestamp in deliveries table\n",
                "\n",
                "1. Cut microseconds from delivery_timestamp, so it will be the same format as purchase_timestamp, because there are no microseconds in purchase_timestamp (using \".\" as a separator).\n",
                "2. Change columns format to datetime\n",
                "3. Add time_diff column (as timedelta64 object).\n",
                "4. Drop rows where time_diff is null (which means that delivery_timestamp was null).\n",
                "5. Change type of time_diff from timedelta64 to seconds in float.\n",
                "6. Drop rows where time_diff is below 0. THIS STEP IS MADE IN ### without time_diff below 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 805,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.\n",
                "deliveries_df[\"delivery_timestamp\"] = deliveries_df[\"delivery_timestamp\"].str.split('.', expand=True)[0]\n",
                "\n",
                "# 2.\n",
                "deliveries_df[\"purchase_timestamp\"] = pd.to_datetime(deliveries_df[\"purchase_timestamp\"], format=DATE_FORMAT)\n",
                "deliveries_df[\"delivery_timestamp\"] = pd.to_datetime(deliveries_df[\"delivery_timestamp\"], format=DATE_FORMAT)\n",
                "\n",
                "# 3.\n",
                "deliveries_df[\"time_diff\"] = deliveries_df[\"delivery_timestamp\"] - deliveries_df[\"purchase_timestamp\"]\n",
                "\n",
                "# 4.\n",
                "deliveries_df = deliveries_df[deliveries_df[\"time_diff\"].notna()]\n",
                "\n",
                "# 5.\n",
                "# time diff as duration in seconds\n",
                "deliveries_df[\"time_diff\"] = deliveries_df[\"time_diff\"].apply(datetime.timedelta.total_seconds)\n",
                "\n",
                "# 6.\n",
                "# deliveries_df = deliveries_df[deliveries_df[\"time_diff\"] >= 0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## join deliveries with sessions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 806,
            "metadata": {},
            "outputs": [],
            "source": [
                "# drop rows where event_type is not equal \"BUY_PRODUCT\"\n",
                "sessions_df = sessions_df[sessions_df[\"event_type\"] == \"BUY_PRODUCT\"]\n",
                "df = deliveries_df.merge(sessions_df, on=\"purchase_id\", how=\"left\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 807,
            "metadata": {},
            "outputs": [],
            "source": [
                "# making sure, that timestamp == purchase_timestamp\n",
                "num_of_rows_before = df.shape[0]\n",
                "df = df[df[\"timestamp\"] == df[\"purchase_timestamp\"]]\n",
                "num_of_rows_after = df.shape[0]\n",
                "\n",
                "assert(num_of_rows_before == num_of_rows_after)\n",
                "\n",
                "# now we can drop timestamp column, as it is redundant\n",
                "df = df.drop(columns=\"timestamp\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## join with other tables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 808,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.merge(users_df, on=\"user_id\", how=\"left\")\n",
                "df = df.merge(products_df, on=\"product_id\", how=\"left\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# missing data analysis - MCAR, MAR, MNAR\n",
                "\n",
                "made without outliers but with prices below zero (on copy of df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 809,
            "metadata": {},
            "outputs": [],
            "source": [
                "missing_data_df = df.copy(deep=False)\n",
                "missing_data_df[\"delivery_company_is_missing\"] = missing_data_df[\"delivery_company\"].isna()\n",
                "missing_data_df[\"user_id_is_missing\"] = missing_data_df[\"user_id\"].isna()\n",
                "missing_data_df[\"product_id_is_missing\"] = missing_data_df[\"product_id\"].isna()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 810,
            "metadata": {},
            "outputs": [],
            "source": [
                "# rejecting outliers for given PRICE_TRESHOLD\n",
                "missing_data_df = missing_data_df[missing_data_df[\"price\"] <= PRICE_TRESHOLD]\n",
                "\n",
                "# rejecting outliers for given WEIGHT_TRESHOLD\n",
                "missing_data_df = missing_data_df[missing_data_df[\"weight_kg\"] <= WEIGHT_TRESHOLD]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 811,
            "metadata": {},
            "outputs": [],
            "source": [
                "NUM_BINS_MISSING = 50\n",
                "\n",
                "def compare_histograms_for_missing(input_df1, input_df2, end_of_title1=\"\", end_of_title2=\"\"):\n",
                "    fig, ax = plt.subplots(4, 2)\n",
                "    \n",
                "    def plot_histograms_missing(input_df, plot_column, end_of_title=\"\"):\n",
                "\n",
                "        def plot_hist_missing(x, y, col_name, num_bins=None):\n",
                "            if num_bins:\n",
                "                ax[x, y].hist(input_df[col_name], bins=num_bins)\n",
                "            else:\n",
                "                ax[x, y].hist(input_df[col_name])\n",
                "            ax[x, y].set_title(f\"histogram of {col_name}\" + end_of_title)\n",
                "            ax[x, y].set_xlabel(col_name)\n",
                "            ax[x, y].set_ylabel(\"# of observations\")\n",
                "\n",
                "        plot_hist_missing(0, plot_column, \"time_diff\", NUM_BINS_MISSING)\n",
                "        plot_hist_missing(1, plot_column, \"offered_discount\", NUM_BINS_MISSING)\n",
                "        plot_hist_missing(2, plot_column, \"price\", NUM_BINS_MISSING)\n",
                "        plot_hist_missing(3, plot_column, \"weight_kg\", NUM_BINS_MISSING)\n",
                "\n",
                "    plot_histograms_missing(input_df1, 0, end_of_title1)\n",
                "    plot_histograms_missing(input_df2, 1, end_of_title2)\n",
                "\n",
                "    fig.set_size_inches([24, 21])\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## delivery_company missing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 812,
            "metadata": {},
            "outputs": [],
            "source": [
                "no_missing_delivery_company = missing_data_df[missing_data_df[\"delivery_company_is_missing\"] == False]\n",
                "missing_delivery_company = missing_data_df[missing_data_df[\"delivery_company_is_missing\"] == True]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 813,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    compare_histograms_for_missing(no_missing_delivery_company, missing_delivery_company, \" without missing data for delivery_company\", \" with missing delivery_company\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## user_id missing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 814,
            "metadata": {},
            "outputs": [],
            "source": [
                "no_missing_user_id = missing_data_df[missing_data_df[\"user_id_is_missing\"] == False]\n",
                "missing_user_id = missing_data_df[missing_data_df[\"user_id_is_missing\"] == True]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 815,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    compare_histograms_for_missing(no_missing_user_id, missing_user_id, \" without missing data for user_id\", \" with missing user_id\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## product_id missing\n",
                "this analysis doesn't make sense"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 816,
            "metadata": {},
            "outputs": [],
            "source": [
                "no_missing_product_id = missing_data_df[missing_data_df[\"product_id_is_missing\"] == False]\n",
                "missing_product_id = missing_data_df[missing_data_df[\"product_id_is_missing\"] == True]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 817,
            "metadata": {},
            "outputs": [],
            "source": [
                "# if MAKE_PLOTS:\n",
                "#     compare_histograms_for_missing(no_missing_product_id, missing_product_id, \" without missing data for product_id\", \" with missing product_id\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# visualizations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## time_diff histogram and log-normal distribution test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 818,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    fig, ax = plt.subplots(1, 2)\n",
                "\n",
                "    def plot_hist(x, num_bins=50, func=None):\n",
                "        if func:\n",
                "            ax[x].hist(func(df[\"time_diff\"]), bins=num_bins)\n",
                "            ax[x].set_title(f\"with {func} function\")\n",
                "        else:\n",
                "            ax[x].hist(df[\"time_diff\"], bins=num_bins)\n",
                "            ax[x].set_title(f\"without function\")\n",
                "        ax[x].set_xlabel(\"time difference [seconds]\")\n",
                "        ax[x].set_ylabel(\"# of observations\")\n",
                "\n",
                "    plot_hist(0)\n",
                "    plot_hist(1, func=np.log)\n",
                "    # plot_hist(1, 0, func=np.log2)\n",
                "    # plot_hist(1, 1, func=np.log10)\n",
                "\n",
                "    fig.set_size_inches([12, 6])\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## histograms of continuous variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 819,
            "metadata": {},
            "outputs": [],
            "source": [
                "NUM_BINS = 50\n",
                "\n",
                "\n",
                "def plot_histograms(input_df):\n",
                "    fig, ax = plt.subplots(2, 2)\n",
                "\n",
                "    def plot_hist(x, y, col_name, num_bins=None):\n",
                "        if num_bins:\n",
                "            ax[x, y].hist(input_df[col_name], bins=num_bins)\n",
                "        else:\n",
                "            ax[x, y].hist(input_df[col_name])\n",
                "        ax[x, y].set_title(f\"histogram of {col_name}\")\n",
                "        ax[x, y].set_xlabel(col_name)\n",
                "        ax[x, y].set_ylabel(\"# of observations\")\n",
                "\n",
                "    plot_hist(0, 0, \"time_diff\", NUM_BINS)\n",
                "    plot_hist(0, 1, \"offered_discount\", NUM_BINS)\n",
                "    plot_hist(1, 0, \"price\", NUM_BINS)\n",
                "    plot_hist(1, 1, \"weight_kg\", NUM_BINS)\n",
                "\n",
                "    fig.set_size_inches([12, 12])\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### with outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 820,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    plot_histograms(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### without outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 821,
            "metadata": {},
            "outputs": [],
            "source": [
                "# rejecting outliers for given PRICE_TRESHOLD\n",
                "df = df[df[\"price\"] <= PRICE_TRESHOLD]\n",
                "\n",
                "# rejecting outliers for given WEIGHT_TRESHOLD\n",
                "df = df[df[\"weight_kg\"] <= WEIGHT_TRESHOLD]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 822,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    plot_histograms(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### without prices below 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 823,
            "metadata": {},
            "outputs": [],
            "source": [
                "# deleting rows with prices below 0\n",
                "df = df[df[\"price\"] >= 0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 824,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    plot_histograms(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### without time_diff below 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 825,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_with_time_diff_below_0 = df\n",
                "df = df[df[\"time_diff\"] >= 0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 826,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    plot_histograms(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## heatmap"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### with time_diff below zero"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 827,
            "metadata": {},
            "outputs": [],
            "source": [
                "def update_list_of_columns():\n",
                "    banned_list_of_columns = [\"purchase_id\", \"delivery_company\", \"session_id\", \"user_id\", \"product_id\"]\n",
                "    columns_list = [col for col in df.columns.values.tolist() if col not in banned_list_of_columns]\n",
                "    return columns_list\n",
                "\n",
                "columns_list = update_list_of_columns()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 828,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    print(df_with_time_diff_below_0.shape)\n",
                "    ax = sns.heatmap(df_with_time_diff_below_0[columns_list].corr(), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### without time_diff below zero"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### pearson"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 829,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    print(df.shape)\n",
                "    ax = sns.heatmap(df[columns_list].corr('pearson'), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### spearman"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 830,
            "metadata": {},
            "outputs": [],
            "source": [
                "if MAKE_PLOTS:\n",
                "    print(df.shape)\n",
                "    ax = sns.heatmap(df[columns_list].corr('spearman'), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### kendall"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 831,
            "metadata": {},
            "outputs": [],
            "source": [
                "# if MAKE_PLOTS:\n",
                "#     print(df.shape)\n",
                "#     ax = sns.heatmap(df[columns_list].corr('kendall'), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# dropping columns (choosing attributes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 832,
            "metadata": {},
            "outputs": [],
            "source": [
                "# drop columns\n",
                "df = df.drop(columns=COLUMNS_TO_DROP)\n",
                "df = df.drop(columns=\"optional_attributes\") # chyba do zmiany - wysokosc itp.\n",
                "df = df.drop(columns=\"purchase_timestamp\") # na pewno do zmiany"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 833,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['delivery_company', 'time_diff', 'user_id', 'city', 'product_name',\n",
                            "       'category_path', 'price', 'brand', 'weight_kg'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 833,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# one-hot encoding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 834,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df.to_excel(\"data_before_one_hot_encoding.xlsx\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 835,
            "metadata": {},
            "outputs": [],
            "source": [
                "def one_hot_encode_a_col_in_pd(df, col_name):\n",
                "    one_hot = pd.get_dummies(df[col_name])\n",
                "    df = df.drop(columns=col_name)\n",
                "    df = df.join(one_hot)\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 836,
            "metadata": {},
            "outputs": [],
            "source": [
                "for col_name in COLUMNS_TO_ONE_HOT:\n",
                "    df = one_hot_encode_a_col_in_pd(df, col_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### testy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 837,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # test only for given attributes\n",
                "# attributes_names = [\"city\", \"street\"]\n",
                "# df = df[[\"time_diff\", *attributes_names]]\n",
                "# for name in attributes_names:  \n",
                "#     df = one_hot_encode_a_col_in_pd(df, name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 838,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from sklearn.ensemble import RandomForestRegressor\n",
                "# from sklearn.model_selection import train_test_split\n",
                "# from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# SEED = 42\n",
                "\n",
                "# y = df[\"time_diff\"].to_numpy()\n",
                "# X = df.drop(columns=\"time_diff\")\n",
                "\n",
                "# # standardize features\n",
                "# scaler = StandardScaler()\n",
                "# X_std = scaler.fit_transform(X)\n",
                "\n",
                "# X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=SEED)\n",
                "\n",
                "# model = RandomForestRegressor(random_state=SEED)\n",
                "\n",
                "# model.fit(X_train, y_train)\n",
                "# y_pred_df = pd.DataFrame()\n",
                "# y_pred_df[\"y_test\"] = y_test\n",
                "# y_pred_df[\"prediction\"] = model.predict(X_test)\n",
                "# y_pred_df[\"mean of time_diff\"] = np.full(675, df[\"time_diff\"].mean())\n",
                "# print(y_pred_df.head())\n",
                "# print(y_pred_df.info())\n",
                "# print(y_pred_df.describe())\n",
                "\n",
                "# score = model.score(X_test, y_test)\n",
                "# print(f\"model score = {score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 839,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from sklearn.tree import DecisionTreeRegressor\n",
                "# from sklearn.model_selection import train_test_split\n",
                "# from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# SEED = 42\n",
                "\n",
                "# y = df[\"time_diff\"].to_numpy()\n",
                "# X = df.drop(columns=\"time_diff\")\n",
                "\n",
                "# # standardize features\n",
                "# scaler = StandardScaler()\n",
                "# X_std = scaler.fit_transform(X)\n",
                "\n",
                "# X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=SEED)\n",
                "\n",
                "# model = DecisionTreeRegressor(random_state=SEED)\n",
                "\n",
                "# model.fit(X_train, y_train)\n",
                "# y_pred_df = pd.DataFrame()\n",
                "# y_pred_df[\"y_test\"] = y_test\n",
                "# y_pred_df[\"prediction\"] = model.predict(X_test)\n",
                "# y_pred_df[\"mean of time_diff\"] = np.full(675, df[\"time_diff\"].mean())\n",
                "# print(y_pred_df.head())\n",
                "# print(y_pred_df.info())\n",
                "# print(y_pred_df.describe())\n",
                "\n",
                "# score = model.score(X_test, y_test)\n",
                "# print(f\"model score = {score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 840,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
                "# from sklearn.model_selection import train_test_split\n",
                "# from sklearn.preprocessing import StandardScaler\n",
                "# from sklearn.linear_model import RidgeCV\n",
                "\n",
                "# SEED = 42\n",
                "\n",
                "# y = df[\"time_diff\"].to_numpy()\n",
                "# X = df.drop(columns=\"time_diff\")\n",
                "\n",
                "# # standardize features\n",
                "# scaler = StandardScaler()\n",
                "# X_std = scaler.fit_transform(X)\n",
                "\n",
                "# # find best alpha value\n",
                "# alphas_list_to_try = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
                "# reg_cv = RidgeCV(alphas=alphas_list_to_try)\n",
                "# model_cv = reg_cv.fit(X_std, y)\n",
                "# best_found_alpha = model_cv.alpha_\n",
                "\n",
                "# X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=SEED)\n",
                "\n",
                "\n",
                "# # reg = LinearRegression()\n",
                "# reg = Ridge(alpha=best_found_alpha)\n",
                "# # reg = Lasso(alpha=0.1)\n",
                "\n",
                "# reg.fit(X_train, y_train)\n",
                "# y_pred_df = pd.DataFrame()\n",
                "# y_pred_df[\"y_test\"] = y_test\n",
                "# y_pred_df[\"prediction\"] = reg.predict(X_test)\n",
                "# y_pred_df[\"mean of time_diff\"] = np.full(675, df[\"time_diff\"].mean())\n",
                "# print(y_pred_df.head())\n",
                "# print(y_pred_df.info())\n",
                "# print(y_pred_df.describe())\n",
                "\n",
                "# score = reg.score(X_test, y_test)\n",
                "# print(f\"R^2 score = {score}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### kontynuacja"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### checking df shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 841,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(3375, 430)\n"
                    ]
                }
            ],
            "source": [
                "print(df.shape)\n",
                "columns_list = update_list_of_columns()\n",
                "# ax = sns.heatmap(df[columns_list].corr(), square=True, cmap='RdYlGn')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 842,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(3375, 430)\n"
                    ]
                }
            ],
            "source": [
                "df = df.dropna()\n",
                "print(df.shape)\n",
                "# one-hot encoding took care of missing data, so shape has not changed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# test of linear regression models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 843,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "\n",
                "def split_data(df, target_column=\"time_diff\"):\n",
                "    y = df[\"time_diff\"].to_numpy()\n",
                "    X = df.drop(columns=\"time_diff\")\n",
                "    return train_test_split(X.values, y, test_size=0.2, random_state=SEED)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 844,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_models(models_list):\n",
                "    for model in models_list:\n",
                "        model.fit(X_train, y_train)\n",
                "    return models_list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 845,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_df_with_predictions(models_list, y_test):\n",
                "    y_pred_df = pd.DataFrame()\n",
                "    y_pred_df[\"y_test\"] = y_test\n",
                "    for model in models_list:\n",
                "        y_pred_df[f\"{type(model).__name__} prediction\"] = model.predict(X_test)\n",
                "    return y_pred_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 846,
            "metadata": {},
            "outputs": [],
            "source": [
                "def display_predictions(y_pred_df):\n",
                "    display(y_pred_df.head())\n",
                "    display(y_pred_df.info())\n",
                "    display(y_pred_df.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 847,
            "metadata": {},
            "outputs": [],
            "source": [
                "def print_scores(models_list):\n",
                "    for model in models_list:\n",
                "        score = model.score(X_test, y_test)\n",
                "        print(f\"{type(model).__name__} score = {score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 848,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\Milosz\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+13, tolerance: 3.833e+09\n",
                        "  model = cd_fast.enet_coordinate_descent(\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>y_test</th>\n",
                            "      <th>Ridge prediction</th>\n",
                            "      <th>Lasso prediction</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>213361.0</td>\n",
                            "      <td>123468.490884</td>\n",
                            "      <td>123126.564172</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>292992.0</td>\n",
                            "      <td>179186.336432</td>\n",
                            "      <td>178880.779341</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>69756.0</td>\n",
                            "      <td>146592.368877</td>\n",
                            "      <td>146571.033139</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>105882.0</td>\n",
                            "      <td>165335.746991</td>\n",
                            "      <td>165496.536482</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>27516.0</td>\n",
                            "      <td>174483.901511</td>\n",
                            "      <td>174456.840288</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "     y_test  Ridge prediction  Lasso prediction\n",
                            "0  213361.0     123468.490884     123126.564172\n",
                            "1  292992.0     179186.336432     178880.779341\n",
                            "2   69756.0     146592.368877     146571.033139\n",
                            "3  105882.0     165335.746991     165496.536482\n",
                            "4   27516.0     174483.901511     174456.840288"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 675 entries, 0 to 674\n",
                        "Data columns (total 3 columns):\n",
                        " #   Column            Non-Null Count  Dtype  \n",
                        "---  ------            --------------  -----  \n",
                        " 0   y_test            675 non-null    float64\n",
                        " 1   Ridge prediction  675 non-null    float64\n",
                        " 2   Lasso prediction  675 non-null    float64\n",
                        "dtypes: float64(3)\n",
                        "memory usage: 15.9 KB\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "None"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>y_test</th>\n",
                            "      <th>Ridge prediction</th>\n",
                            "      <th>Lasso prediction</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>count</th>\n",
                            "      <td>675.000000</td>\n",
                            "      <td>675.000000</td>\n",
                            "      <td>675.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>mean</th>\n",
                            "      <td>174414.380741</td>\n",
                            "      <td>175483.808920</td>\n",
                            "      <td>175454.863244</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>std</th>\n",
                            "      <td>123556.467558</td>\n",
                            "      <td>44347.866946</td>\n",
                            "      <td>45008.490085</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>min</th>\n",
                            "      <td>286.000000</td>\n",
                            "      <td>26331.464080</td>\n",
                            "      <td>24589.700613</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25%</th>\n",
                            "      <td>78062.500000</td>\n",
                            "      <td>147973.618790</td>\n",
                            "      <td>148037.620934</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50%</th>\n",
                            "      <td>154073.000000</td>\n",
                            "      <td>172000.704590</td>\n",
                            "      <td>171733.355771</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75%</th>\n",
                            "      <td>246080.000000</td>\n",
                            "      <td>198557.892384</td>\n",
                            "      <td>198604.365682</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>max</th>\n",
                            "      <td>818364.000000</td>\n",
                            "      <td>380255.827463</td>\n",
                            "      <td>389566.788136</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "              y_test  Ridge prediction  Lasso prediction\n",
                            "count     675.000000        675.000000        675.000000\n",
                            "mean   174414.380741     175483.808920     175454.863244\n",
                            "std    123556.467558      44347.866946      45008.490085\n",
                            "min       286.000000      26331.464080      24589.700613\n",
                            "25%     78062.500000     147973.618790     148037.620934\n",
                            "50%    154073.000000     172000.704590     171733.355771\n",
                            "75%    246080.000000     198557.892384     198604.365682\n",
                            "max    818364.000000     380255.827463     389566.788136"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ridge score = -0.15484943314179023\n",
                        "Lasso score = -0.15979123492106417\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
                "\n",
                "\n",
                "X_train, X_test, y_train, y_test = split_data(df)\n",
                "\n",
                "models_list = [Ridge(alpha=0.1), Lasso(alpha=0.1)]\n",
                "models_list = train_models(models_list)\n",
                "\n",
                "y_pred_df = create_df_with_predictions(models_list, y_test)\n",
                "display_predictions(y_pred_df)\n",
                "\n",
                "print_scores(models_list)\n"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
        },
        "kernelspec": {
            "display_name": "Python 3.10.1 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.1"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
