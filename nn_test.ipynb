{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "# fact table\n",
    "sessions_df = pd.read_json(\"data/sessions.jsonl\", lines=True)\n",
    "\n",
    "# dimension tables\n",
    "deliveries_df = pd.read_json(\"data/deliveries.jsonl\", lines=True)\n",
    "products_df = pd.read_json(\"data/products.jsonl\", lines=True)\n",
    "users_df = pd.read_json(\"data/users.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_PLOTS = True\n",
    "MAKE_PAIRPLOT = True\n",
    "DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S\"\n",
    "PRICE_TRESHOLD = 100_000    # for outliers\n",
    "WEIGHT_TRESHOLD = 50        # for outliers\n",
    "NUM_OF_HOURS = 12\n",
    "SEED = 42\n",
    "SHOW_ALL_WARNINGS = False\n",
    "SHOW_ONLY_ONE_WARNING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "if SHOW_ONLY_ONE_WARNING:\n",
    "    warnings.filterwarnings(action='once')\n",
    "elif not SHOW_ALL_WARNINGS:\n",
    "    warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "deliveries_df[\"delivery_timestamp\"] = deliveries_df[\"delivery_timestamp\"].str.split('.', expand=True)[0]\n",
    "\n",
    "# 2.\n",
    "deliveries_df[\"purchase_timestamp\"] = pd.to_datetime(deliveries_df[\"purchase_timestamp\"], format=DATE_FORMAT)\n",
    "deliveries_df[\"delivery_timestamp\"] = pd.to_datetime(deliveries_df[\"delivery_timestamp\"], format=DATE_FORMAT)\n",
    "\n",
    "# 3.\n",
    "deliveries_df[\"time_diff\"] = deliveries_df[\"delivery_timestamp\"] - deliveries_df[\"purchase_timestamp\"]\n",
    "\n",
    "# 4.\n",
    "deliveries_df = deliveries_df[deliveries_df[\"time_diff\"].notna()]\n",
    "\n",
    "# 5.\n",
    "# time diff as duration in seconds\n",
    "deliveries_df[\"time_diff\"] = deliveries_df[\"time_diff\"].apply(datetime.timedelta.total_seconds)\n",
    "\n",
    "# 6.\n",
    "# deliveries_df = deliveries_df[deliveries_df[\"time_diff\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where event_type is not equal \"BUY_PRODUCT\"\n",
    "sessions_df = sessions_df[sessions_df[\"event_type\"] == \"BUY_PRODUCT\"]\n",
    "df = deliveries_df.merge(sessions_df, on=\"purchase_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure, that timestamp == purchase_timestamp\n",
    "num_of_rows_before = df.shape[0]\n",
    "df = df[df[\"timestamp\"] == df[\"purchase_timestamp\"]]\n",
    "num_of_rows_after = df.shape[0]\n",
    "\n",
    "assert(num_of_rows_before == num_of_rows_after)\n",
    "\n",
    "# now we can drop timestamp column, as it is redundant\n",
    "df = df.drop(columns=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(users_df, on=\"user_id\", how=\"left\")\n",
    "df = df.merge(products_df, on=\"product_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejecting outliers for given PRICE_TRESHOLD\n",
    "df = df[df[\"price\"] <= PRICE_TRESHOLD]\n",
    "\n",
    "# rejecting outliers for given WEIGHT_TRESHOLD\n",
    "df = df[df[\"weight_kg\"] <= WEIGHT_TRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting rows with prices below 0\n",
    "df = df[df[\"price\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_time_diff_below_0 = df\n",
    "df = df[df[\"time_diff\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['purchase_timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_and_street</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11447</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11448</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11315 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                city_and_street    city             street\n",
       "0      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "1      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "2      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "3      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "4      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "...                         ...     ...                ...\n",
       "11447   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11448   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11449   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11450   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11451   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "\n",
       "[11315 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['city_and_street'] = df['city'] + ' ' + df['street']\n",
    "display(df[['city_and_street', 'city', 'street']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['purchase_datetime_delta'] = (df['purchase_timestamp'] - df['purchase_timestamp'].min())  / np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "ADDITIONAL_COLUMNS_TO_DROP = [\"delivery_timestamp\",\n",
    "                              \"session_id\",\n",
    "                              \"purchase_id\",\n",
    "                              \"event_type\",\n",
    "                              \"name\",\n",
    "                              \"city_and_street\",\n",
    "                              \"brand\",\n",
    "                              \"user_id\",\n",
    "                              'product_name',\n",
    "                              'offered_discount']\n",
    "df = df.drop(columns=ADDITIONAL_COLUMNS_TO_DROP)\n",
    "df = df.drop(columns=\"optional_attributes\") # chyba do zmiany - wysokosc itp.\n",
    "df = df.drop(columns=\"purchase_timestamp\") # na pewno do zmiany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_a_col_in_pd(df, col_name):\n",
    "    one_hot = pd.get_dummies(df[col_name], drop_first=True)\n",
    "    df = df.drop(columns=col_name)\n",
    "    df = df.join(one_hot)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_ONE_HOT = [\"delivery_company\", \"city\", \"category_path\", \"street\", 'day_of_week', 'product_id']\n",
    "\n",
    "for col_name in COLUMNS_TO_ONE_HOT:\n",
    "    df = one_hot_encode_a_col_in_pd(df, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11315, 595)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# one-hot encoding took care of missing data, so shape has not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11315 entries, 0 to 11451\n",
      "Columns: 595 entries, time_diff to 1653\n",
      "dtypes: float64(4), uint8(591)\n",
      "memory usage: 7.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify columns for standardization scaling (Z-score normalization)\n",
    "cols_to_std = []\n",
    "\n",
    "# specify columns for min-max scaling\n",
    "# offered_discount, price, weight_kg, purchase_datetime_delta\n",
    "cols_to_min_max = ['price', 'weight_kg', 'purchase_datetime_delta']\n",
    "# cols_to_min_max = ['weight_kg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "for col in cols_to_std:\n",
    "    x = df[col].values\n",
    "    std_scaler = StandardScaler()\n",
    "    x_scaled = std_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    df[col] = x_scaled\n",
    "\n",
    "for col in cols_to_min_max:\n",
    "    x = df[col].values\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    df[col] = x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_diff</th>\n",
       "      <th>price</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>purchase_datetime_delta</th>\n",
       "      <th>516</th>\n",
       "      <th>620</th>\n",
       "      <th>Kraków</th>\n",
       "      <th>Poznań</th>\n",
       "      <th>Radom</th>\n",
       "      <th>Szczecin</th>\n",
       "      <th>...</th>\n",
       "      <th>1627</th>\n",
       "      <th>1628</th>\n",
       "      <th>1629</th>\n",
       "      <th>1630</th>\n",
       "      <th>1631</th>\n",
       "      <th>1632</th>\n",
       "      <th>1633</th>\n",
       "      <th>1634</th>\n",
       "      <th>1635</th>\n",
       "      <th>1653</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194397.0</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.459215</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184285.0</td>\n",
       "      <td>0.406238</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.191245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164705.0</td>\n",
       "      <td>0.665416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>252885.0</td>\n",
       "      <td>0.448400</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.822722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228672.0</td>\n",
       "      <td>0.032173</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.343154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 595 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_diff     price  weight_kg  purchase_datetime_delta  516  620  Kraków  \\\n",
       "0   194397.0  0.228930   0.020000                 0.459215    0    1       0   \n",
       "1   184285.0  0.406238   0.000800                 0.191245    0    1       0   \n",
       "2   164705.0  0.665416   0.000000                 0.082285    0    0       0   \n",
       "3   252885.0  0.448400   0.010667                 0.822722    0    1       0   \n",
       "4   228672.0  0.032173   0.008667                 0.343154    1    0       0   \n",
       "\n",
       "   Poznań  Radom  Szczecin  ...  1627  1628  1629  1630  1631  1632  1633  \\\n",
       "0       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "1       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "2       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "3       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "4       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "\n",
       "   1634  1635  1653  \n",
       "0     0     0     0  \n",
       "1     0     0     0  \n",
       "2     0     0     0  \n",
       "3     0     0     0  \n",
       "4     0     0     0  \n",
       "\n",
       "[5 rows x 595 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def split_data(df, target_column=\"time_diff\"):\n",
    "    y = df[\"time_diff\"].to_numpy()\n",
    "    X = df.drop(columns=\"time_diff\")\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(models_list, X_train, y_train):\n",
    "    for model in models_list:\n",
    "        model.fit(X_train, y_train)\n",
    "    return models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_predictions(models_list, X_test, y_test):\n",
    "    y_pred_df = pd.DataFrame()\n",
    "    y_pred_df[\"y_test\"] = y_test\n",
    "    for model in models_list:\n",
    "        y_pred_df[f\"{type(model).__name__} prediction\"] = model.predict(X_test)\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(y_pred_df):\n",
    "    display(y_pred_df.head())\n",
    "    display(y_pred_df.info())\n",
    "    display(y_pred_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(models_list, X_test, y_test):\n",
    "    for model in models_list:\n",
    "        score = model.score(X_test, y_test)\n",
    "        print(f\"{type(model).__name__} score = {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percent_of_good_predictions(models_list, X_test, y_test, error=NUM_OF_HOURS*60*60):\n",
    "    for model in models_list:\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions_time_diff = np.abs(y_test - predictions)\n",
    "        num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "        percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "        print(f'number of good predictions for {type(model).__name__} = {num_of_good_predictions}')\n",
    "        print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# models_list = [Ridge(alpha=0.1),\n",
    "#                Lasso(alpha=0.1),\n",
    "#                DecisionTreeRegressor(random_state=SEED),\n",
    "#                RandomForestRegressor(random_state=SEED)]\n",
    "# models_list = train_models(models_list, X_train, y_train)\n",
    "\n",
    "# y_pred_df = create_df_with_predictions(models_list, X_test, y_test)\n",
    "# # display_predictions(y_pred_df)\n",
    "\n",
    "# print_scores(models_list, X_test, y_test)\n",
    "\n",
    "# print_percent_of_good_predictions(models_list, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "283/283 [==============================] - 4s 10ms/step - loss: 61296750592.0000 - mae: 233508.0781 - val_loss: 59717242880.0000 - val_mae: 231072.7031\n",
      "Epoch 2/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 61171269632.0000 - mae: 233335.8594 - val_loss: 59508150272.0000 - val_mae: 230760.1094\n",
      "Epoch 3/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 60929314816.0000 - mae: 232971.2031 - val_loss: 59213971456.0000 - val_mae: 230298.1562\n",
      "Epoch 4/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 60578598912.0000 - mae: 232424.3438 - val_loss: 58779774976.0000 - val_mae: 229610.8906\n",
      "Epoch 5/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 60132782080.0000 - mae: 231713.6094 - val_loss: 58083131392.0000 - val_mae: 228380.1719\n",
      "Epoch 6/1000\n",
      "283/283 [==============================] - 4s 13ms/step - loss: 59598909440.0000 - mae: 230853.2812 - val_loss: 57487638528.0000 - val_mae: 227397.5781\n",
      "Epoch 7/1000\n",
      "283/283 [==============================] - 4s 13ms/step - loss: 58988011520.0000 - mae: 229857.2344 - val_loss: 56735408128.0000 - val_mae: 226070.3750\n",
      "Epoch 8/1000\n",
      "283/283 [==============================] - 4s 14ms/step - loss: 58293125120.0000 - mae: 228726.8438 - val_loss: 55592742912.0000 - val_mae: 223922.3438\n",
      "Epoch 9/1000\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 57550176256.0000 - mae: 227485.4688 - val_loss: 54856105984.0000 - val_mae: 222677.8438\n",
      "Epoch 10/1000\n",
      "283/283 [==============================] - 4s 16ms/step - loss: 56739360768.0000 - mae: 226120.4062 - val_loss: 53902688256.0000 - val_mae: 220897.5000\n",
      "Epoch 11/1000\n",
      "283/283 [==============================] - 5s 18ms/step - loss: 55884963840.0000 - mae: 224662.5469 - val_loss: 52638322688.0000 - val_mae: 218453.4688\n",
      "Epoch 12/1000\n",
      "283/283 [==============================] - 5s 19ms/step - loss: 54969782272.0000 - mae: 223096.2031 - val_loss: 52349579264.0000 - val_mae: 218311.1719\n",
      "Epoch 13/1000\n",
      "283/283 [==============================] - 6s 21ms/step - loss: 54026190848.0000 - mae: 221440.3125 - val_loss: 50873884672.0000 - val_mae: 215353.0625\n",
      "Epoch 14/1000\n",
      "283/283 [==============================] - 6s 23ms/step - loss: 53022531584.0000 - mae: 219674.5312 - val_loss: 49129320448.0000 - val_mae: 211746.4531\n",
      "Epoch 15/1000\n",
      "283/283 [==============================] - 7s 24ms/step - loss: 51998072832.0000 - mae: 217839.6406 - val_loss: 48406634496.0000 - val_mae: 210319.4062\n",
      "Epoch 16/1000\n",
      "283/283 [==============================] - 6s 21ms/step - loss: 50925944832.0000 - mae: 215875.3438 - val_loss: 47554707456.0000 - val_mae: 208588.9531\n",
      "Epoch 17/1000\n",
      "283/283 [==============================] - 5s 19ms/step - loss: 49834700800.0000 - mae: 213845.3594 - val_loss: 45679443968.0000 - val_mae: 204703.3594\n",
      "Epoch 18/1000\n",
      "283/283 [==============================] - 7s 26ms/step - loss: 48741793792.0000 - mae: 211774.7344 - val_loss: 44171153408.0000 - val_mae: 201158.5156\n",
      "Epoch 19/1000\n",
      "283/283 [==============================] - 6s 20ms/step - loss: 47588687872.0000 - mae: 209562.8125 - val_loss: 42937159680.0000 - val_mae: 198424.0625\n",
      "Epoch 20/1000\n",
      "283/283 [==============================] - 6s 23ms/step - loss: 46422814720.0000 - mae: 207315.9062 - val_loss: 42780782592.0000 - val_mae: 198347.2031\n",
      "Epoch 21/1000\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 45241147392.0000 - mae: 204961.2031 - val_loss: 40888786944.0000 - val_mae: 193633.7656\n",
      "Epoch 22/1000\n",
      "283/283 [==============================] - 7s 23ms/step - loss: 44042551296.0000 - mae: 202568.7969 - val_loss: 39279685632.0000 - val_mae: 189743.9375\n",
      "Epoch 23/1000\n",
      "283/283 [==============================] - 6s 22ms/step - loss: 42857824256.0000 - mae: 200069.3750 - val_loss: 37040431104.0000 - val_mae: 183704.3594\n",
      "Epoch 24/1000\n",
      "283/283 [==============================] - 7s 26ms/step - loss: 41602441216.0000 - mae: 197493.9375 - val_loss: 37649018880.0000 - val_mae: 185125.2656\n",
      "Epoch 25/1000\n",
      "283/283 [==============================] - 8s 29ms/step - loss: 40368250880.0000 - mae: 194830.6094 - val_loss: 36563324928.0000 - val_mae: 182335.4375\n",
      "Epoch 26/1000\n",
      "283/283 [==============================] - 8s 30ms/step - loss: 39131451392.0000 - mae: 192086.4375 - val_loss: 35798343680.0000 - val_mae: 180260.4375\n",
      "Epoch 27/1000\n",
      "283/283 [==============================] - 6s 21ms/step - loss: 37913968640.0000 - mae: 189325.6250 - val_loss: 33455288320.0000 - val_mae: 173466.5625\n",
      "Epoch 28/1000\n",
      "283/283 [==============================] - 6s 22ms/step - loss: 36684955648.0000 - mae: 186451.2344 - val_loss: 32615211008.0000 - val_mae: 170667.3281\n",
      "Epoch 29/1000\n",
      "283/283 [==============================] - 6s 20ms/step - loss: 35399811072.0000 - mae: 183487.8125 - val_loss: 31263567872.0000 - val_mae: 166031.1719\n",
      "Epoch 30/1000\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 34174941184.0000 - mae: 180508.3750 - val_loss: 30984568832.0000 - val_mae: 164828.1719\n",
      "Epoch 31/1000\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 32951212032.0000 - mae: 177421.7188 - val_loss: 29476118528.0000 - val_mae: 159387.0156\n",
      "Epoch 32/1000\n",
      "283/283 [==============================] - 4s 13ms/step - loss: 31705372672.0000 - mae: 174290.6719 - val_loss: 28139139072.0000 - val_mae: 154974.3594\n",
      "Epoch 33/1000\n",
      "283/283 [==============================] - 4s 13ms/step - loss: 30475227136.0000 - mae: 171034.0156 - val_loss: 27478890496.0000 - val_mae: 152031.1406\n",
      "Epoch 34/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 29245116416.0000 - mae: 167763.6875 - val_loss: 26825437184.0000 - val_mae: 148875.6875\n",
      "Epoch 35/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 28115408896.0000 - mae: 164496.2188 - val_loss: 24823291904.0000 - val_mae: 141459.5781\n",
      "Epoch 36/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 26939977728.0000 - mae: 161103.0000 - val_loss: 25770598400.0000 - val_mae: 143971.3438\n",
      "Epoch 37/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 25721585664.0000 - mae: 157582.9531 - val_loss: 25007251456.0000 - val_mae: 141134.9531\n",
      "Epoch 38/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 24585129984.0000 - mae: 154063.8906 - val_loss: 24737118208.0000 - val_mae: 139159.0781\n",
      "Epoch 39/1000\n",
      "283/283 [==============================] - 4s 12ms/step - loss: 23444645888.0000 - mae: 150467.7656 - val_loss: 23287017472.0000 - val_mae: 133897.3750\n",
      "Epoch 40/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 22327011328.0000 - mae: 146876.6250 - val_loss: 22437974016.0000 - val_mae: 129834.8047\n",
      "Epoch 41/1000\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 21242925056.0000 - mae: 143148.8750 - val_loss: 20415754240.0000 - val_mae: 121732.7969\n",
      "Epoch 42/1000\n",
      "283/283 [==============================] - 4s 14ms/step - loss: 20197359616.0000 - mae: 139393.5625 - val_loss: 20479414272.0000 - val_mae: 122081.4844\n",
      "Epoch 43/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 19125217280.0000 - mae: 135577.3125 - val_loss: 20199763968.0000 - val_mae: 120159.5078\n",
      "Epoch 44/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 18060488704.0000 - mae: 131674.0000 - val_loss: 19602368512.0000 - val_mae: 118430.2031\n",
      "Epoch 45/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 17039537152.0000 - mae: 127829.7188 - val_loss: 17551802368.0000 - val_mae: 110331.9688\n",
      "Epoch 46/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 16041501696.0000 - mae: 123836.9609 - val_loss: 17989203968.0000 - val_mae: 112105.8438\n",
      "Epoch 47/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 15081370624.0000 - mae: 119850.3047 - val_loss: 16624296960.0000 - val_mae: 107535.4297\n",
      "Epoch 48/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 14100220928.0000 - mae: 115663.0703 - val_loss: 16365432832.0000 - val_mae: 107056.7812\n",
      "Epoch 49/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 13166128128.0000 - mae: 111582.9219 - val_loss: 15235292160.0000 - val_mae: 102518.9453\n",
      "Epoch 50/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 12228724736.0000 - mae: 107379.4219 - val_loss: 13827777536.0000 - val_mae: 95896.9844\n",
      "Epoch 51/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 11310481408.0000 - mae: 103190.8516 - val_loss: 13701234688.0000 - val_mae: 95400.0781\n",
      "Epoch 52/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 10432063488.0000 - mae: 98892.4766 - val_loss: 12593923072.0000 - val_mae: 90489.7266\n",
      "Epoch 53/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 9675717632.0000 - mae: 94693.2734 - val_loss: 12441737216.0000 - val_mae: 90247.1797\n",
      "Epoch 54/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 8810319872.0000 - mae: 90269.3828 - val_loss: 11921540096.0000 - val_mae: 87744.6328\n",
      "Epoch 55/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 8057318400.0000 - mae: 85893.4688 - val_loss: 11124722688.0000 - val_mae: 84409.6094\n",
      "Epoch 56/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 7255299072.0000 - mae: 81485.7656 - val_loss: 10631446528.0000 - val_mae: 82220.5625\n",
      "Epoch 57/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 6619985408.0000 - mae: 77223.8516 - val_loss: 10105743360.0000 - val_mae: 79527.6641\n",
      "Epoch 58/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 5957519872.0000 - mae: 72867.9844 - val_loss: 9542272000.0000 - val_mae: 76558.3906\n",
      "Epoch 59/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 5325412864.0000 - mae: 68451.3750 - val_loss: 9016724480.0000 - val_mae: 74399.0703\n",
      "Epoch 60/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 4744660480.0000 - mae: 64035.5547 - val_loss: 8055255552.0000 - val_mae: 70048.6016\n",
      "Epoch 61/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 4251136512.0000 - mae: 60076.3359 - val_loss: 7705667584.0000 - val_mae: 68224.5781\n",
      "Epoch 62/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 3741999360.0000 - mae: 55807.5938 - val_loss: 7300263424.0000 - val_mae: 66035.6875\n",
      "Epoch 63/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 3308250880.0000 - mae: 51681.8789 - val_loss: 6773281792.0000 - val_mae: 63476.6953\n",
      "Epoch 64/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 2856227072.0000 - mae: 47664.1094 - val_loss: 6534128128.0000 - val_mae: 61965.1562\n",
      "Epoch 65/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 2488437248.0000 - mae: 43866.4258 - val_loss: 5864547840.0000 - val_mae: 58534.0352\n",
      "Epoch 66/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 2168878592.0000 - mae: 40179.6328 - val_loss: 5824315904.0000 - val_mae: 58560.4961\n",
      "Epoch 67/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 1819275136.0000 - mae: 36585.5078 - val_loss: 5603829248.0000 - val_mae: 57779.5039\n",
      "Epoch 68/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 1609119744.0000 - mae: 33724.9180 - val_loss: 5252977152.0000 - val_mae: 56214.6367\n",
      "Epoch 69/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 1412344192.0000 - mae: 31098.3516 - val_loss: 5276127744.0000 - val_mae: 56157.7578\n",
      "Epoch 70/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 1195017600.0000 - mae: 28254.4785 - val_loss: 5219769856.0000 - val_mae: 55719.1719\n",
      "Epoch 71/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 1045267200.0000 - mae: 26077.1270 - val_loss: 5051314688.0000 - val_mae: 55180.7812\n",
      "Epoch 72/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 922316544.0000 - mae: 24375.8008 - val_loss: 5005392384.0000 - val_mae: 54711.2227\n",
      "Epoch 73/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 865539328.0000 - mae: 23400.4453 - val_loss: 4914597888.0000 - val_mae: 54855.2344\n",
      "Epoch 74/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 787748800.0000 - mae: 22147.0781 - val_loss: 4936892416.0000 - val_mae: 54648.9180\n",
      "Epoch 75/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 720535552.0000 - mae: 21068.6367 - val_loss: 5010845696.0000 - val_mae: 55317.1328\n",
      "Epoch 76/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 721220032.0000 - mae: 20906.0371 - val_loss: 4794079744.0000 - val_mae: 54194.3867\n",
      "Epoch 77/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 661165184.0000 - mae: 20267.1660 - val_loss: 4861663232.0000 - val_mae: 54619.1797\n",
      "Epoch 78/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 632801728.0000 - mae: 19674.7812 - val_loss: 4990642688.0000 - val_mae: 54988.4727\n",
      "Epoch 79/1000\n",
      "283/283 [==============================] - 3s 9ms/step - loss: 653778624.0000 - mae: 19990.6523 - val_loss: 4768430592.0000 - val_mae: 53756.2422\n",
      "Epoch 80/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 636981952.0000 - mae: 19736.7676 - val_loss: 4672234496.0000 - val_mae: 53452.8125\n",
      "Epoch 81/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 638296384.0000 - mae: 19796.6113 - val_loss: 4708040704.0000 - val_mae: 53710.7539\n",
      "Epoch 82/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 606021120.0000 - mae: 19282.9844 - val_loss: 4625632768.0000 - val_mae: 53059.3711\n",
      "Epoch 83/1000\n",
      "283/283 [==============================] - 6s 20ms/step - loss: 631503744.0000 - mae: 19695.1484 - val_loss: 4791162368.0000 - val_mae: 54029.5859\n",
      "Epoch 84/1000\n",
      "283/283 [==============================] - 4s 15ms/step - loss: 581825344.0000 - mae: 18891.9805 - val_loss: 4644890112.0000 - val_mae: 53231.8242\n",
      "Epoch 85/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 650157056.0000 - mae: 19899.9863 - val_loss: 4636352512.0000 - val_mae: 53155.9102\n",
      "Epoch 86/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 597216704.0000 - mae: 19150.8789 - val_loss: 4858386944.0000 - val_mae: 54101.1406\n",
      "Epoch 87/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 599386048.0000 - mae: 19204.6289 - val_loss: 4822489600.0000 - val_mae: 53868.7422\n",
      "Epoch 88/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 624285312.0000 - mae: 19601.6348 - val_loss: 4659845632.0000 - val_mae: 53039.0391\n",
      "Epoch 89/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 664461568.0000 - mae: 20217.2715 - val_loss: 4580080640.0000 - val_mae: 52583.6484\n",
      "Epoch 90/1000\n",
      "283/283 [==============================] - 3s 10ms/step - loss: 586772352.0000 - mae: 19085.1074 - val_loss: 4745865728.0000 - val_mae: 53422.6602\n",
      "Epoch 91/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 573047616.0000 - mae: 18882.1543 - val_loss: 4794144768.0000 - val_mae: 53781.6055\n",
      "Epoch 92/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 587244224.0000 - mae: 18911.7168 - val_loss: 4655123968.0000 - val_mae: 53183.3516\n",
      "Epoch 93/1000\n",
      "283/283 [==============================] - 3s 11ms/step - loss: 596974528.0000 - mae: 19142.7910 - val_loss: 4423406592.0000 - val_mae: 51900.1680\n",
      "Epoch 94/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 617359296.0000 - mae: 19389.2715 - val_loss: 4533414400.0000 - val_mae: 52401.5352\n",
      "Epoch 95/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 594520960.0000 - mae: 19021.3633 - val_loss: 4415249920.0000 - val_mae: 51671.3594\n",
      "Epoch 96/1000\n",
      "283/283 [==============================] - 3s 12ms/step - loss: 592486848.0000 - mae: 18929.9492 - val_loss: 4530637312.0000 - val_mae: 52266.9414\n",
      "Epoch 97/1000\n",
      "283/283 [==============================] - 4s 13ms/step - loss: 606946752.0000 - mae: 19321.5352 - val_loss: 4532062720.0000 - val_mae: 52225.4570\n",
      "Epoch 98/1000\n",
      "283/283 [==============================] - 4s 14ms/step - loss: 618657984.0000 - mae: 19469.8301 - val_loss: 4562678272.0000 - val_mae: 52295.8320\n",
      "Epoch 99/1000\n",
      "283/283 [==============================] - 5s 16ms/step - loss: 592267072.0000 - mae: 18944.6641 - val_loss: 4306835456.0000 - val_mae: 51046.5156\n",
      "Epoch 100/1000\n",
      "283/283 [==============================] - 5s 17ms/step - loss: 603843264.0000 - mae: 19259.5957 - val_loss: 4227984896.0000 - val_mae: 50635.5352\n",
      "Epoch 101/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 588564800.0000 - mae: 18930.0664 - val_loss: 4296617472.0000 - val_mae: 50877.4297\n",
      "Epoch 102/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 617396352.0000 - mae: 19483.2422 - val_loss: 4148616192.0000 - val_mae: 50135.8906\n",
      "Epoch 103/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 597657920.0000 - mae: 19097.9785 - val_loss: 4201306368.0000 - val_mae: 50592.1602\n",
      "Epoch 104/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 563868480.0000 - mae: 18637.6445 - val_loss: 4186624768.0000 - val_mae: 50421.0078\n",
      "Epoch 105/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 572764288.0000 - mae: 18629.2539 - val_loss: 4136363008.0000 - val_mae: 50015.6836\n",
      "Epoch 106/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 552442560.0000 - mae: 18364.5078 - val_loss: 4121713664.0000 - val_mae: 50037.5742\n",
      "Epoch 107/1000\n",
      "283/283 [==============================] - 2s 9ms/step - loss: 579308160.0000 - mae: 18820.6074 - val_loss: 4152486144.0000 - val_mae: 50097.8242\n",
      "Epoch 108/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 599902272.0000 - mae: 19110.9043 - val_loss: 4048860160.0000 - val_mae: 49648.4844\n",
      "Epoch 109/1000\n",
      "283/283 [==============================] - 2s 8ms/step - loss: 609874688.0000 - mae: 19370.8887 - val_loss: 3991298560.0000 - val_mae: 49392.8047\n",
      "Epoch 110/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 561172672.0000 - mae: 18555.5391 - val_loss: 4266368000.0000 - val_mae: 50571.5195\n",
      "Epoch 111/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 597556288.0000 - mae: 19136.9023 - val_loss: 4344281088.0000 - val_mae: 50927.0469\n",
      "Epoch 112/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 560736768.0000 - mae: 18554.3711 - val_loss: 4141602816.0000 - val_mae: 50023.9688\n",
      "Epoch 113/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 586219264.0000 - mae: 18939.2871 - val_loss: 3900940032.0000 - val_mae: 48923.4180\n",
      "Epoch 114/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 559911680.0000 - mae: 18499.0215 - val_loss: 4099181056.0000 - val_mae: 50019.3047\n",
      "Epoch 115/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 583092672.0000 - mae: 18962.2871 - val_loss: 3982051840.0000 - val_mae: 49196.4531\n",
      "Epoch 116/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 515833472.0000 - mae: 17820.6133 - val_loss: 4049616384.0000 - val_mae: 49797.7930\n",
      "Epoch 117/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 530654048.0000 - mae: 17985.9668 - val_loss: 3960022528.0000 - val_mae: 49343.5586\n",
      "Epoch 118/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 582232128.0000 - mae: 18863.1016 - val_loss: 3976524544.0000 - val_mae: 49322.8359\n",
      "Epoch 119/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 594175360.0000 - mae: 19038.2227 - val_loss: 4081855744.0000 - val_mae: 49983.0547\n",
      "Epoch 120/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 570206144.0000 - mae: 18644.9375 - val_loss: 4112508672.0000 - val_mae: 49991.8984\n",
      "Epoch 121/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 614862656.0000 - mae: 19613.8340 - val_loss: 4128598528.0000 - val_mae: 50147.0859\n",
      "Epoch 122/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 553451456.0000 - mae: 18304.8496 - val_loss: 4077067264.0000 - val_mae: 49618.1914\n",
      "Epoch 123/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 573440064.0000 - mae: 18768.3066 - val_loss: 4122121472.0000 - val_mae: 50082.8477\n",
      "Epoch 124/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 570977600.0000 - mae: 18616.5195 - val_loss: 4087872256.0000 - val_mae: 49872.2773\n",
      "Epoch 125/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 528414720.0000 - mae: 18199.6348 - val_loss: 4067245568.0000 - val_mae: 49709.8789\n",
      "Epoch 126/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 543687680.0000 - mae: 18264.5488 - val_loss: 4026828288.0000 - val_mae: 49629.0234\n",
      "Epoch 127/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 581590016.0000 - mae: 18883.4297 - val_loss: 4012971776.0000 - val_mae: 49396.6211\n",
      "Epoch 128/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 531794944.0000 - mae: 18113.8750 - val_loss: 4110148352.0000 - val_mae: 50024.1523\n",
      "Epoch 129/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 559385600.0000 - mae: 18656.4746 - val_loss: 4086090752.0000 - val_mae: 49916.3945\n",
      "Epoch 130/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 572020672.0000 - mae: 18633.4453 - val_loss: 3945797632.0000 - val_mae: 48796.2969\n",
      "Epoch 131/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 532413952.0000 - mae: 18055.4707 - val_loss: 4038198272.0000 - val_mae: 49134.4375\n",
      "Epoch 132/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 543325888.0000 - mae: 18231.4727 - val_loss: 3905120256.0000 - val_mae: 48585.9102\n",
      "Epoch 133/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 581771584.0000 - mae: 19029.0957 - val_loss: 3838614528.0000 - val_mae: 48395.6133\n",
      "Epoch 134/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 567318080.0000 - mae: 18700.1133 - val_loss: 4205404160.0000 - val_mae: 49865.6289\n",
      "Epoch 135/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 558264896.0000 - mae: 18614.5273 - val_loss: 4049773824.0000 - val_mae: 49066.9062\n",
      "Epoch 136/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 532203360.0000 - mae: 18108.3555 - val_loss: 4110970624.0000 - val_mae: 49401.2188\n",
      "Epoch 137/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 555314432.0000 - mae: 18526.1035 - val_loss: 4045003008.0000 - val_mae: 49167.1094\n",
      "Epoch 138/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 555623680.0000 - mae: 18460.1465 - val_loss: 3964486656.0000 - val_mae: 48851.5547\n",
      "Epoch 139/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 524788416.0000 - mae: 17979.5977 - val_loss: 3976293888.0000 - val_mae: 48723.4883\n",
      "Epoch 140/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 546034304.0000 - mae: 18239.8105 - val_loss: 4098579200.0000 - val_mae: 49487.8516\n",
      "Epoch 141/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 530293056.0000 - mae: 18052.5566 - val_loss: 3903471616.0000 - val_mae: 48518.6641\n",
      "Epoch 142/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 544081152.0000 - mae: 18157.6816 - val_loss: 3933655808.0000 - val_mae: 48670.8359\n",
      "Epoch 143/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 577856512.0000 - mae: 18834.0820 - val_loss: 3879664384.0000 - val_mae: 48499.7734\n",
      "Epoch 144/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 521024000.0000 - mae: 17763.0566 - val_loss: 3790151936.0000 - val_mae: 47877.2383\n",
      "Epoch 145/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 524703040.0000 - mae: 17899.0234 - val_loss: 3844985600.0000 - val_mae: 48162.9336\n",
      "Epoch 146/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 525785216.0000 - mae: 18060.2637 - val_loss: 3887229184.0000 - val_mae: 48388.6719\n",
      "Epoch 147/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 565674752.0000 - mae: 18612.0117 - val_loss: 3852348928.0000 - val_mae: 47862.4141\n",
      "Epoch 148/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 573015360.0000 - mae: 18828.3613 - val_loss: 3748957440.0000 - val_mae: 47628.4102\n",
      "Epoch 149/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 536915904.0000 - mae: 18233.6641 - val_loss: 3857783808.0000 - val_mae: 48199.4570\n",
      "Epoch 150/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 560967232.0000 - mae: 18448.3164 - val_loss: 3761904128.0000 - val_mae: 47577.8867\n",
      "Epoch 151/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 498807840.0000 - mae: 17639.0273 - val_loss: 3803386880.0000 - val_mae: 47730.4414\n",
      "Epoch 152/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 554992960.0000 - mae: 18457.4668 - val_loss: 3962784512.0000 - val_mae: 48766.5273\n",
      "Epoch 153/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 549531712.0000 - mae: 18377.1016 - val_loss: 3721121024.0000 - val_mae: 47260.2734\n",
      "Epoch 154/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 530275392.0000 - mae: 18078.7207 - val_loss: 3927885568.0000 - val_mae: 48342.1562\n",
      "Epoch 155/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 533019072.0000 - mae: 18160.0879 - val_loss: 3864908544.0000 - val_mae: 48119.0742\n",
      "Epoch 156/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 539001856.0000 - mae: 18188.3750 - val_loss: 4047859200.0000 - val_mae: 48935.7656\n",
      "Epoch 157/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 576932736.0000 - mae: 18981.8379 - val_loss: 3943517696.0000 - val_mae: 48530.8164\n",
      "Epoch 158/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 489771232.0000 - mae: 17363.5176 - val_loss: 3797675008.0000 - val_mae: 47501.1953\n",
      "Epoch 159/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 547577856.0000 - mae: 18452.0391 - val_loss: 3847497472.0000 - val_mae: 48071.6953\n",
      "Epoch 160/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 562347904.0000 - mae: 18552.6719 - val_loss: 3806199040.0000 - val_mae: 47804.6211\n",
      "Epoch 161/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 532402176.0000 - mae: 18075.6562 - val_loss: 3740310784.0000 - val_mae: 47435.7031\n",
      "Epoch 162/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 537162624.0000 - mae: 18133.4414 - val_loss: 3843605248.0000 - val_mae: 47765.0781\n",
      "Epoch 163/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 513784416.0000 - mae: 17728.0566 - val_loss: 3785365760.0000 - val_mae: 47521.2891\n",
      "Epoch 164/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 526983456.0000 - mae: 17961.9609 - val_loss: 4023414016.0000 - val_mae: 48532.1055\n",
      "Epoch 165/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 562777728.0000 - mae: 18468.2520 - val_loss: 3942393344.0000 - val_mae: 48040.8203\n",
      "Epoch 166/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 556917056.0000 - mae: 18506.9531 - val_loss: 3897874432.0000 - val_mae: 47869.1094\n",
      "Epoch 167/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 529478112.0000 - mae: 18098.5918 - val_loss: 4153103360.0000 - val_mae: 49020.4102\n",
      "Epoch 168/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 526969504.0000 - mae: 18014.5391 - val_loss: 4102432512.0000 - val_mae: 48766.7070\n",
      "Epoch 169/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 540022336.0000 - mae: 18288.2441 - val_loss: 3839188992.0000 - val_mae: 47490.0898\n",
      "Epoch 170/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 539508096.0000 - mae: 18154.4023 - val_loss: 3876715008.0000 - val_mae: 47935.5820\n",
      "Epoch 171/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 532324928.0000 - mae: 18010.3945 - val_loss: 3771144960.0000 - val_mae: 47374.9375\n",
      "Epoch 172/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 515866560.0000 - mae: 17895.7812 - val_loss: 3870888704.0000 - val_mae: 47832.3086\n",
      "Epoch 173/1000\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 531547520.0000 - mae: 18147.4355 - val_loss: 3970750208.0000 - val_mae: 48494.1602\n",
      "Minimum validation loss: 3721121024.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=[input_shape]),\n",
    "\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(1),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping], # put your callbacks in a list\n",
    "    # verbose=0,  # turn off training log\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step\n",
      "number of good predictions for Sequential = 1240\n",
      "which is 54.794520547945204%\n"
     ]
    }
   ],
   "source": [
    "error = NUM_OF_HOURS * 60 * 60\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.squeeze(predictions)\n",
    "predictions_time_diff = np.abs(y_test - predictions)\n",
    "num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "print(f'number of good predictions for {type(model).__name__} = {num_of_good_predictions}')\n",
    "print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
