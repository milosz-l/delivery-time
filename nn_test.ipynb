{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "# fact table\n",
    "sessions_df = pd.read_json(\"data/sessions.jsonl\", lines=True)\n",
    "\n",
    "# dimension tables\n",
    "deliveries_df = pd.read_json(\"data/deliveries.jsonl\", lines=True)\n",
    "products_df = pd.read_json(\"data/products.jsonl\", lines=True)\n",
    "users_df = pd.read_json(\"data/users.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_PLOTS = True\n",
    "MAKE_PAIRPLOT = True\n",
    "DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S\"\n",
    "PRICE_TRESHOLD = 100_000    # for outliers\n",
    "WEIGHT_TRESHOLD = 50        # for outliers\n",
    "NUM_OF_HOURS = 12\n",
    "SEED = 42\n",
    "SHOW_ALL_WARNINGS = False\n",
    "SHOW_ONLY_ONE_WARNING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "if SHOW_ONLY_ONE_WARNING:\n",
    "    warnings.filterwarnings(action='once')\n",
    "elif not SHOW_ALL_WARNINGS:\n",
    "    warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "deliveries_df[\"delivery_timestamp\"] = deliveries_df[\"delivery_timestamp\"].str.split('.', expand=True)[0]\n",
    "\n",
    "# 2.\n",
    "deliveries_df[\"purchase_timestamp\"] = pd.to_datetime(deliveries_df[\"purchase_timestamp\"], format=DATE_FORMAT)\n",
    "deliveries_df[\"delivery_timestamp\"] = pd.to_datetime(deliveries_df[\"delivery_timestamp\"], format=DATE_FORMAT)\n",
    "\n",
    "# 3.\n",
    "deliveries_df[\"time_diff\"] = deliveries_df[\"delivery_timestamp\"] - deliveries_df[\"purchase_timestamp\"]\n",
    "\n",
    "# 4.\n",
    "deliveries_df = deliveries_df[deliveries_df[\"time_diff\"].notna()]\n",
    "\n",
    "# 5.\n",
    "# time diff as duration in seconds\n",
    "deliveries_df[\"time_diff\"] = deliveries_df[\"time_diff\"].apply(datetime.timedelta.total_seconds)\n",
    "\n",
    "# 6.\n",
    "# deliveries_df = deliveries_df[deliveries_df[\"time_diff\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where event_type is not equal \"BUY_PRODUCT\"\n",
    "sessions_df = sessions_df[sessions_df[\"event_type\"] == \"BUY_PRODUCT\"]\n",
    "df = deliveries_df.merge(sessions_df, on=\"purchase_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure, that timestamp == purchase_timestamp\n",
    "num_of_rows_before = df.shape[0]\n",
    "df = df[df[\"timestamp\"] == df[\"purchase_timestamp\"]]\n",
    "num_of_rows_after = df.shape[0]\n",
    "\n",
    "assert(num_of_rows_before == num_of_rows_after)\n",
    "\n",
    "# now we can drop timestamp column, as it is redundant\n",
    "df = df.drop(columns=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(users_df, on=\"user_id\", how=\"left\")\n",
    "df = df.merge(products_df, on=\"product_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejecting outliers for given PRICE_TRESHOLD\n",
    "df = df[df[\"price\"] <= PRICE_TRESHOLD]\n",
    "\n",
    "# rejecting outliers for given WEIGHT_TRESHOLD\n",
    "df = df[df[\"weight_kg\"] <= WEIGHT_TRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting rows with prices below 0\n",
    "df = df[df[\"price\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_time_diff_below_0 = df\n",
    "df = df[df[\"time_diff\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['purchase_timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_and_street</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11447</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11448</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11315 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                city_and_street    city             street\n",
       "0      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "1      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "2      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "3      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "4      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "...                         ...     ...                ...\n",
       "11447   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11448   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11449   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11450   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11451   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "\n",
       "[11315 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['city_and_street'] = df['city'] + ' ' + df['street']\n",
    "display(df[['city_and_street', 'city', 'street']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['purchase_datetime_delta'] = (df['purchase_timestamp'] - df['purchase_timestamp'].min())  / np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "ADDITIONAL_COLUMNS_TO_DROP = [\"delivery_timestamp\",\n",
    "                              \"session_id\",\n",
    "                              \"purchase_id\",\n",
    "                              \"event_type\",\n",
    "                              \"name\",\n",
    "                              \"city_and_street\",\n",
    "                              \"brand\",\n",
    "                              \"user_id\",\n",
    "                              'product_name',\n",
    "                              'offered_discount']\n",
    "df = df.drop(columns=ADDITIONAL_COLUMNS_TO_DROP)\n",
    "df = df.drop(columns=\"optional_attributes\") # chyba do zmiany - wysokosc itp.\n",
    "df = df.drop(columns=\"purchase_timestamp\") # na pewno do zmiany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_a_col_in_pd(df, col_name):\n",
    "    one_hot = pd.get_dummies(df[col_name], drop_first=True)\n",
    "    df = df.drop(columns=col_name)\n",
    "    df = df.join(one_hot)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_ONE_HOT = [\"delivery_company\", \"city\", \"category_path\", \"street\", 'day_of_week', 'product_id']\n",
    "\n",
    "for col_name in COLUMNS_TO_ONE_HOT:\n",
    "    df = one_hot_encode_a_col_in_pd(df, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11315, 595)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# one-hot encoding took care of missing data, so shape has not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11315 entries, 0 to 11451\n",
      "Columns: 595 entries, time_diff to 1653\n",
      "dtypes: float64(4), uint8(591)\n",
      "memory usage: 7.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify columns for standardization scaling (Z-score normalization)\n",
    "cols_to_std = []\n",
    "\n",
    "# specify columns for min-max scaling\n",
    "# offered_discount, price, weight_kg, purchase_datetime_delta\n",
    "cols_to_min_max = ['price', 'weight_kg', 'purchase_datetime_delta']\n",
    "# cols_to_min_max = ['weight_kg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "for col in cols_to_std:\n",
    "    x = df[col].values\n",
    "    std_scaler = StandardScaler()\n",
    "    x_scaled = std_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    df[col] = x_scaled\n",
    "\n",
    "for col in cols_to_min_max:\n",
    "    x = df[col].values\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    df[col] = x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_diff</th>\n",
       "      <th>price</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>purchase_datetime_delta</th>\n",
       "      <th>516</th>\n",
       "      <th>620</th>\n",
       "      <th>Kraków</th>\n",
       "      <th>Poznań</th>\n",
       "      <th>Radom</th>\n",
       "      <th>Szczecin</th>\n",
       "      <th>...</th>\n",
       "      <th>1627</th>\n",
       "      <th>1628</th>\n",
       "      <th>1629</th>\n",
       "      <th>1630</th>\n",
       "      <th>1631</th>\n",
       "      <th>1632</th>\n",
       "      <th>1633</th>\n",
       "      <th>1634</th>\n",
       "      <th>1635</th>\n",
       "      <th>1653</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194397.0</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.459215</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184285.0</td>\n",
       "      <td>0.406238</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.191245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164705.0</td>\n",
       "      <td>0.665416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>252885.0</td>\n",
       "      <td>0.448400</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.822722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228672.0</td>\n",
       "      <td>0.032173</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.343154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 595 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_diff     price  weight_kg  purchase_datetime_delta  516  620  Kraków  \\\n",
       "0   194397.0  0.228930   0.020000                 0.459215    0    1       0   \n",
       "1   184285.0  0.406238   0.000800                 0.191245    0    1       0   \n",
       "2   164705.0  0.665416   0.000000                 0.082285    0    0       0   \n",
       "3   252885.0  0.448400   0.010667                 0.822722    0    1       0   \n",
       "4   228672.0  0.032173   0.008667                 0.343154    1    0       0   \n",
       "\n",
       "   Poznań  Radom  Szczecin  ...  1627  1628  1629  1630  1631  1632  1633  \\\n",
       "0       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "1       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "2       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "3       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "4       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "\n",
       "   1634  1635  1653  \n",
       "0     0     0     0  \n",
       "1     0     0     0  \n",
       "2     0     0     0  \n",
       "3     0     0     0  \n",
       "4     0     0     0  \n",
       "\n",
       "[5 rows x 595 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def split_data(df, target_column=\"time_diff\"):\n",
    "    y = df[\"time_diff\"].to_numpy()\n",
    "    X = df.drop(columns=\"time_diff\")\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(models_list, X_train, y_train):\n",
    "    for model in models_list:\n",
    "        model.fit(X_train, y_train)\n",
    "    return models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_predictions(models_list, X_test, y_test):\n",
    "    y_pred_df = pd.DataFrame()\n",
    "    y_pred_df[\"y_test\"] = y_test\n",
    "    for model in models_list:\n",
    "        y_pred_df[f\"{type(model).__name__} prediction\"] = model.predict(X_test)\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(y_pred_df):\n",
    "    display(y_pred_df.head())\n",
    "    display(y_pred_df.info())\n",
    "    display(y_pred_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(models_list, X_test, y_test):\n",
    "    for model in models_list:\n",
    "        score = model.score(X_test, y_test)\n",
    "        print(f\"{type(model).__name__} score = {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percent_of_good_predictions(models_list, X_test, y_test, error=NUM_OF_HOURS*60*60):\n",
    "    for model in models_list:\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions_time_diff = np.abs(y_test - predictions)\n",
    "        num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "        percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "        print(f'number of good predictions for {type(model).__name__} = {num_of_good_predictions}')\n",
    "        print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# models_list = [Ridge(alpha=0.1),\n",
    "#                Lasso(alpha=0.1),\n",
    "#                DecisionTreeRegressor(random_state=SEED),\n",
    "#                RandomForestRegressor(random_state=SEED)]\n",
    "# models_list = train_models(models_list, X_train, y_train)\n",
    "\n",
    "# y_pred_df = create_df_with_predictions(models_list, X_test, y_test)\n",
    "# # display_predictions(y_pred_df)\n",
    "\n",
    "# print_scores(models_list, X_test, y_test)\n",
    "\n",
    "# print_percent_of_good_predictions(models_list, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 2s 29ms/step - loss: 61319053312.0000 - mae: 233531.7656 - val_loss: 59746222080.0000 - val_mae: 231077.1406\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 61313413120.0000 - mae: 233529.2344 - val_loss: 59744432128.0000 - val_mae: 231078.6406\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 61306777600.0000 - mae: 233524.0156 - val_loss: 59742126080.0000 - val_mae: 231080.5000\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 61298597888.0000 - mae: 233516.0000 - val_loss: 59735076864.0000 - val_mae: 231073.7969\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 61288337408.0000 - mae: 233505.1250 - val_loss: 59722719232.0000 - val_mae: 231058.1719\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 61275811840.0000 - mae: 233490.9844 - val_loss: 59700154368.0000 - val_mae: 231021.0156\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 61261443072.0000 - mae: 233473.9688 - val_loss: 59682062336.0000 - val_mae: 230994.0469\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 61244858368.0000 - mae: 233453.4688 - val_loss: 59666550784.0000 - val_mae: 230972.5625\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 61226160128.0000 - mae: 233429.8281 - val_loss: 59650551808.0000 - val_mae: 230950.0469\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 61205479424.0000 - mae: 233403.0781 - val_loss: 59620663296.0000 - val_mae: 230898.6719\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 61182717952.0000 - mae: 233372.9375 - val_loss: 59592224768.0000 - val_mae: 230850.7656\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 61157965824.0000 - mae: 233339.4844 - val_loss: 59580280832.0000 - val_mae: 230843.1562\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 61131321344.0000 - mae: 233303.7188 - val_loss: 59564814336.0000 - val_mae: 230829.8750\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 61102469120.0000 - mae: 233263.7031 - val_loss: 59557715968.0000 - val_mae: 230837.7969\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 61071572992.0000 - mae: 233221.0469 - val_loss: 59539628032.0000 - val_mae: 230819.6250\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 61038186496.0000 - mae: 233174.6406 - val_loss: 59519488000.0000 - val_mae: 230800.8750\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 61003264000.0000 - mae: 233125.9219 - val_loss: 59500724224.0000 - val_mae: 230774.2812\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 60966113280.0000 - mae: 233073.7656 - val_loss: 59434049536.0000 - val_mae: 230667.2344\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 60927307776.0000 - mae: 233018.3594 - val_loss: 59396403200.0000 - val_mae: 230612.2188\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 60886728704.0000 - mae: 232960.6562 - val_loss: 59376111616.0000 - val_mae: 230598.4062\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 60843982848.0000 - mae: 232899.2031 - val_loss: 59293237248.0000 - val_mae: 230446.3281\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 60799246336.0000 - mae: 232834.6875 - val_loss: 59282137088.0000 - val_mae: 230440.7969\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 60752715776.0000 - mae: 232767.6250 - val_loss: 59288645632.0000 - val_mae: 230477.1562\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 60705464320.0000 - mae: 232698.6875 - val_loss: 59199672320.0000 - val_mae: 230319.7031\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 60654391296.0000 - mae: 232624.2969 - val_loss: 59200397312.0000 - val_mae: 230354.7500\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 60603047936.0000 - mae: 232549.8750 - val_loss: 59123396608.0000 - val_mae: 230213.4375\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 60550291456.0000 - mae: 232471.8906 - val_loss: 59067412480.0000 - val_mae: 230121.0938\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 60495982592.0000 - mae: 232391.0312 - val_loss: 59044179968.0000 - val_mae: 230099.9531\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 60436869120.0000 - mae: 232303.7812 - val_loss: 58987151360.0000 - val_mae: 230004.6562\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 60381016064.0000 - mae: 232220.4375 - val_loss: 58890375168.0000 - val_mae: 229836.0469\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 60321603584.0000 - mae: 232131.0938 - val_loss: 58886778880.0000 - val_mae: 229845.6719\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 60259893248.0000 - mae: 232038.5469 - val_loss: 58803568640.0000 - val_mae: 229696.8594\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 60197543936.0000 - mae: 231944.0938 - val_loss: 58746408960.0000 - val_mae: 229616.2656\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 60133199872.0000 - mae: 231847.9531 - val_loss: 58660507648.0000 - val_mae: 229442.9531\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 60068880384.0000 - mae: 231748.5625 - val_loss: 58585604096.0000 - val_mae: 229331.2188\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 60000768000.0000 - mae: 231645.7500 - val_loss: 58537078784.0000 - val_mae: 229253.4375\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 59933507584.0000 - mae: 231542.3281 - val_loss: 58430500864.0000 - val_mae: 229047.2969\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 59863412736.0000 - mae: 231436.5000 - val_loss: 58349146112.0000 - val_mae: 228914.5000\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 1s 42ms/step - loss: 59792302080.0000 - mae: 231327.8125 - val_loss: 58398724096.0000 - val_mae: 229034.4531\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 59720478720.0000 - mae: 231215.8438 - val_loss: 58208350208.0000 - val_mae: 228693.8281\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 59648847872.0000 - mae: 231104.7188 - val_loss: 58170331136.0000 - val_mae: 228625.5469\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 59570728960.0000 - mae: 230984.9219 - val_loss: 58101493760.0000 - val_mae: 228512.4219\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 59494195200.0000 - mae: 230867.5625 - val_loss: 58018652160.0000 - val_mae: 228362.1562\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 59414519808.0000 - mae: 230744.3281 - val_loss: 57974145024.0000 - val_mae: 228328.5156\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 59336232960.0000 - mae: 230622.2969 - val_loss: 57868722176.0000 - val_mae: 228121.1406\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 59258368000.0000 - mae: 230499.3906 - val_loss: 57773240320.0000 - val_mae: 227963.7812\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 59173015552.0000 - mae: 230369.2812 - val_loss: 57772621824.0000 - val_mae: 227987.7031\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 59091714048.0000 - mae: 230240.2812 - val_loss: 57656999936.0000 - val_mae: 227778.9688\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 59005165568.0000 - mae: 230105.9688 - val_loss: 57561952256.0000 - val_mae: 227613.7500\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 58926022656.0000 - mae: 229980.0625 - val_loss: 57508970496.0000 - val_mae: 227529.5938\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 58837831680.0000 - mae: 229841.7188 - val_loss: 57423429632.0000 - val_mae: 227386.4062\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 58748493824.0000 - mae: 229702.0312 - val_loss: 57345421312.0000 - val_mae: 227231.0625\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 58657898496.0000 - mae: 229559.1250 - val_loss: 57220313088.0000 - val_mae: 226986.1406\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 58569424896.0000 - mae: 229419.6406 - val_loss: 57189359616.0000 - val_mae: 226990.3125\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 58476453888.0000 - mae: 229273.2812 - val_loss: 57055485952.0000 - val_mae: 226722.3906\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 58385424384.0000 - mae: 229128.4375 - val_loss: 57020153856.0000 - val_mae: 226715.4062\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 58294562816.0000 - mae: 228981.2969 - val_loss: 56878096384.0000 - val_mae: 226405.6719\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 58198097920.0000 - mae: 228826.5156 - val_loss: 56858562560.0000 - val_mae: 226447.7812\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 58104868864.0000 - mae: 228680.1250 - val_loss: 56718290944.0000 - val_mae: 226171.3438\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 58006745088.0000 - mae: 228524.1875 - val_loss: 56627105792.0000 - val_mae: 226064.5469\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 57911537664.0000 - mae: 228371.0625 - val_loss: 56545787904.0000 - val_mae: 225899.6875\n",
      "Epoch 62/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 57809465344.0000 - mae: 228205.8281 - val_loss: 56534339584.0000 - val_mae: 225856.4375\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 57710845952.0000 - mae: 228048.0312 - val_loss: 56366829568.0000 - val_mae: 225586.1719\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 57606254592.0000 - mae: 227880.2812 - val_loss: 56177119232.0000 - val_mae: 225199.1094\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 57505480704.0000 - mae: 227718.6250 - val_loss: 56271380480.0000 - val_mae: 225454.2500\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 57404301312.0000 - mae: 227555.4688 - val_loss: 56062984192.0000 - val_mae: 225047.0938\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 57298345984.0000 - mae: 227383.8594 - val_loss: 56053379072.0000 - val_mae: 225056.3281\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 57193197568.0000 - mae: 227212.5781 - val_loss: 55992176640.0000 - val_mae: 224935.4531\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 57095454720.0000 - mae: 227051.5312 - val_loss: 55846506496.0000 - val_mae: 224666.5625\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 56985653248.0000 - mae: 226874.3438 - val_loss: 55720153088.0000 - val_mae: 224425.5938\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 56879017984.0000 - mae: 226700.2344 - val_loss: 55659003904.0000 - val_mae: 224381.9219\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 56768675840.0000 - mae: 226521.2656 - val_loss: 55427420160.0000 - val_mae: 223901.4688\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 56659963904.0000 - mae: 226344.5312 - val_loss: 55340961792.0000 - val_mae: 223765.2812\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 56550309888.0000 - mae: 226165.5625 - val_loss: 55361761280.0000 - val_mae: 223842.4219\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 56438988800.0000 - mae: 225979.9375 - val_loss: 55161520128.0000 - val_mae: 223441.1406\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 56324370432.0000 - mae: 225795.2656 - val_loss: 55221084160.0000 - val_mae: 223589.7031\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 56213868544.0000 - mae: 225611.8906 - val_loss: 55021813760.0000 - val_mae: 223256.7969\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 56099753984.0000 - mae: 225423.8125 - val_loss: 54914490368.0000 - val_mae: 223031.8906\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 55986855936.0000 - mae: 225236.1875 - val_loss: 54617702400.0000 - val_mae: 222433.6719\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 55866130432.0000 - mae: 225034.6562 - val_loss: 54649040896.0000 - val_mae: 222546.6406\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 55753625600.0000 - mae: 224848.5625 - val_loss: 54551109632.0000 - val_mae: 222372.1875\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 55634784256.0000 - mae: 224652.8438 - val_loss: 54492241920.0000 - val_mae: 222285.7500\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 55523905536.0000 - mae: 224463.1094 - val_loss: 54377418752.0000 - val_mae: 222116.5625\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 55404630016.0000 - mae: 224267.3125 - val_loss: 54469451776.0000 - val_mae: 222314.1094\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 55284301824.0000 - mae: 224068.8906 - val_loss: 54398668800.0000 - val_mae: 222202.5781\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 55157567488.0000 - mae: 223857.0625 - val_loss: 53894496256.0000 - val_mae: 221183.6250\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 55043895296.0000 - mae: 223660.7188 - val_loss: 53865656320.0000 - val_mae: 221145.7188\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 54924947456.0000 - mae: 223466.5000 - val_loss: 53777428480.0000 - val_mae: 220954.0156\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 54799704064.0000 - mae: 223253.0312 - val_loss: 53836226560.0000 - val_mae: 221188.0781\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 54677745664.0000 - mae: 223049.2969 - val_loss: 53393260544.0000 - val_mae: 220234.1250\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 54558961664.0000 - mae: 222840.3281 - val_loss: 53493432320.0000 - val_mae: 220487.0312\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 54426210304.0000 - mae: 222628.3594 - val_loss: 53347540992.0000 - val_mae: 220215.4531\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 54302273536.0000 - mae: 222414.9844 - val_loss: 53293670400.0000 - val_mae: 220103.7812\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 54176624640.0000 - mae: 222199.1719 - val_loss: 53164101632.0000 - val_mae: 219894.7812\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 54050336768.0000 - mae: 221981.6094 - val_loss: 53017436160.0000 - val_mae: 219613.0938\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 53919555584.0000 - mae: 221763.8594 - val_loss: 52745031680.0000 - val_mae: 219042.8906\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 53798973440.0000 - mae: 221550.0156 - val_loss: 52709801984.0000 - val_mae: 219003.8906\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 53669212160.0000 - mae: 221331.0781 - val_loss: 52811341824.0000 - val_mae: 219347.5469\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 53536903168.0000 - mae: 221106.4844 - val_loss: 52657201152.0000 - val_mae: 218972.7500\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 53410492416.0000 - mae: 220893.2656 - val_loss: 52582350848.0000 - val_mae: 218908.3281\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 53275226112.0000 - mae: 220658.7188 - val_loss: 52276187136.0000 - val_mae: 218244.8438\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 53151973376.0000 - mae: 220437.3906 - val_loss: 52088926208.0000 - val_mae: 217960.9375\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 53020246016.0000 - mae: 220217.6094 - val_loss: 52038467584.0000 - val_mae: 217827.7812\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 52885475328.0000 - mae: 219984.3281 - val_loss: 51890601984.0000 - val_mae: 217538.3281\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 52752654336.0000 - mae: 219752.5156 - val_loss: 51728031744.0000 - val_mae: 217175.5938\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 52611665920.0000 - mae: 219507.4219 - val_loss: 51807105024.0000 - val_mae: 217535.1719\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 52478795776.0000 - mae: 219272.1406 - val_loss: 51530301440.0000 - val_mae: 216954.3750\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 52344823808.0000 - mae: 219044.6562 - val_loss: 51313291264.0000 - val_mae: 216441.1562\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 52215070720.0000 - mae: 218812.1406 - val_loss: 51349504000.0000 - val_mae: 216556.0938\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 52078686208.0000 - mae: 218579.5781 - val_loss: 51205623808.0000 - val_mae: 216238.7344\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 51940556800.0000 - mae: 218330.0781 - val_loss: 51172167680.0000 - val_mae: 216166.6250\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 51801690112.0000 - mae: 218084.8438 - val_loss: 51097829376.0000 - val_mae: 216129.7969\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 51667341312.0000 - mae: 217853.9062 - val_loss: 50873532416.0000 - val_mae: 215647.2812\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 51530846208.0000 - mae: 217611.0625 - val_loss: 50641043456.0000 - val_mae: 215082.2344\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 51381002240.0000 - mae: 217346.4531 - val_loss: 50487889920.0000 - val_mae: 214893.7344\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 51256815616.0000 - mae: 217123.0312 - val_loss: 50466553856.0000 - val_mae: 214858.9375\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 51107553280.0000 - mae: 216862.1094 - val_loss: 50245033984.0000 - val_mae: 214399.7969\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 50968514560.0000 - mae: 216613.5000 - val_loss: 50177343488.0000 - val_mae: 214293.1562\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 1s 42ms/step - loss: 50826289152.0000 - mae: 216356.8125 - val_loss: 50072231936.0000 - val_mae: 214093.1875\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 50698813440.0000 - mae: 216128.6875 - val_loss: 49845018624.0000 - val_mae: 213652.7500\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 50550595584.0000 - mae: 215863.9844 - val_loss: 49786949632.0000 - val_mae: 213582.4844\n",
      "Epoch 122/500\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 50404278272.0000 - mae: 215606.7812 - val_loss: 49598541824.0000 - val_mae: 213239.6406\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 50260832256.0000 - mae: 215341.4531 - val_loss: 49251065856.0000 - val_mae: 212408.8594\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 50109747200.0000 - mae: 215081.8906 - val_loss: 49405210624.0000 - val_mae: 212785.4844\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 49979826176.0000 - mae: 214835.8594 - val_loss: 49466793984.0000 - val_mae: 212978.0312\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 49826430976.0000 - mae: 214564.7031 - val_loss: 49123041280.0000 - val_mae: 212322.7344\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 49687994368.0000 - mae: 214306.6562 - val_loss: 49066246144.0000 - val_mae: 212220.5000\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 49542123520.0000 - mae: 214047.7500 - val_loss: 48984477696.0000 - val_mae: 212015.4375\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 49402654720.0000 - mae: 213795.8125 - val_loss: 48534224896.0000 - val_mae: 211121.2031\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 49248944128.0000 - mae: 213517.9531 - val_loss: 48753156096.0000 - val_mae: 211570.7969\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 49105678336.0000 - mae: 213248.3906 - val_loss: 48188960768.0000 - val_mae: 210333.8438\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 48954601472.0000 - mae: 212979.1875 - val_loss: 48521490432.0000 - val_mae: 211132.2031\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 48806092800.0000 - mae: 212700.5938 - val_loss: 48073043968.0000 - val_mae: 210097.7812\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 48662093824.0000 - mae: 212431.4844 - val_loss: 48015335424.0000 - val_mae: 210021.2969\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 48506925056.0000 - mae: 212149.0312 - val_loss: 47913717760.0000 - val_mae: 209861.4531\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 48358604800.0000 - mae: 211871.6094 - val_loss: 48079253504.0000 - val_mae: 210282.8438\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 48223789056.0000 - mae: 211611.1719 - val_loss: 47709036544.0000 - val_mae: 209505.5625\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 48073629696.0000 - mae: 211334.5469 - val_loss: 47281721344.0000 - val_mae: 208576.2344\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 47919935488.0000 - mae: 211045.9062 - val_loss: 47386374144.0000 - val_mae: 208807.4688\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 47763906560.0000 - mae: 210765.9219 - val_loss: 47237353472.0000 - val_mae: 208619.9062\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 47609896960.0000 - mae: 210473.8125 - val_loss: 46913945600.0000 - val_mae: 207780.1719\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 47468720128.0000 - mae: 210218.2656 - val_loss: 47138062336.0000 - val_mae: 208431.6562\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 47325003776.0000 - mae: 209933.1875 - val_loss: 46247444480.0000 - val_mae: 206351.2031\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 47162462208.0000 - mae: 209631.0000 - val_loss: 46702972928.0000 - val_mae: 207434.6406\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 47009120256.0000 - mae: 209343.4375 - val_loss: 46236516352.0000 - val_mae: 206429.4688\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 46860861440.0000 - mae: 209056.7188 - val_loss: 46325903360.0000 - val_mae: 206646.0156\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 46708396032.0000 - mae: 208770.9531 - val_loss: 46170591232.0000 - val_mae: 206375.7500\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 46561484800.0000 - mae: 208484.4531 - val_loss: 45916495872.0000 - val_mae: 205827.7344\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 46411735040.0000 - mae: 208209.8750 - val_loss: 46295191552.0000 - val_mae: 206683.8750\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 46231822336.0000 - mae: 207870.0469 - val_loss: 45712211968.0000 - val_mae: 205500.5156\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 46096637952.0000 - mae: 207598.8906 - val_loss: 45376991232.0000 - val_mae: 204631.1562\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 45952098304.0000 - mae: 207310.2812 - val_loss: 45439688704.0000 - val_mae: 204874.3281\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 45785559040.0000 - mae: 207000.3281 - val_loss: 45286031360.0000 - val_mae: 204514.3906\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 45628194816.0000 - mae: 206692.2344 - val_loss: 45294010368.0000 - val_mae: 204537.7969\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 45479047168.0000 - mae: 206406.8906 - val_loss: 44839710720.0000 - val_mae: 203541.1562\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 45323145216.0000 - mae: 206094.2031 - val_loss: 45019246592.0000 - val_mae: 203988.7656\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 45173272576.0000 - mae: 205814.7188 - val_loss: 45043294208.0000 - val_mae: 204152.9688\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 45011668992.0000 - mae: 205497.4844 - val_loss: 44855541760.0000 - val_mae: 203663.5469\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 44853829632.0000 - mae: 205191.1094 - val_loss: 44499947520.0000 - val_mae: 202801.3281\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 44713164800.0000 - mae: 204904.1094 - val_loss: 44416552960.0000 - val_mae: 202750.2188\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 44546179072.0000 - mae: 204573.5469 - val_loss: 44031688704.0000 - val_mae: 201890.0469\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 44388745216.0000 - mae: 204273.8125 - val_loss: 44075307008.0000 - val_mae: 201923.9688\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 44230107136.0000 - mae: 203965.7344 - val_loss: 43895009280.0000 - val_mae: 201681.8906\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 44076736512.0000 - mae: 203651.9844 - val_loss: 43472588800.0000 - val_mae: 200715.0312\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 43921682432.0000 - mae: 203347.7969 - val_loss: 43776315392.0000 - val_mae: 201389.9062\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 43756724224.0000 - mae: 203019.7031 - val_loss: 43730935808.0000 - val_mae: 201208.4844\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 43609153536.0000 - mae: 202716.9531 - val_loss: 43359027200.0000 - val_mae: 200487.4531\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 43436371968.0000 - mae: 202376.6562 - val_loss: 42636550144.0000 - val_mae: 198810.3594\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 43287887872.0000 - mae: 202073.4531 - val_loss: 42994225152.0000 - val_mae: 199678.2812\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 43142901760.0000 - mae: 201787.9219 - val_loss: 42820141056.0000 - val_mae: 199193.1719\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 42970161152.0000 - mae: 201430.2656 - val_loss: 42956111872.0000 - val_mae: 199531.5000\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 42805604352.0000 - mae: 201094.7656 - val_loss: 43212787712.0000 - val_mae: 200262.2188\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 42652385280.0000 - mae: 200785.5000 - val_loss: 42278428672.0000 - val_mae: 198128.2344\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 42499497984.0000 - mae: 200459.5469 - val_loss: 42409791488.0000 - val_mae: 198318.1406\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 42357542912.0000 - mae: 200164.6719 - val_loss: 42180247552.0000 - val_mae: 197868.1094\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 42172141568.0000 - mae: 199801.3750 - val_loss: 42081882112.0000 - val_mae: 197589.2656\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 42028511232.0000 - mae: 199502.5469 - val_loss: 41845538816.0000 - val_mae: 197008.4531\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 41864372224.0000 - mae: 199170.3281 - val_loss: 41719455744.0000 - val_mae: 196728.9688\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 41699770368.0000 - mae: 198832.2500 - val_loss: 41575075840.0000 - val_mae: 196411.1875\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 41535188992.0000 - mae: 198485.2500 - val_loss: 41515196416.0000 - val_mae: 196311.5000\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 41360723968.0000 - mae: 198131.5312 - val_loss: 41320722432.0000 - val_mae: 195914.0938\n",
      "Epoch 182/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 41246359552.0000 - mae: 197876.3750 - val_loss: 41261539328.0000 - val_mae: 195788.9219\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 41042984960.0000 - mae: 197466.5625 - val_loss: 40825999360.0000 - val_mae: 194799.2031\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 40900476928.0000 - mae: 197153.0000 - val_loss: 40552775680.0000 - val_mae: 194043.2188\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 40745422848.0000 - mae: 196833.8750 - val_loss: 40717983744.0000 - val_mae: 194579.4844\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 40592551936.0000 - mae: 196501.5312 - val_loss: 40834220032.0000 - val_mae: 194875.5781\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 40425717760.0000 - mae: 196143.9531 - val_loss: 40824352768.0000 - val_mae: 194901.8594\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 40267472896.0000 - mae: 195819.1875 - val_loss: 39911567360.0000 - val_mae: 192641.1562\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 40103682048.0000 - mae: 195469.6250 - val_loss: 40052629504.0000 - val_mae: 192933.3594\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 39928586240.0000 - mae: 195098.9062 - val_loss: 40154570752.0000 - val_mae: 193345.1250\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 39783211008.0000 - mae: 194780.7344 - val_loss: 39635955712.0000 - val_mae: 191980.1250\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 39619833856.0000 - mae: 194439.8906 - val_loss: 39877750784.0000 - val_mae: 192561.7031\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 39465594880.0000 - mae: 194103.7656 - val_loss: 39572549632.0000 - val_mae: 191707.4844\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 39295078400.0000 - mae: 193730.2344 - val_loss: 39287435264.0000 - val_mae: 191077.6406\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 39119699968.0000 - mae: 193356.0625 - val_loss: 39319068672.0000 - val_mae: 191329.4219\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 38982746112.0000 - mae: 193056.0781 - val_loss: 39119773696.0000 - val_mae: 190789.2500\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 38800003072.0000 - mae: 192655.7031 - val_loss: 39001624576.0000 - val_mae: 190511.5469\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 38631735296.0000 - mae: 192302.9688 - val_loss: 38541578240.0000 - val_mae: 189311.6094\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 38483267584.0000 - mae: 191963.8281 - val_loss: 38856609792.0000 - val_mae: 190144.8125\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 38334304256.0000 - mae: 191636.2188 - val_loss: 38511509504.0000 - val_mae: 189332.4375\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 38180474880.0000 - mae: 191288.5469 - val_loss: 38536433664.0000 - val_mae: 189427.2656\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 38015819776.0000 - mae: 190898.0938 - val_loss: 38567104512.0000 - val_mae: 189588.0156\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 37841600512.0000 - mae: 190549.0781 - val_loss: 38086918144.0000 - val_mae: 188287.7500\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 37687209984.0000 - mae: 190189.3750 - val_loss: 37747322880.0000 - val_mae: 187351.4688\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 37502922752.0000 - mae: 189779.4531 - val_loss: 37870456832.0000 - val_mae: 187767.0000\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 37371215872.0000 - mae: 189465.5156 - val_loss: 37804580864.0000 - val_mae: 187583.6875\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 37195419648.0000 - mae: 189085.0781 - val_loss: 36800053248.0000 - val_mae: 185028.5469\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 37036298240.0000 - mae: 188736.3750 - val_loss: 36730642432.0000 - val_mae: 184820.0781\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 36866813952.0000 - mae: 188353.5625 - val_loss: 37196353536.0000 - val_mae: 186090.3594\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 36702720000.0000 - mae: 187974.0469 - val_loss: 36974465024.0000 - val_mae: 185433.4844\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 36554571776.0000 - mae: 187618.8906 - val_loss: 36863074304.0000 - val_mae: 185354.6094\n",
      "Epoch 212/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 36391739392.0000 - mae: 187264.4844 - val_loss: 36685467648.0000 - val_mae: 184803.8125\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 36223283200.0000 - mae: 186856.6250 - val_loss: 36526034944.0000 - val_mae: 184480.9219\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 36060950528.0000 - mae: 186497.3906 - val_loss: 36060999680.0000 - val_mae: 183131.1094\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 35903414272.0000 - mae: 186126.0625 - val_loss: 36552421376.0000 - val_mae: 184562.3125\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 35724906496.0000 - mae: 185749.0938 - val_loss: 36534669312.0000 - val_mae: 184505.0000\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 35563081728.0000 - mae: 185357.9219 - val_loss: 35635826688.0000 - val_mae: 182050.5625\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 35416686592.0000 - mae: 184999.1406 - val_loss: 35685404672.0000 - val_mae: 182170.0156\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 35267575808.0000 - mae: 184645.1719 - val_loss: 35369705472.0000 - val_mae: 181374.7188\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 35106238464.0000 - mae: 184257.2500 - val_loss: 35518349312.0000 - val_mae: 181777.3906\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 34926813184.0000 - mae: 183867.2656 - val_loss: 35932712960.0000 - val_mae: 182887.1406\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 34764976128.0000 - mae: 183465.1250 - val_loss: 35200688128.0000 - val_mae: 180922.8281\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 34615050240.0000 - mae: 183098.4688 - val_loss: 35490029568.0000 - val_mae: 181701.0469\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 34475462656.0000 - mae: 182773.8906 - val_loss: 35448926208.0000 - val_mae: 181701.5938\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 34303612928.0000 - mae: 182336.0156 - val_loss: 35231850496.0000 - val_mae: 181077.0469\n",
      "Epoch 226/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 34169522176.0000 - mae: 182017.8750 - val_loss: 34786992128.0000 - val_mae: 179876.4375\n",
      "Epoch 227/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 33982814208.0000 - mae: 181559.6875 - val_loss: 34249363456.0000 - val_mae: 178428.5781\n",
      "Epoch 228/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 33802004480.0000 - mae: 181161.1875 - val_loss: 34327040000.0000 - val_mae: 178644.7656\n",
      "Epoch 229/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 33676105728.0000 - mae: 180818.9219 - val_loss: 34318006272.0000 - val_mae: 178641.1250\n",
      "Epoch 230/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 33482416128.0000 - mae: 180347.1406 - val_loss: 33664958464.0000 - val_mae: 176769.9219\n",
      "Epoch 231/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 33340442624.0000 - mae: 180026.6406 - val_loss: 33600827392.0000 - val_mae: 176683.7656\n",
      "Epoch 232/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 33193570304.0000 - mae: 179643.2344 - val_loss: 34313891840.0000 - val_mae: 178646.3281\n",
      "Epoch 233/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 33009424384.0000 - mae: 179184.5312 - val_loss: 33379772416.0000 - val_mae: 176060.3750\n",
      "Epoch 234/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 32863440896.0000 - mae: 178805.6875 - val_loss: 33354602496.0000 - val_mae: 175986.0781\n",
      "Epoch 235/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 32720615424.0000 - mae: 178453.3750 - val_loss: 33044799488.0000 - val_mae: 175143.7656\n",
      "Epoch 236/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 32545660928.0000 - mae: 178035.5000 - val_loss: 33689546752.0000 - val_mae: 176931.0469\n",
      "Epoch 237/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 32388026368.0000 - mae: 177641.7500 - val_loss: 33264285696.0000 - val_mae: 175753.1094\n",
      "Epoch 238/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 32217124864.0000 - mae: 177227.4531 - val_loss: 32818247680.0000 - val_mae: 174514.7344\n",
      "Epoch 239/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 32051730432.0000 - mae: 176820.5781 - val_loss: 32842424320.0000 - val_mae: 174503.9219\n",
      "Epoch 240/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 31886919680.0000 - mae: 176357.2344 - val_loss: 32581912576.0000 - val_mae: 173773.7969\n",
      "Epoch 241/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 31753934848.0000 - mae: 176020.2500 - val_loss: 32692254720.0000 - val_mae: 174133.4219\n",
      "Epoch 242/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 31595479040.0000 - mae: 175649.9219 - val_loss: 32239374336.0000 - val_mae: 172782.2188\n",
      "Epoch 243/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 31439861760.0000 - mae: 175243.2812 - val_loss: 32407402496.0000 - val_mae: 173297.9688\n",
      "Epoch 244/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 31271413760.0000 - mae: 174819.2031 - val_loss: 31769360384.0000 - val_mae: 171520.7812\n",
      "Epoch 245/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 31118544896.0000 - mae: 174383.1094 - val_loss: 32304871424.0000 - val_mae: 173049.1250\n",
      "Epoch 246/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 30945378304.0000 - mae: 173938.4219 - val_loss: 31795642368.0000 - val_mae: 171569.9375\n",
      "Epoch 247/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 30794256384.0000 - mae: 173570.9219 - val_loss: 31503900672.0000 - val_mae: 170725.2344\n",
      "Epoch 248/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 30655918080.0000 - mae: 173216.8594 - val_loss: 31688568832.0000 - val_mae: 171284.8594\n",
      "Epoch 249/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 30495807488.0000 - mae: 172772.7188 - val_loss: 31478327296.0000 - val_mae: 170671.4531\n",
      "Epoch 250/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 30344163328.0000 - mae: 172369.5781 - val_loss: 31259779072.0000 - val_mae: 170044.3438\n",
      "Epoch 251/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 30195777536.0000 - mae: 171970.5781 - val_loss: 30860431360.0000 - val_mae: 168834.0938\n",
      "Epoch 252/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 30038925312.0000 - mae: 171550.9375 - val_loss: 30626922496.0000 - val_mae: 168161.7656\n",
      "Epoch 253/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 29866950656.0000 - mae: 171128.2188 - val_loss: 31214878720.0000 - val_mae: 169904.7812\n",
      "Epoch 254/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 29737033728.0000 - mae: 170711.2969 - val_loss: 30579482624.0000 - val_mae: 168032.3906\n",
      "Epoch 255/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 29560934400.0000 - mae: 170273.5938 - val_loss: 30365351936.0000 - val_mae: 167353.7188\n",
      "Epoch 256/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 29400713216.0000 - mae: 169863.8438 - val_loss: 30304831488.0000 - val_mae: 167178.2500\n",
      "Epoch 257/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 29253433344.0000 - mae: 169471.9844 - val_loss: 30460375040.0000 - val_mae: 167669.1250\n",
      "Epoch 258/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 29103872000.0000 - mae: 169051.6562 - val_loss: 30455648256.0000 - val_mae: 167680.6562\n",
      "Epoch 259/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 28956506112.0000 - mae: 168619.3594 - val_loss: 29688971264.0000 - val_mae: 165376.9844\n",
      "Epoch 260/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 28793145344.0000 - mae: 168203.0781 - val_loss: 29101400064.0000 - val_mae: 163491.0000\n",
      "Epoch 261/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 28628760576.0000 - mae: 167753.8125 - val_loss: 29608290304.0000 - val_mae: 165048.9062\n",
      "Epoch 262/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 28477270016.0000 - mae: 167352.3438 - val_loss: 29614286848.0000 - val_mae: 165121.9688\n",
      "Epoch 263/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 28324407296.0000 - mae: 166910.0469 - val_loss: 29460480000.0000 - val_mae: 164652.7656\n",
      "Epoch 264/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 28193726464.0000 - mae: 166506.7969 - val_loss: 29343244288.0000 - val_mae: 164276.4531\n",
      "Epoch 265/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 28013236224.0000 - mae: 166055.8594 - val_loss: 29183236096.0000 - val_mae: 163790.2031\n",
      "Epoch 266/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 27860834304.0000 - mae: 165599.0469 - val_loss: 28913448960.0000 - val_mae: 162974.0156\n",
      "Epoch 267/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 27721310208.0000 - mae: 165188.6094 - val_loss: 29128529920.0000 - val_mae: 163530.6875\n",
      "Epoch 268/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 27564527616.0000 - mae: 164792.6250 - val_loss: 29437902848.0000 - val_mae: 164511.1875\n",
      "Epoch 269/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 27404994560.0000 - mae: 164301.9531 - val_loss: 28734887936.0000 - val_mae: 162358.9531\n",
      "Epoch 270/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 27262877696.0000 - mae: 163863.4844 - val_loss: 28577241088.0000 - val_mae: 161833.4219\n",
      "Epoch 271/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 27126059008.0000 - mae: 163455.0938 - val_loss: 28392024064.0000 - val_mae: 161253.2656\n",
      "Epoch 272/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 26982998016.0000 - mae: 163047.8281 - val_loss: 28383100928.0000 - val_mae: 161205.0156\n",
      "Epoch 273/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 26843361280.0000 - mae: 162643.6875 - val_loss: 27702704128.0000 - val_mae: 159015.7500\n",
      "Epoch 274/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 26669305856.0000 - mae: 162142.8438 - val_loss: 28049768448.0000 - val_mae: 160171.5781\n",
      "Epoch 275/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 26507116544.0000 - mae: 161693.2969 - val_loss: 28053020672.0000 - val_mae: 160175.0781\n",
      "Epoch 276/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 26382221312.0000 - mae: 161318.0469 - val_loss: 27326457856.0000 - val_mae: 157817.1875\n",
      "Epoch 277/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 26235721728.0000 - mae: 160854.4062 - val_loss: 27274217472.0000 - val_mae: 157617.2500\n",
      "Epoch 278/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 26071277568.0000 - mae: 160436.1719 - val_loss: 27786602496.0000 - val_mae: 159269.5469\n",
      "Epoch 279/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 25925724160.0000 - mae: 159974.1719 - val_loss: 27324059648.0000 - val_mae: 157808.8594\n",
      "Epoch 280/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 25782226944.0000 - mae: 159579.5625 - val_loss: 27310442496.0000 - val_mae: 157653.8281\n",
      "Epoch 281/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 25620789248.0000 - mae: 159074.3594 - val_loss: 26694004736.0000 - val_mae: 155708.7031\n",
      "Epoch 282/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 25485350912.0000 - mae: 158615.2812 - val_loss: 27009845248.0000 - val_mae: 156724.7188\n",
      "Epoch 283/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 25352763392.0000 - mae: 158237.6562 - val_loss: 26922311680.0000 - val_mae: 156429.8906\n",
      "Epoch 284/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 25210370048.0000 - mae: 157792.8438 - val_loss: 25958936576.0000 - val_mae: 153234.5312\n",
      "Epoch 285/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 25040119808.0000 - mae: 157231.4375 - val_loss: 26035814400.0000 - val_mae: 153460.3594\n",
      "Epoch 286/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 24898054144.0000 - mae: 156839.9375 - val_loss: 26348808192.0000 - val_mae: 154511.7812\n",
      "Epoch 287/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 24763287552.0000 - mae: 156399.4219 - val_loss: 26107705344.0000 - val_mae: 153780.4688\n",
      "Epoch 288/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 24597803008.0000 - mae: 155938.9844 - val_loss: 25892947968.0000 - val_mae: 152939.6875\n",
      "Epoch 289/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 24437233664.0000 - mae: 155441.0156 - val_loss: 25904422912.0000 - val_mae: 153156.3594\n",
      "Epoch 290/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 24310155264.0000 - mae: 155051.5625 - val_loss: 25413081088.0000 - val_mae: 151402.0156\n",
      "Epoch 291/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 24143060992.0000 - mae: 154527.7812 - val_loss: 25560188928.0000 - val_mae: 151961.4531\n",
      "Epoch 292/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 24008935424.0000 - mae: 154090.4219 - val_loss: 25539223552.0000 - val_mae: 151732.0000\n",
      "Epoch 293/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 23887908864.0000 - mae: 153692.1094 - val_loss: 25070264320.0000 - val_mae: 150262.7031\n",
      "Epoch 294/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 23754108928.0000 - mae: 153278.8125 - val_loss: 25038315520.0000 - val_mae: 150124.5938\n",
      "Epoch 295/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 23586709504.0000 - mae: 152740.3906 - val_loss: 25348581376.0000 - val_mae: 151001.4844\n",
      "Epoch 296/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 23442030592.0000 - mae: 152313.7969 - val_loss: 24765517824.0000 - val_mae: 148998.0156\n",
      "Epoch 297/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 23322726400.0000 - mae: 151879.2812 - val_loss: 25235279872.0000 - val_mae: 150612.2812\n",
      "Epoch 298/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 23148474368.0000 - mae: 151322.3906 - val_loss: 24161957888.0000 - val_mae: 146960.9531\n",
      "Epoch 299/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 23015933952.0000 - mae: 150910.1719 - val_loss: 24439805952.0000 - val_mae: 147933.2344\n",
      "Epoch 300/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 22875080704.0000 - mae: 150453.2812 - val_loss: 24640833536.0000 - val_mae: 148508.1406\n",
      "Epoch 301/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 22744059904.0000 - mae: 149973.8281 - val_loss: 24462379008.0000 - val_mae: 147873.1562\n",
      "Epoch 302/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 22602743808.0000 - mae: 149547.9688 - val_loss: 24693348352.0000 - val_mae: 148554.5156\n",
      "Epoch 303/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 22460921856.0000 - mae: 149116.1406 - val_loss: 24104593408.0000 - val_mae: 146681.6719\n",
      "Epoch 304/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 22332311552.0000 - mae: 148634.1094 - val_loss: 23874547712.0000 - val_mae: 145795.5938\n",
      "Epoch 305/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 22171314176.0000 - mae: 148101.1562 - val_loss: 23628894208.0000 - val_mae: 145074.3906\n",
      "Epoch 306/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 22037975040.0000 - mae: 147677.3125 - val_loss: 23564648448.0000 - val_mae: 144779.3438\n",
      "Epoch 307/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 21890453504.0000 - mae: 147216.7969 - val_loss: 23614586880.0000 - val_mae: 144946.4375\n",
      "Epoch 308/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 21768155136.0000 - mae: 146727.8906 - val_loss: 23433371648.0000 - val_mae: 144241.5781\n",
      "Epoch 309/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 21613725696.0000 - mae: 146259.1875 - val_loss: 22999875584.0000 - val_mae: 142751.9531\n",
      "Epoch 310/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 21490499584.0000 - mae: 145803.4844 - val_loss: 23243124736.0000 - val_mae: 143522.9531\n",
      "Epoch 311/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 21356019712.0000 - mae: 145341.5156 - val_loss: 22739490816.0000 - val_mae: 141738.2344\n",
      "Epoch 312/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 21222551552.0000 - mae: 144876.6094 - val_loss: 23349161984.0000 - val_mae: 143956.2812\n",
      "Epoch 313/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 21050873856.0000 - mae: 144345.2812 - val_loss: 23253856256.0000 - val_mae: 143540.3750\n",
      "Epoch 314/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 20915132416.0000 - mae: 143876.1875 - val_loss: 22695297024.0000 - val_mae: 141216.5781\n",
      "Epoch 315/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 20786239488.0000 - mae: 143393.2500 - val_loss: 22476072960.0000 - val_mae: 140723.9375\n",
      "Epoch 316/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 20663240704.0000 - mae: 142956.1562 - val_loss: 22557579264.0000 - val_mae: 140961.0312\n",
      "Epoch 317/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 20523331584.0000 - mae: 142449.0938 - val_loss: 21958451200.0000 - val_mae: 138759.1250\n",
      "Epoch 318/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 20381368320.0000 - mae: 141940.6562 - val_loss: 22174689280.0000 - val_mae: 139482.4219\n",
      "Epoch 319/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 20215805952.0000 - mae: 141434.6250 - val_loss: 21978408960.0000 - val_mae: 138896.5781\n",
      "Epoch 320/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 20088469504.0000 - mae: 140959.9219 - val_loss: 21821655040.0000 - val_mae: 138311.0469\n",
      "Epoch 321/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 19942696960.0000 - mae: 140467.3906 - val_loss: 21690535936.0000 - val_mae: 138052.3750\n",
      "Epoch 322/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 19847596032.0000 - mae: 140044.1250 - val_loss: 22005463040.0000 - val_mae: 138902.9688\n",
      "Epoch 323/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 19691790336.0000 - mae: 139513.4375 - val_loss: 21383286784.0000 - val_mae: 136627.0938\n",
      "Epoch 324/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 19574583296.0000 - mae: 139069.7500 - val_loss: 21370640384.0000 - val_mae: 136670.4531\n",
      "Epoch 325/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 19406616576.0000 - mae: 138552.8125 - val_loss: 21521504256.0000 - val_mae: 137075.1250\n",
      "Epoch 326/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 19298252800.0000 - mae: 138124.3281 - val_loss: 21737129984.0000 - val_mae: 138019.2969\n",
      "Epoch 327/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 19157985280.0000 - mae: 137600.6250 - val_loss: 21201483776.0000 - val_mae: 136002.5469\n",
      "Epoch 328/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 19027505152.0000 - mae: 137169.0469 - val_loss: 20844496896.0000 - val_mae: 134881.0938\n",
      "Epoch 329/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 18878056448.0000 - mae: 136575.0938 - val_loss: 20714399744.0000 - val_mae: 134368.2812\n",
      "Epoch 330/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 18750750720.0000 - mae: 136126.0469 - val_loss: 20381097984.0000 - val_mae: 132981.0000\n",
      "Epoch 331/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 18605844480.0000 - mae: 135605.9062 - val_loss: 20252823552.0000 - val_mae: 132622.5312\n",
      "Epoch 332/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 18472577024.0000 - mae: 135089.9375 - val_loss: 20737591296.0000 - val_mae: 134221.2969\n",
      "Epoch 333/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 18339018752.0000 - mae: 134599.2969 - val_loss: 20616710144.0000 - val_mae: 133911.6875\n",
      "Epoch 334/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 18237145088.0000 - mae: 134137.6875 - val_loss: 20013139968.0000 - val_mae: 131812.1562\n",
      "Epoch 335/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 18082314240.0000 - mae: 133611.4375 - val_loss: 20040769536.0000 - val_mae: 131660.1562\n",
      "Epoch 336/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 17960421376.0000 - mae: 133100.4688 - val_loss: 20163905536.0000 - val_mae: 132141.2656\n",
      "Epoch 337/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 17828100096.0000 - mae: 132617.5781 - val_loss: 19591038976.0000 - val_mae: 129791.2109\n",
      "Epoch 338/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 17683126272.0000 - mae: 132121.9688 - val_loss: 19476367360.0000 - val_mae: 129284.5547\n",
      "Epoch 339/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 17531115520.0000 - mae: 131594.1406 - val_loss: 19358554112.0000 - val_mae: 129024.5938\n",
      "Epoch 340/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 17400899584.0000 - mae: 131066.6562 - val_loss: 19533084672.0000 - val_mae: 129732.2812\n",
      "Epoch 341/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 17272778752.0000 - mae: 130581.1406 - val_loss: 19474391040.0000 - val_mae: 129630.3281\n",
      "Epoch 342/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 17148943360.0000 - mae: 130138.0469 - val_loss: 19107999744.0000 - val_mae: 128146.3672\n",
      "Epoch 343/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 16995538944.0000 - mae: 129551.4531 - val_loss: 19076270080.0000 - val_mae: 127940.2578\n",
      "Epoch 344/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 16893733888.0000 - mae: 129102.8906 - val_loss: 18789390336.0000 - val_mae: 126745.2109\n",
      "Epoch 345/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 16745654272.0000 - mae: 128584.5859 - val_loss: 18835826688.0000 - val_mae: 127157.3125\n",
      "Epoch 346/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 16604508160.0000 - mae: 128034.0781 - val_loss: 18358065152.0000 - val_mae: 125040.2891\n",
      "Epoch 347/500\n",
      "36/36 [==============================] - 1s 42ms/step - loss: 16491426816.0000 - mae: 127571.6250 - val_loss: 18810335232.0000 - val_mae: 127048.5000\n",
      "Epoch 348/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 16383926272.0000 - mae: 127074.4297 - val_loss: 18811451392.0000 - val_mae: 127041.3828\n",
      "Epoch 349/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 16225291264.0000 - mae: 126510.1953 - val_loss: 18005092352.0000 - val_mae: 123678.2188\n",
      "Epoch 350/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 16125647872.0000 - mae: 126080.9062 - val_loss: 18163912704.0000 - val_mae: 124173.1250\n",
      "Epoch 351/500\n",
      "36/36 [==============================] - 1s 42ms/step - loss: 15960221696.0000 - mae: 125457.5078 - val_loss: 17837469696.0000 - val_mae: 123136.5625\n",
      "Epoch 352/500\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 15807842304.0000 - mae: 124916.2891 - val_loss: 18286393344.0000 - val_mae: 125089.1016\n",
      "Epoch 353/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 15710887936.0000 - mae: 124481.0156 - val_loss: 18008176640.0000 - val_mae: 124091.5625\n",
      "Epoch 354/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 15573686272.0000 - mae: 123916.7969 - val_loss: 17580632064.0000 - val_mae: 122086.6328\n",
      "Epoch 355/500\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 15416875008.0000 - mae: 123312.8438 - val_loss: 17384587264.0000 - val_mae: 121094.4766\n",
      "Epoch 356/500\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 15324631040.0000 - mae: 122880.8906 - val_loss: 17164871680.0000 - val_mae: 120412.1953\n",
      "Epoch 357/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 15168822272.0000 - mae: 122297.0547 - val_loss: 17009357824.0000 - val_mae: 119674.6016\n",
      "Epoch 358/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 15066468352.0000 - mae: 121834.4062 - val_loss: 16909692928.0000 - val_mae: 119428.3672\n",
      "Epoch 359/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 14945742848.0000 - mae: 121344.7812 - val_loss: 17116680192.0000 - val_mae: 120404.9453\n",
      "Epoch 360/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 14795359232.0000 - mae: 120744.9375 - val_loss: 16878368768.0000 - val_mae: 119315.0469\n",
      "Epoch 361/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 14714052608.0000 - mae: 120395.9609 - val_loss: 16671980544.0000 - val_mae: 118518.1719\n",
      "Epoch 362/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 14562011136.0000 - mae: 119792.8984 - val_loss: 16405255168.0000 - val_mae: 117194.7422\n",
      "Epoch 363/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 14441781248.0000 - mae: 119262.4297 - val_loss: 16495851520.0000 - val_mae: 118016.5703\n",
      "Epoch 364/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 14296848384.0000 - mae: 118666.1094 - val_loss: 16454936576.0000 - val_mae: 117778.1875\n",
      "Epoch 365/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 14166187008.0000 - mae: 118136.3750 - val_loss: 16200646656.0000 - val_mae: 116544.8984\n",
      "Epoch 366/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 14049034240.0000 - mae: 117628.8984 - val_loss: 16178540544.0000 - val_mae: 116321.6406\n",
      "Epoch 367/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 13910407168.0000 - mae: 117051.5547 - val_loss: 16094747648.0000 - val_mae: 115913.7969\n",
      "Epoch 368/500\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 13793672192.0000 - mae: 116515.4922 - val_loss: 15822836736.0000 - val_mae: 114816.6250\n",
      "Epoch 369/500\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 13690083328.0000 - mae: 116068.6094 - val_loss: 15288359936.0000 - val_mae: 112612.5781\n",
      "Epoch 370/500\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 13577014272.0000 - mae: 115567.1094 - val_loss: 15577368576.0000 - val_mae: 113985.5234\n",
      "Epoch 371/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 13429844992.0000 - mae: 114942.5859 - val_loss: 15423268864.0000 - val_mae: 113186.1953\n",
      "Epoch 372/500\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 13314079744.0000 - mae: 114439.2266 - val_loss: 15185116160.0000 - val_mae: 112201.0391\n",
      "Epoch 373/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 13194000384.0000 - mae: 113921.0312 - val_loss: 15345257472.0000 - val_mae: 113164.2188\n",
      "Epoch 374/500\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 13078025216.0000 - mae: 113445.5000 - val_loss: 15407578112.0000 - val_mae: 113284.1562\n",
      "Epoch 375/500\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 12947419136.0000 - mae: 112825.9297 - val_loss: 15055433728.0000 - val_mae: 111698.4922\n",
      "Epoch 376/500\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 12812759040.0000 - mae: 112226.8906 - val_loss: 14883773440.0000 - val_mae: 111033.1016\n",
      "Epoch 377/500\n",
      "36/36 [==============================] - 1s 42ms/step - loss: 12699722752.0000 - mae: 111728.0938 - val_loss: 14854502400.0000 - val_mae: 110741.3203\n",
      "Epoch 378/500\n",
      "36/36 [==============================] - 1s 42ms/step - loss: 12551779328.0000 - mae: 111166.0234 - val_loss: 14975835136.0000 - val_mae: 111516.3125\n",
      "Epoch 379/500\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 12439300096.0000 - mae: 110642.0469 - val_loss: 14666314752.0000 - val_mae: 110255.1406\n",
      "Epoch 380/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 12340101120.0000 - mae: 110136.3359 - val_loss: 14438575104.0000 - val_mae: 109168.1094\n",
      "Epoch 381/500\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 12211920896.0000 - mae: 109554.7656 - val_loss: 14421004288.0000 - val_mae: 109146.6016\n",
      "Epoch 382/500\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 12097119232.0000 - mae: 109037.0391 - val_loss: 13900928000.0000 - val_mae: 106589.4375\n",
      "Epoch 383/500\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 11986051072.0000 - mae: 108541.5469 - val_loss: 13758224384.0000 - val_mae: 105713.0000\n",
      "Epoch 384/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 11867663360.0000 - mae: 107947.3047 - val_loss: 13960459264.0000 - val_mae: 106793.1875\n",
      "Epoch 385/500\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 11741496320.0000 - mae: 107386.5703 - val_loss: 14033404928.0000 - val_mae: 107357.5547\n",
      "Epoch 386/500\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 11630516224.0000 - mae: 106843.2500 - val_loss: 13961861120.0000 - val_mae: 106755.2812\n",
      "Epoch 387/500\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 11503797248.0000 - mae: 106288.7656 - val_loss: 13957828608.0000 - val_mae: 106832.8516\n",
      "Epoch 388/500\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 11386653696.0000 - mae: 105732.9922 - val_loss: 13447742464.0000 - val_mae: 104725.1875\n",
      "Epoch 389/500\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 11288646656.0000 - mae: 105252.5000 - val_loss: 13042709504.0000 - val_mae: 102412.6875\n",
      "Epoch 390/500\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 11179017216.0000 - mae: 104659.3594 - val_loss: 12850251776.0000 - val_mae: 101835.1250\n",
      "Epoch 391/500\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 11037952000.0000 - mae: 104120.4453 - val_loss: 13069563904.0000 - val_mae: 102931.6406\n",
      "Epoch 392/500\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 10957829120.0000 - mae: 103615.2969 - val_loss: 12933437440.0000 - val_mae: 102221.6172\n",
      "Epoch 393/500\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 10842608640.0000 - mae: 103079.2812 - val_loss: 12711865344.0000 - val_mae: 101149.4844\n",
      "Epoch 394/500\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 10725197824.0000 - mae: 102555.5000 - val_loss: 12610784256.0000 - val_mae: 100738.4766\n",
      "Epoch 395/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 10616025088.0000 - mae: 101947.5469 - val_loss: 12621196288.0000 - val_mae: 100692.0938\n",
      "Epoch 396/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 10481902592.0000 - mae: 101383.4531 - val_loss: 12887771136.0000 - val_mae: 102018.9453\n",
      "Epoch 397/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 10395939840.0000 - mae: 100919.8359 - val_loss: 12417200128.0000 - val_mae: 99547.8516\n",
      "Epoch 398/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 10265955328.0000 - mae: 100249.7266 - val_loss: 12174030848.0000 - val_mae: 98565.1953\n",
      "Epoch 399/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 10158106624.0000 - mae: 99717.2891 - val_loss: 12128405504.0000 - val_mae: 98345.5625\n",
      "Epoch 400/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 10031736832.0000 - mae: 99149.8906 - val_loss: 12310828032.0000 - val_mae: 99183.5938\n",
      "Epoch 401/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 9932279808.0000 - mae: 98603.0469 - val_loss: 11579914240.0000 - val_mae: 95345.2500\n",
      "Epoch 402/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 9818597376.0000 - mae: 98061.4141 - val_loss: 11358833664.0000 - val_mae: 94382.4219\n",
      "Epoch 403/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 9723409408.0000 - mae: 97500.3047 - val_loss: 11884806144.0000 - val_mae: 97048.2266\n",
      "Epoch 404/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 9609720832.0000 - mae: 96963.1172 - val_loss: 12106688512.0000 - val_mae: 97925.5938\n",
      "Epoch 405/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 9515710464.0000 - mae: 96442.1094 - val_loss: 11676959744.0000 - val_mae: 96094.8906\n",
      "Epoch 406/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 9403764736.0000 - mae: 95879.3594 - val_loss: 11458736128.0000 - val_mae: 95077.3906\n",
      "Epoch 407/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 9270821888.0000 - mae: 95255.1094 - val_loss: 11396350976.0000 - val_mae: 94580.5000\n",
      "Epoch 408/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 9179018240.0000 - mae: 94682.8281 - val_loss: 11227889664.0000 - val_mae: 93801.0234\n",
      "Epoch 409/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 9066162176.0000 - mae: 94123.5156 - val_loss: 11192612864.0000 - val_mae: 93675.0078\n",
      "Epoch 410/500\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 8950459392.0000 - mae: 93507.3750 - val_loss: 10998394880.0000 - val_mae: 92734.4609\n",
      "Epoch 411/500\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 8877996032.0000 - mae: 93065.1875 - val_loss: 10917662720.0000 - val_mae: 92446.5312\n",
      "Epoch 412/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 8768948224.0000 - mae: 92493.4219 - val_loss: 11002382336.0000 - val_mae: 92884.4062\n",
      "Epoch 413/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 8655276032.0000 - mae: 91888.7422 - val_loss: 10626963456.0000 - val_mae: 90880.4531\n",
      "Epoch 414/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 8551868928.0000 - mae: 91366.7031 - val_loss: 10641275904.0000 - val_mae: 90814.9219\n",
      "Epoch 415/500\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 8442479616.0000 - mae: 90692.8203 - val_loss: 10554087424.0000 - val_mae: 90532.3516\n",
      "Epoch 416/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 8345539072.0000 - mae: 90211.6484 - val_loss: 10376758272.0000 - val_mae: 89479.2188\n",
      "Epoch 417/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 8250354688.0000 - mae: 89645.2656 - val_loss: 10527241216.0000 - val_mae: 90313.1875\n",
      "Epoch 418/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 8158950912.0000 - mae: 89152.1875 - val_loss: 10015815680.0000 - val_mae: 87515.4219\n",
      "Epoch 419/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 8044016128.0000 - mae: 88531.4922 - val_loss: 10244550656.0000 - val_mae: 88969.5312\n",
      "Epoch 420/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 7945711616.0000 - mae: 87990.1797 - val_loss: 10147530752.0000 - val_mae: 88410.5859\n",
      "Epoch 421/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 7855526400.0000 - mae: 87459.5156 - val_loss: 10010296320.0000 - val_mae: 87750.3125\n",
      "Epoch 422/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7751875072.0000 - mae: 86840.6719 - val_loss: 9477837824.0000 - val_mae: 84776.4531\n",
      "Epoch 423/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7656876032.0000 - mae: 86285.2656 - val_loss: 9882305536.0000 - val_mae: 87017.5703\n",
      "Epoch 424/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 7544009216.0000 - mae: 85632.4297 - val_loss: 9741396992.0000 - val_mae: 86079.7266\n",
      "Epoch 425/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 7493076992.0000 - mae: 85302.4844 - val_loss: 9588176896.0000 - val_mae: 85193.0625\n",
      "Epoch 426/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 7361814016.0000 - mae: 84576.0391 - val_loss: 9268258816.0000 - val_mae: 83594.4453\n",
      "Epoch 427/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 7259478528.0000 - mae: 84057.7422 - val_loss: 9408296960.0000 - val_mae: 84447.6484\n",
      "Epoch 428/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 7158703104.0000 - mae: 83428.7500 - val_loss: 9315134464.0000 - val_mae: 83896.3828\n",
      "Epoch 429/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 7077540864.0000 - mae: 82858.3125 - val_loss: 9076868096.0000 - val_mae: 82476.2891\n",
      "Epoch 430/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 6991979520.0000 - mae: 82303.5547 - val_loss: 9186722816.0000 - val_mae: 83287.6797\n",
      "Epoch 431/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 6885495296.0000 - mae: 81765.5703 - val_loss: 9139382272.0000 - val_mae: 82968.5938\n",
      "Epoch 432/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 6804709376.0000 - mae: 81177.7109 - val_loss: 8526904320.0000 - val_mae: 79304.0000\n",
      "Epoch 433/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 6696865280.0000 - mae: 80660.9609 - val_loss: 8824692736.0000 - val_mae: 81074.1562\n",
      "Epoch 434/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 6609719808.0000 - mae: 80047.2734 - val_loss: 8612174848.0000 - val_mae: 79828.2812\n",
      "Epoch 435/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 6519447552.0000 - mae: 79441.5078 - val_loss: 8654004224.0000 - val_mae: 79999.6484\n",
      "Epoch 436/500\n",
      "36/36 [==============================] - 1s 42ms/step - loss: 6447822848.0000 - mae: 78962.5000 - val_loss: 8679225344.0000 - val_mae: 80271.8125\n",
      "Epoch 437/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 6362385408.0000 - mae: 78402.5703 - val_loss: 8564890112.0000 - val_mae: 79728.1172\n",
      "Epoch 438/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 6243667456.0000 - mae: 77764.9062 - val_loss: 8428124672.0000 - val_mae: 78955.8203\n",
      "Epoch 439/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 6184368128.0000 - mae: 77248.9688 - val_loss: 8237509120.0000 - val_mae: 77996.8359\n",
      "Epoch 440/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 6080691712.0000 - mae: 76550.8125 - val_loss: 8197515264.0000 - val_mae: 77705.6172\n",
      "Epoch 441/500\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 5995325952.0000 - mae: 76102.5469 - val_loss: 8202946560.0000 - val_mae: 77654.7891\n",
      "Epoch 442/500\n",
      "36/36 [==============================] - 1s 38ms/step - loss: 5919851520.0000 - mae: 75524.4766 - val_loss: 8122162176.0000 - val_mae: 77089.6797\n",
      "Epoch 443/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 5815518720.0000 - mae: 74875.1641 - val_loss: 8142466560.0000 - val_mae: 77409.4141\n",
      "Epoch 444/500\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 5741887488.0000 - mae: 74425.0156 - val_loss: 7831286272.0000 - val_mae: 75662.6172\n",
      "Epoch 445/500\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 5640473600.0000 - mae: 73732.6406 - val_loss: 7619884544.0000 - val_mae: 74325.3594\n",
      "Epoch 446/500\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 5563859968.0000 - mae: 73193.2656 - val_loss: 7617327616.0000 - val_mae: 74274.6797\n",
      "Epoch 447/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 5472079360.0000 - mae: 72614.9062 - val_loss: 7715131904.0000 - val_mae: 74896.3125\n",
      "Epoch 448/500\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 5406151168.0000 - mae: 72096.2344 - val_loss: 7485921792.0000 - val_mae: 73320.8203\n",
      "Epoch 449/500\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 5318173696.0000 - mae: 71492.2266 - val_loss: 7622503936.0000 - val_mae: 74302.0781\n",
      "Epoch 450/500\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 5249242112.0000 - mae: 70950.0156 - val_loss: 7400103936.0000 - val_mae: 72977.1562\n",
      "Epoch 451/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 5173634048.0000 - mae: 70416.7031 - val_loss: 7301832704.0000 - val_mae: 72453.7969\n",
      "Epoch 452/500\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 5088594432.0000 - mae: 69782.1875 - val_loss: 7162732544.0000 - val_mae: 71445.0391\n",
      "Epoch 453/500\n",
      "36/36 [==============================] - 1s 37ms/step - loss: 4989624320.0000 - mae: 69100.2891 - val_loss: 7144547328.0000 - val_mae: 71459.7344\n",
      "Epoch 454/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 4943740928.0000 - mae: 68747.7969 - val_loss: 7231130624.0000 - val_mae: 71912.6250\n",
      "Epoch 455/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 4868497920.0000 - mae: 68254.9297 - val_loss: 7077573120.0000 - val_mae: 71105.3359\n",
      "Epoch 456/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 4798296064.0000 - mae: 67607.2500 - val_loss: 6921441280.0000 - val_mae: 70101.6562\n",
      "Epoch 457/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 4702657024.0000 - mae: 67017.3359 - val_loss: 6824115712.0000 - val_mae: 69520.6484\n",
      "Epoch 458/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 4624284160.0000 - mae: 66479.5938 - val_loss: 6717232640.0000 - val_mae: 68806.5859\n",
      "Epoch 459/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 4545869312.0000 - mae: 65883.4844 - val_loss: 6757381632.0000 - val_mae: 69121.7031\n",
      "Epoch 460/500\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 4474918400.0000 - mae: 65280.4023 - val_loss: 6574606848.0000 - val_mae: 67999.5391\n",
      "Epoch 461/500\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 4381770752.0000 - mae: 64688.9180 - val_loss: 6666445824.0000 - val_mae: 68620.7109\n",
      "Epoch 462/500\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 4337288192.0000 - mae: 64254.6211 - val_loss: 6405424640.0000 - val_mae: 66886.5000\n",
      "Epoch 463/500\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 4274145024.0000 - mae: 63679.7578 - val_loss: 6385018368.0000 - val_mae: 66761.4219\n",
      "Epoch 464/500\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 4183541248.0000 - mae: 63066.0117 - val_loss: 6393052672.0000 - val_mae: 66892.0078\n",
      "Epoch 465/500\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 4105496064.0000 - mae: 62400.3398 - val_loss: 6140281856.0000 - val_mae: 65021.5547\n",
      "Epoch 466/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 4032195840.0000 - mae: 61849.8828 - val_loss: 6173587456.0000 - val_mae: 65327.8516\n",
      "Epoch 467/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 3972041216.0000 - mae: 61268.1016 - val_loss: 6133952000.0000 - val_mae: 65094.3359\n",
      "Epoch 468/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 3899666688.0000 - mae: 60743.0781 - val_loss: 6104895488.0000 - val_mae: 64816.2109\n",
      "Epoch 469/500\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 3835918080.0000 - mae: 60250.0977 - val_loss: 5956441600.0000 - val_mae: 63965.0664\n",
      "Epoch 470/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 3781440512.0000 - mae: 59636.4766 - val_loss: 5959740928.0000 - val_mae: 63944.0117\n",
      "Epoch 471/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 3684133376.0000 - mae: 59041.6172 - val_loss: 5799396352.0000 - val_mae: 62760.6680\n",
      "Epoch 472/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 3627607808.0000 - mae: 58549.9180 - val_loss: 5886550528.0000 - val_mae: 63655.2266\n",
      "Epoch 473/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 3561567232.0000 - mae: 57902.5938 - val_loss: 5793024000.0000 - val_mae: 63044.4102\n",
      "Epoch 474/500\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 3490642176.0000 - mae: 57367.1719 - val_loss: 5689113088.0000 - val_mae: 62271.8867\n",
      "Epoch 475/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 3437228800.0000 - mae: 56819.5430 - val_loss: 5574388736.0000 - val_mae: 61454.9609\n",
      "Epoch 476/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 3386735872.0000 - mae: 56301.6211 - val_loss: 5561083392.0000 - val_mae: 61305.4023\n",
      "Epoch 477/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 3301931776.0000 - mae: 55691.0625 - val_loss: 5671631872.0000 - val_mae: 62106.1680\n",
      "Epoch 478/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 3254509568.0000 - mae: 55195.0586 - val_loss: 5455562752.0000 - val_mae: 60626.7773\n",
      "Epoch 479/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 3183435520.0000 - mae: 54507.1758 - val_loss: 5290817536.0000 - val_mae: 59582.8906\n",
      "Epoch 480/500\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 3127346176.0000 - mae: 54037.9883 - val_loss: 5161025024.0000 - val_mae: 58699.3867\n",
      "Epoch 481/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 3069357056.0000 - mae: 53387.8867 - val_loss: 5244296704.0000 - val_mae: 59162.5781\n",
      "Epoch 482/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2998277120.0000 - mae: 52821.0938 - val_loss: 5264370688.0000 - val_mae: 59277.3125\n",
      "Epoch 483/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2946097408.0000 - mae: 52240.1602 - val_loss: 5036164096.0000 - val_mae: 57837.3711\n",
      "Epoch 484/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2907483648.0000 - mae: 51797.0781 - val_loss: 5068199424.0000 - val_mae: 57964.8555\n",
      "Epoch 485/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2813862912.0000 - mae: 51127.5078 - val_loss: 5052331520.0000 - val_mae: 57932.4102\n",
      "Epoch 486/500\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 2793670144.0000 - mae: 50649.7461 - val_loss: 5002616320.0000 - val_mae: 57585.3125\n",
      "Epoch 487/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2723501312.0000 - mae: 50111.5977 - val_loss: 4846508544.0000 - val_mae: 56387.4570\n",
      "Epoch 488/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2669134336.0000 - mae: 49577.8438 - val_loss: 4947415552.0000 - val_mae: 57177.8438\n",
      "Epoch 489/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 2617627136.0000 - mae: 49028.3711 - val_loss: 5053558272.0000 - val_mae: 57951.7969\n",
      "Epoch 490/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 2571931904.0000 - mae: 48491.9766 - val_loss: 4793012224.0000 - val_mae: 56115.7383\n",
      "Epoch 491/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2499633152.0000 - mae: 47853.8594 - val_loss: 4726593536.0000 - val_mae: 55559.1250\n",
      "Epoch 492/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 2449769472.0000 - mae: 47356.0781 - val_loss: 4705867776.0000 - val_mae: 55441.6914\n",
      "Epoch 493/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2398403584.0000 - mae: 46772.4883 - val_loss: 4745755136.0000 - val_mae: 55735.6836\n",
      "Epoch 494/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2364535552.0000 - mae: 46317.0547 - val_loss: 4521330688.0000 - val_mae: 54157.7305\n",
      "Epoch 495/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2287047424.0000 - mae: 45708.7461 - val_loss: 4448586240.0000 - val_mae: 53617.3984\n",
      "Epoch 496/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 2251437824.0000 - mae: 45227.8906 - val_loss: 4414220288.0000 - val_mae: 53316.5195\n",
      "Epoch 497/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2214330112.0000 - mae: 44627.7734 - val_loss: 4491696640.0000 - val_mae: 53830.0195\n",
      "Epoch 498/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 2163479552.0000 - mae: 44042.0273 - val_loss: 4334889472.0000 - val_mae: 52761.7695\n",
      "Epoch 499/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2124658048.0000 - mae: 43676.0195 - val_loss: 4295520768.0000 - val_mae: 52477.1328\n",
      "Epoch 500/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 2075755776.0000 - mae: 43088.8828 - val_loss: 4323683328.0000 - val_mae: 52761.4648\n",
      "Minimum validation loss: 4295520768.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=[input_shape]),\n",
    "\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(1),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping], # put your callbacks in a list\n",
    "    # verbose=0,  # turn off training log\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step\n",
      "number of good predictions for Sequential = 1454239\n",
      "which is 64261.555457357485%\n"
     ]
    }
   ],
   "source": [
    "print_percent_of_good_predictions([model], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step\n",
      "number of good predictions for Sequential = 1076\n",
      "which is 47.54750331418471%\n"
     ]
    }
   ],
   "source": [
    "error = NUM_OF_HOURS * 60 * 60\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.squeeze(predictions)\n",
    "predictions_time_diff = np.abs(y_test - predictions)\n",
    "num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "print(f'number of good predictions for {type(model).__name__} = {num_of_good_predictions}')\n",
    "print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2263,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>purchase_datetime_delta</th>\n",
       "      <th>516</th>\n",
       "      <th>620</th>\n",
       "      <th>Kraków</th>\n",
       "      <th>Poznań</th>\n",
       "      <th>Radom</th>\n",
       "      <th>Szczecin</th>\n",
       "      <th>Warszawa</th>\n",
       "      <th>...</th>\n",
       "      <th>1627</th>\n",
       "      <th>1628</th>\n",
       "      <th>1629</th>\n",
       "      <th>1630</th>\n",
       "      <th>1631</th>\n",
       "      <th>1632</th>\n",
       "      <th>1633</th>\n",
       "      <th>1634</th>\n",
       "      <th>1635</th>\n",
       "      <th>1653</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10825</th>\n",
       "      <td>0.013589</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.660933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>0.027859</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.558801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>0.119751</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>0.913933</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>0.124076</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.659243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>0.134886</td>\n",
       "      <td>0.023667</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>0.032173</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.177023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.563015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8928</th>\n",
       "      <td>0.836941</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.762100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>0.092714</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.213929</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>0.719751</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.903028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2263 rows × 594 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  weight_kg  purchase_datetime_delta  516  620  Kraków  Poznań  \\\n",
       "10825  0.013589   0.000467                 0.660933    0    0       0       0   \n",
       "3593   0.027859   0.001333                 0.558801    0    0       0       0   \n",
       "5653   0.119751   0.013733                 0.913933    1    0       0       0   \n",
       "4854   0.124076   0.226667                 0.659243    0    0       0       1   \n",
       "3864   0.134886   0.023667                 0.498738    0    1       0       0   \n",
       "...         ...        ...                      ...  ...  ...     ...     ...   \n",
       "6667   0.032173   0.008667                 0.177023    1    0       0       0   \n",
       "721    0.632184   0.680000                 0.563015    0    0       1       0   \n",
       "8928   0.836941   0.001733                 0.762100    0    0       0       1   \n",
       "8521   0.092714   0.166667                 0.213929    1    0       0       0   \n",
       "5647   0.719751   0.166667                 0.903028    0    1       0       0   \n",
       "\n",
       "       Radom  Szczecin  Warszawa  ...  1627  1628  1629  1630  1631  1632  \\\n",
       "10825      1         0         0  ...     0     0     0     0     0     0   \n",
       "3593       0         0         0  ...     0     0     0     0     0     0   \n",
       "5653       0         0         0  ...     0     0     0     0     0     0   \n",
       "4854       0         0         0  ...     0     0     0     0     0     0   \n",
       "3864       1         0         0  ...     0     0     0     0     0     0   \n",
       "...      ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "6667       0         1         0  ...     0     0     0     0     0     0   \n",
       "721        0         0         0  ...     0     0     0     0     0     0   \n",
       "8928       0         0         0  ...     0     0     0     0     0     0   \n",
       "8521       0         0         0  ...     0     0     0     0     0     0   \n",
       "5647       0         0         0  ...     0     0     0     0     0     0   \n",
       "\n",
       "       1633  1634  1635  1653  \n",
       "10825     0     0     0     0  \n",
       "3593      0     0     0     0  \n",
       "5653      0     0     0     0  \n",
       "4854      0     0     0     0  \n",
       "3864      0     0     0     0  \n",
       "...     ...   ...   ...   ...  \n",
       "6667      0     0     0     0  \n",
       "721       0     0     0     0  \n",
       "8928      0     0     0     0  \n",
       "8521      0     0     0     0  \n",
       "5647      0     0     0     0  \n",
       "\n",
       "[2263 rows x 594 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>Sequential prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225013.0</td>\n",
       "      <td>180021.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170068.0</td>\n",
       "      <td>150993.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195038.0</td>\n",
       "      <td>221957.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279415.0</td>\n",
       "      <td>201696.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331221.0</td>\n",
       "      <td>264245.281250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  Sequential prediction\n",
       "0  225013.0          180021.734375\n",
       "1  170068.0          150993.828125\n",
       "2  195038.0          221957.234375\n",
       "3  279415.0          201696.421875\n",
       "4  331221.0          264245.281250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2263 entries, 0 to 2262\n",
      "Data columns (total 2 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   y_test                 2263 non-null   float64\n",
      " 1   Sequential prediction  2263 non-null   float32\n",
      "dtypes: float32(1), float64(1)\n",
      "memory usage: 26.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>Sequential prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2263.000000</td>\n",
       "      <td>2263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>231077.817941</td>\n",
       "      <td>189635.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79705.119199</td>\n",
       "      <td>78274.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>33091.000000</td>\n",
       "      <td>-6670.231445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174344.000000</td>\n",
       "      <td>128748.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>222482.000000</td>\n",
       "      <td>184437.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>281067.000000</td>\n",
       "      <td>239183.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>535390.000000</td>\n",
       "      <td>498618.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y_test  Sequential prediction\n",
       "count    2263.000000            2263.000000\n",
       "mean   231077.817941          189635.656250\n",
       "std     79705.119199           78274.601562\n",
       "min     33091.000000           -6670.231445\n",
       "25%    174344.000000          128748.859375\n",
       "50%    222482.000000          184437.031250\n",
       "75%    281067.000000          239183.453125\n",
       "max    535390.000000          498618.250000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_df = create_df_with_predictions([model], X_test, y_test)\n",
    "display_predictions(y_pred_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
