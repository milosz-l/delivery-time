{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "# fact table\n",
    "sessions_df = pd.read_json(\"data/sessions.jsonl\", lines=True)\n",
    "\n",
    "# dimension tables\n",
    "deliveries_df = pd.read_json(\"data/deliveries.jsonl\", lines=True)\n",
    "products_df = pd.read_json(\"data/products.jsonl\", lines=True)\n",
    "users_df = pd.read_json(\"data/users.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_PLOTS = True\n",
    "MAKE_PAIRPLOT = True\n",
    "DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S\"\n",
    "PRICE_TRESHOLD = 100_000    # for outliers\n",
    "WEIGHT_TRESHOLD = 50        # for outliers\n",
    "NUM_OF_HOURS = 12\n",
    "SEED = 42\n",
    "SHOW_ALL_WARNINGS = False\n",
    "SHOW_ONLY_ONE_WARNING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "if SHOW_ONLY_ONE_WARNING:\n",
    "    warnings.filterwarnings(action='once')\n",
    "elif not SHOW_ALL_WARNINGS:\n",
    "    warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "deliveries_df[\"delivery_timestamp\"] = deliveries_df[\"delivery_timestamp\"].str.split('.', expand=True)[0]\n",
    "\n",
    "# 2.\n",
    "deliveries_df[\"purchase_timestamp\"] = pd.to_datetime(deliveries_df[\"purchase_timestamp\"], format=DATE_FORMAT)\n",
    "deliveries_df[\"delivery_timestamp\"] = pd.to_datetime(deliveries_df[\"delivery_timestamp\"], format=DATE_FORMAT)\n",
    "\n",
    "# 3.\n",
    "deliveries_df[\"time_diff\"] = deliveries_df[\"delivery_timestamp\"] - deliveries_df[\"purchase_timestamp\"]\n",
    "\n",
    "# 4.\n",
    "deliveries_df = deliveries_df[deliveries_df[\"time_diff\"].notna()]\n",
    "\n",
    "# 5.\n",
    "# time diff as duration in seconds\n",
    "deliveries_df[\"time_diff\"] = deliveries_df[\"time_diff\"].apply(datetime.timedelta.total_seconds)\n",
    "\n",
    "# 6.\n",
    "# deliveries_df = deliveries_df[deliveries_df[\"time_diff\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where event_type is not equal \"BUY_PRODUCT\"\n",
    "sessions_df = sessions_df[sessions_df[\"event_type\"] == \"BUY_PRODUCT\"]\n",
    "df = deliveries_df.merge(sessions_df, on=\"purchase_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure, that timestamp == purchase_timestamp\n",
    "num_of_rows_before = df.shape[0]\n",
    "df = df[df[\"timestamp\"] == df[\"purchase_timestamp\"]]\n",
    "num_of_rows_after = df.shape[0]\n",
    "\n",
    "assert(num_of_rows_before == num_of_rows_after)\n",
    "\n",
    "# now we can drop timestamp column, as it is redundant\n",
    "df = df.drop(columns=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(users_df, on=\"user_id\", how=\"left\")\n",
    "df = df.merge(products_df, on=\"product_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejecting outliers for given PRICE_TRESHOLD\n",
    "df = df[df[\"price\"] <= PRICE_TRESHOLD]\n",
    "\n",
    "# rejecting outliers for given WEIGHT_TRESHOLD\n",
    "df = df[df[\"weight_kg\"] <= WEIGHT_TRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting rows with prices below 0\n",
    "df = df[df[\"price\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_time_diff_below_0 = df\n",
    "df = df[df[\"time_diff\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['purchase_timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_and_street</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poznań plac Dębowa 11/53</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>plac Dębowa 11/53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11447</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11448</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>Poznań ul. Zachodnia 88</td>\n",
       "      <td>Poznań</td>\n",
       "      <td>ul. Zachodnia 88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11315 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                city_and_street    city             street\n",
       "0      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "1      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "2      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "3      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "4      Poznań plac Dębowa 11/53  Poznań  plac Dębowa 11/53\n",
       "...                         ...     ...                ...\n",
       "11447   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11448   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11449   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11450   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "11451   Poznań ul. Zachodnia 88  Poznań   ul. Zachodnia 88\n",
       "\n",
       "[11315 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['city_and_street'] = df['city'] + ' ' + df['street']\n",
    "display(df[['city_and_street', 'city', 'street']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['purchase_datetime_delta'] = (df['purchase_timestamp'] - df['purchase_timestamp'].min())  / np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "ADDITIONAL_COLUMNS_TO_DROP = [\"delivery_timestamp\",\n",
    "                              \"session_id\",\n",
    "                              \"purchase_id\",\n",
    "                              \"event_type\",\n",
    "                              \"name\",\n",
    "                              \"city_and_street\",\n",
    "                              \"brand\",\n",
    "                              \"user_id\",\n",
    "                              'product_name',\n",
    "                              'offered_discount']\n",
    "df = df.drop(columns=ADDITIONAL_COLUMNS_TO_DROP)\n",
    "df = df.drop(columns=\"optional_attributes\") # chyba do zmiany - wysokosc itp.\n",
    "df = df.drop(columns=\"purchase_timestamp\") # na pewno do zmiany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_a_col_in_pd(df, col_name):\n",
    "    one_hot = pd.get_dummies(df[col_name], drop_first=True)\n",
    "    df = df.drop(columns=col_name)\n",
    "    df = df.join(one_hot)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_ONE_HOT = [\"delivery_company\", \"city\", \"category_path\", \"street\", 'day_of_week', 'product_id']\n",
    "\n",
    "for col_name in COLUMNS_TO_ONE_HOT:\n",
    "    df = one_hot_encode_a_col_in_pd(df, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11315, 595)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# one-hot encoding took care of missing data, so shape has not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11315 entries, 0 to 11451\n",
      "Columns: 595 entries, time_diff to 1653\n",
      "dtypes: float64(4), uint8(591)\n",
      "memory usage: 7.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify columns for standardization scaling (Z-score normalization)\n",
    "cols_to_std = []\n",
    "\n",
    "# specify columns for min-max scaling\n",
    "# offered_discount, price, weight_kg, purchase_datetime_delta\n",
    "cols_to_min_max = ['price', 'weight_kg', 'purchase_datetime_delta']\n",
    "# cols_to_min_max = ['weight_kg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "for col in cols_to_std:\n",
    "    x = df[col].values\n",
    "    std_scaler = StandardScaler()\n",
    "    x_scaled = std_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    df[col] = x_scaled\n",
    "\n",
    "for col in cols_to_min_max:\n",
    "    x = df[col].values\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x.reshape(-1, 1))\n",
    "    df[col] = x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_diff</th>\n",
       "      <th>price</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>purchase_datetime_delta</th>\n",
       "      <th>516</th>\n",
       "      <th>620</th>\n",
       "      <th>Kraków</th>\n",
       "      <th>Poznań</th>\n",
       "      <th>Radom</th>\n",
       "      <th>Szczecin</th>\n",
       "      <th>...</th>\n",
       "      <th>1627</th>\n",
       "      <th>1628</th>\n",
       "      <th>1629</th>\n",
       "      <th>1630</th>\n",
       "      <th>1631</th>\n",
       "      <th>1632</th>\n",
       "      <th>1633</th>\n",
       "      <th>1634</th>\n",
       "      <th>1635</th>\n",
       "      <th>1653</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194397.0</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.459215</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184285.0</td>\n",
       "      <td>0.406238</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.191245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164705.0</td>\n",
       "      <td>0.665416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>252885.0</td>\n",
       "      <td>0.448400</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.822722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228672.0</td>\n",
       "      <td>0.032173</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.343154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 595 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_diff     price  weight_kg  purchase_datetime_delta  516  620  Kraków  \\\n",
       "0   194397.0  0.228930   0.020000                 0.459215    0    1       0   \n",
       "1   184285.0  0.406238   0.000800                 0.191245    0    1       0   \n",
       "2   164705.0  0.665416   0.000000                 0.082285    0    0       0   \n",
       "3   252885.0  0.448400   0.010667                 0.822722    0    1       0   \n",
       "4   228672.0  0.032173   0.008667                 0.343154    1    0       0   \n",
       "\n",
       "   Poznań  Radom  Szczecin  ...  1627  1628  1629  1630  1631  1632  1633  \\\n",
       "0       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "1       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "2       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "3       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "4       1      0         0  ...     0     0     0     0     0     0     0   \n",
       "\n",
       "   1634  1635  1653  \n",
       "0     0     0     0  \n",
       "1     0     0     0  \n",
       "2     0     0     0  \n",
       "3     0     0     0  \n",
       "4     0     0     0  \n",
       "\n",
       "[5 rows x 595 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def split_data(df, target_column=\"time_diff\"):\n",
    "    y = df[\"time_diff\"].to_numpy()\n",
    "    X = df.drop(columns=\"time_diff\")\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(models_list, X_train, y_train):\n",
    "    for model in models_list:\n",
    "        model.fit(X_train, y_train)\n",
    "    return models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_predictions(models_list, X_test, y_test):\n",
    "    y_pred_df = pd.DataFrame()\n",
    "    y_pred_df[\"y_test\"] = y_test\n",
    "    for model in models_list:\n",
    "        y_pred_df[f\"{type(model).__name__} prediction\"] = model.predict(X_test)\n",
    "    return y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(y_pred_df):\n",
    "    display(y_pred_df.head())\n",
    "    display(y_pred_df.info())\n",
    "    display(y_pred_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(models_list, X_test, y_test):\n",
    "    for model in models_list:\n",
    "        score = model.score(X_test, y_test)\n",
    "        print(f\"{type(model).__name__} score = {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percent_of_good_predictions(models_list, X_test, y_test, error=NUM_OF_HOURS*60*60):\n",
    "    for model in models_list:\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions_time_diff = np.abs(y_test - predictions)\n",
    "        num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "        percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "        print(f'number of good predictions for {type(model).__name__} = {num_of_good_predictions}')\n",
    "        print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# models_list = [Ridge(alpha=0.1),\n",
    "#                Lasso(alpha=0.1),\n",
    "#                DecisionTreeRegressor(random_state=SEED),\n",
    "#                RandomForestRegressor(random_state=SEED)]\n",
    "# models_list = train_models(models_list, X_train, y_train)\n",
    "\n",
    "# y_pred_df = create_df_with_predictions(models_list, X_test, y_test)\n",
    "# # display_predictions(y_pred_df)\n",
    "\n",
    "# print_scores(models_list, X_test, y_test)\n",
    "\n",
    "# print_percent_of_good_predictions(models_list, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 61319774208.0000 - mae: 233531.9062 - val_loss: 59746390016.0000 - val_mae: 231076.7656\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 61316800512.0000 - mae: 233530.4688 - val_loss: 59744972800.0000 - val_mae: 231076.6406\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 61312974848.0000 - mae: 233527.7344 - val_loss: 59742474240.0000 - val_mae: 231075.6875\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 61308608512.0000 - mae: 233523.4062 - val_loss: 59743580160.0000 - val_mae: 231082.8750\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 61303341056.0000 - mae: 233517.6562 - val_loss: 59737665536.0000 - val_mae: 231075.5000\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 61297020928.0000 - mae: 233510.3281 - val_loss: 59728510976.0000 - val_mae: 231062.0000\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 61289635840.0000 - mae: 233501.6094 - val_loss: 59721945088.0000 - val_mae: 231054.7344\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 61281308672.0000 - mae: 233491.1719 - val_loss: 59706355712.0000 - val_mae: 231028.2031\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 61271789568.0000 - mae: 233479.0625 - val_loss: 59698270208.0000 - val_mae: 231017.7344\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 61261295616.0000 - mae: 233465.4219 - val_loss: 59688054784.0000 - val_mae: 231002.8438\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 61249835008.0000 - mae: 233450.1875 - val_loss: 59680006144.0000 - val_mae: 230993.1250\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 61237293056.0000 - mae: 233433.2188 - val_loss: 59668889600.0000 - val_mae: 230976.4219\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 61223759872.0000 - mae: 233415.1094 - val_loss: 59667935232.0000 - val_mae: 230982.6094\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 61209411584.0000 - mae: 233395.1250 - val_loss: 59658649600.0000 - val_mae: 230970.8281\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 61193773056.0000 - mae: 233373.5469 - val_loss: 59646803968.0000 - val_mae: 230957.0469\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 61176688640.0000 - mae: 233350.0312 - val_loss: 59626831872.0000 - val_mae: 230925.1719\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 61158727680.0000 - mae: 233325.2656 - val_loss: 59617767424.0000 - val_mae: 230916.5312\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 61140201472.0000 - mae: 233299.3750 - val_loss: 59605712896.0000 - val_mae: 230904.5312\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 61120315392.0000 - mae: 233271.1562 - val_loss: 59589677056.0000 - val_mae: 230881.5000\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 61099970560.0000 - mae: 233242.1562 - val_loss: 59555155968.0000 - val_mae: 230820.7656\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 61078069248.0000 - mae: 233210.8750 - val_loss: 59541254144.0000 - val_mae: 230803.0781\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 61055983616.0000 - mae: 233178.8281 - val_loss: 59510910976.0000 - val_mae: 230753.9062\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 61032894464.0000 - mae: 233145.6562 - val_loss: 59493253120.0000 - val_mae: 230731.6562\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 61008650240.0000 - mae: 233110.0938 - val_loss: 59470966784.0000 - val_mae: 230697.3594\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 60983373824.0000 - mae: 233073.1875 - val_loss: 59424477184.0000 - val_mae: 230612.2344\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60957962240.0000 - mae: 233035.8906 - val_loss: 59425570816.0000 - val_mae: 230629.2812\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 60930707456.0000 - mae: 232995.6250 - val_loss: 59361951744.0000 - val_mae: 230508.0312\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60904161280.0000 - mae: 232956.0781 - val_loss: 59358003200.0000 - val_mae: 230509.7500\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 60875411456.0000 - mae: 232913.1562 - val_loss: 59330179072.0000 - val_mae: 230466.0781\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60846387200.0000 - mae: 232871.0312 - val_loss: 59281080320.0000 - val_mae: 230375.3125\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 60816760832.0000 - mae: 232826.0469 - val_loss: 59278409728.0000 - val_mae: 230385.6875\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60785565696.0000 - mae: 232779.4219 - val_loss: 59219812352.0000 - val_mae: 230279.6094\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60753797120.0000 - mae: 232730.5469 - val_loss: 59208249344.0000 - val_mae: 230272.8125\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60721672192.0000 - mae: 232683.3906 - val_loss: 59197100032.0000 - val_mae: 230262.7188\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 60688818176.0000 - mae: 232632.9219 - val_loss: 59131727872.0000 - val_mae: 230134.4375\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 60656066560.0000 - mae: 232583.9062 - val_loss: 59110064128.0000 - val_mae: 230103.4688\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60619718656.0000 - mae: 232528.6562 - val_loss: 59070980096.0000 - val_mae: 230043.7656\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60585365504.0000 - mae: 232476.7656 - val_loss: 59031810048.0000 - val_mae: 229975.6406\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60548968448.0000 - mae: 232420.7031 - val_loss: 58995318784.0000 - val_mae: 229920.2656\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60513447936.0000 - mae: 232365.9844 - val_loss: 58952269824.0000 - val_mae: 229841.4531\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60474404864.0000 - mae: 232307.3594 - val_loss: 58961637376.0000 - val_mae: 229868.1406\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60437970944.0000 - mae: 232251.1094 - val_loss: 58914787328.0000 - val_mae: 229795.4844\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 60399943680.0000 - mae: 232192.2188 - val_loss: 58880491520.0000 - val_mae: 229746.5312\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60358017024.0000 - mae: 232128.6250 - val_loss: 58775625728.0000 - val_mae: 229535.1875\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60320571392.0000 - mae: 232070.2969 - val_loss: 58742984704.0000 - val_mae: 229484.8281\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60278009856.0000 - mae: 232004.8125 - val_loss: 58730848256.0000 - val_mae: 229477.1719\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60236673024.0000 - mae: 231941.5000 - val_loss: 58673065984.0000 - val_mae: 229371.0000\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 60193959936.0000 - mae: 231874.6250 - val_loss: 58661625856.0000 - val_mae: 229364.9531\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60152520704.0000 - mae: 231810.4688 - val_loss: 58644418560.0000 - val_mae: 229353.3438\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60109324288.0000 - mae: 231744.2188 - val_loss: 58590158848.0000 - val_mae: 229254.2812\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 60065005568.0000 - mae: 231674.7188 - val_loss: 58607554560.0000 - val_mae: 229292.8125\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 60019712000.0000 - mae: 231606.3594 - val_loss: 58456002560.0000 - val_mae: 228998.3281\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 59975094272.0000 - mae: 231533.6875 - val_loss: 58477768704.0000 - val_mae: 229066.3281\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 59929317376.0000 - mae: 231464.0781 - val_loss: 58433552384.0000 - val_mae: 228994.3125\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59882291200.0000 - mae: 231391.0312 - val_loss: 58328711168.0000 - val_mae: 228799.9219\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59833839616.0000 - mae: 231315.7500 - val_loss: 58331484160.0000 - val_mae: 228804.7188\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 59786481664.0000 - mae: 231240.8125 - val_loss: 58260443136.0000 - val_mae: 228671.6562\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59739901952.0000 - mae: 231167.7031 - val_loss: 58213040128.0000 - val_mae: 228603.0469\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59691286528.0000 - mae: 231091.9844 - val_loss: 58231906304.0000 - val_mae: 228661.9219\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59638722560.0000 - mae: 231010.0938 - val_loss: 58170130432.0000 - val_mae: 228559.4375\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59591585792.0000 - mae: 230933.7969 - val_loss: 58119147520.0000 - val_mae: 228459.4531\n",
      "Epoch 62/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 59540697088.0000 - mae: 230853.9844 - val_loss: 58048679936.0000 - val_mae: 228332.2656\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59488083968.0000 - mae: 230773.1250 - val_loss: 58077782016.0000 - val_mae: 228422.6250\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59433664512.0000 - mae: 230685.9688 - val_loss: 57996152832.0000 - val_mae: 228262.8281\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59386789888.0000 - mae: 230612.4375 - val_loss: 57909624832.0000 - val_mae: 228103.5938\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59331633152.0000 - mae: 230525.1250 - val_loss: 57806897152.0000 - val_mae: 227924.2656\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 59275546624.0000 - mae: 230435.9688 - val_loss: 57772388352.0000 - val_mae: 227854.0156\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59219963904.0000 - mae: 230349.1562 - val_loss: 57709539328.0000 - val_mae: 227737.2188\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 59170471936.0000 - mae: 230269.5469 - val_loss: 57673121792.0000 - val_mae: 227704.6250\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 59113295872.0000 - mae: 230179.0469 - val_loss: 57714012160.0000 - val_mae: 227817.8906\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 59057963008.0000 - mae: 230090.6250 - val_loss: 57612386304.0000 - val_mae: 227605.8281\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 59003297792.0000 - mae: 230001.7969 - val_loss: 57469861888.0000 - val_mae: 227341.9375\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 58943717376.0000 - mae: 229907.6406 - val_loss: 57547890688.0000 - val_mae: 227511.1094\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 58889175040.0000 - mae: 229820.6250 - val_loss: 57478873088.0000 - val_mae: 227401.9531\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 58831233024.0000 - mae: 229729.6250 - val_loss: 57422524416.0000 - val_mae: 227293.1875\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 58777755648.0000 - mae: 229641.2500 - val_loss: 57333714944.0000 - val_mae: 227139.0156\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 58715205632.0000 - mae: 229544.7031 - val_loss: 57306038272.0000 - val_mae: 227069.7344\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 58654380032.0000 - mae: 229447.2188 - val_loss: 57235685376.0000 - val_mae: 226952.5469\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 58595328000.0000 - mae: 229352.2656 - val_loss: 57148968960.0000 - val_mae: 226814.1094\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 58536321024.0000 - mae: 229256.3906 - val_loss: 57162256384.0000 - val_mae: 226848.8125\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 58475982848.0000 - mae: 229159.4219 - val_loss: 57080254464.0000 - val_mae: 226693.6406\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 58417647616.0000 - mae: 229064.1250 - val_loss: 57031659520.0000 - val_mae: 226605.2969\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 58352316416.0000 - mae: 228961.5781 - val_loss: 56892452864.0000 - val_mae: 226343.7031\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 58288181248.0000 - mae: 228859.3594 - val_loss: 56892420096.0000 - val_mae: 226357.2812\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 58224930816.0000 - mae: 228756.9688 - val_loss: 56854323200.0000 - val_mae: 226323.1094\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 58166358016.0000 - mae: 228657.8281 - val_loss: 56834985984.0000 - val_mae: 226311.9062\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 58107203584.0000 - mae: 228564.6875 - val_loss: 56711393280.0000 - val_mae: 226072.7812\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 58039005184.0000 - mae: 228454.5938 - val_loss: 56623046656.0000 - val_mae: 225875.0469\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57969942528.0000 - mae: 228341.2031 - val_loss: 56572133376.0000 - val_mae: 225793.4844\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57910525952.0000 - mae: 228243.9531 - val_loss: 56506290176.0000 - val_mae: 225694.3750\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 57844314112.0000 - mae: 228138.9688 - val_loss: 56554647552.0000 - val_mae: 225811.5625\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57776996352.0000 - mae: 228029.8594 - val_loss: 56416378880.0000 - val_mae: 225549.0312\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 57714266112.0000 - mae: 227925.3594 - val_loss: 56322940928.0000 - val_mae: 225342.3438\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 57646854144.0000 - mae: 227818.3750 - val_loss: 56342929408.0000 - val_mae: 225424.4531\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57579360256.0000 - mae: 227707.1562 - val_loss: 56274317312.0000 - val_mae: 225324.8906\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57514614784.0000 - mae: 227601.7812 - val_loss: 56043253760.0000 - val_mae: 224857.6406\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57446506496.0000 - mae: 227489.3281 - val_loss: 56115535872.0000 - val_mae: 225067.0156\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57372233728.0000 - mae: 227371.3438 - val_loss: 55981051904.0000 - val_mae: 224809.2500\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57308065792.0000 - mae: 227264.7344 - val_loss: 55925129216.0000 - val_mae: 224664.2656\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57238343680.0000 - mae: 227148.2656 - val_loss: 55937990656.0000 - val_mae: 224727.7500\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 57169580032.0000 - mae: 227038.0625 - val_loss: 55781969920.0000 - val_mae: 224449.2812\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 57101230080.0000 - mae: 226922.5000 - val_loss: 55776858112.0000 - val_mae: 224424.1094\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 57026568192.0000 - mae: 226800.2969 - val_loss: 55516057600.0000 - val_mae: 223921.3281\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 56956719104.0000 - mae: 226690.6250 - val_loss: 55682756608.0000 - val_mae: 224294.8281\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 56886448128.0000 - mae: 226571.9531 - val_loss: 55590936576.0000 - val_mae: 224109.5781\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 56809861120.0000 - mae: 226444.7500 - val_loss: 55456915456.0000 - val_mae: 223819.4844\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 56741830656.0000 - mae: 226333.6250 - val_loss: 55481217024.0000 - val_mae: 223923.7500\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 56667201536.0000 - mae: 226208.5000 - val_loss: 55388372992.0000 - val_mae: 223733.9844\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 56600133632.0000 - mae: 226097.8906 - val_loss: 55239049216.0000 - val_mae: 223450.9375\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 56528957440.0000 - mae: 225976.3906 - val_loss: 55176646656.0000 - val_mae: 223352.7344\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 56454742016.0000 - mae: 225855.1719 - val_loss: 55037849600.0000 - val_mae: 223055.0781\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 56374788096.0000 - mae: 225722.8906 - val_loss: 54974353408.0000 - val_mae: 222995.7969\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 56308842496.0000 - mae: 225613.6406 - val_loss: 54971588608.0000 - val_mae: 222997.1250\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 56231784448.0000 - mae: 225487.7969 - val_loss: 54953938944.0000 - val_mae: 222923.6406\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 56152174592.0000 - mae: 225358.4531 - val_loss: 54907453440.0000 - val_mae: 222896.0469\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 56078897152.0000 - mae: 225228.6406 - val_loss: 54739689472.0000 - val_mae: 222593.3594\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 56004157440.0000 - mae: 225104.5625 - val_loss: 54580215808.0000 - val_mae: 222234.2969\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 55926882304.0000 - mae: 224977.2969 - val_loss: 54758121472.0000 - val_mae: 222633.5312\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 55849996288.0000 - mae: 224849.7344 - val_loss: 54617182208.0000 - val_mae: 222320.2031\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 55773601792.0000 - mae: 224723.5156 - val_loss: 54483939328.0000 - val_mae: 222085.0625\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 55693500416.0000 - mae: 224587.5000 - val_loss: 54250278912.0000 - val_mae: 221638.3281\n",
      "Epoch 122/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 55613497344.0000 - mae: 224454.5000 - val_loss: 54341914624.0000 - val_mae: 221852.2031\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 55536287744.0000 - mae: 224326.5625 - val_loss: 54249127936.0000 - val_mae: 221705.5469\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 55460110336.0000 - mae: 224197.3906 - val_loss: 54280544256.0000 - val_mae: 221807.7656\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 55381389312.0000 - mae: 224063.6562 - val_loss: 54038241280.0000 - val_mae: 221289.5938\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 55301951488.0000 - mae: 223931.8438 - val_loss: 53934088192.0000 - val_mae: 221066.2188\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 55222657024.0000 - mae: 223796.7500 - val_loss: 54095974400.0000 - val_mae: 221482.9375\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 55138672640.0000 - mae: 223655.0312 - val_loss: 53959045120.0000 - val_mae: 221203.7500\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 55069630464.0000 - mae: 223532.6250 - val_loss: 53789274112.0000 - val_mae: 220828.2188\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 54976991232.0000 - mae: 223383.8906 - val_loss: 53702295552.0000 - val_mae: 220705.5625\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 54906781696.0000 - mae: 223260.5000 - val_loss: 53593485312.0000 - val_mae: 220481.1719\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 54823137280.0000 - mae: 223120.9375 - val_loss: 53608595456.0000 - val_mae: 220563.9375\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 54738284544.0000 - mae: 222975.1562 - val_loss: 53595324416.0000 - val_mae: 220539.2188\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 54667358208.0000 - mae: 222851.0156 - val_loss: 53384773632.0000 - val_mae: 220147.0781\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 54579654656.0000 - mae: 222708.2031 - val_loss: 53420871680.0000 - val_mae: 220255.6875\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 54495195136.0000 - mae: 222560.2031 - val_loss: 53475889152.0000 - val_mae: 220413.7500\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 54409117696.0000 - mae: 222418.0156 - val_loss: 53258309632.0000 - val_mae: 219922.0469\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 54329196544.0000 - mae: 222276.0938 - val_loss: 53146513408.0000 - val_mae: 219693.0000\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 54243827712.0000 - mae: 222132.9531 - val_loss: 52902969344.0000 - val_mae: 219229.4688\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 54156484608.0000 - mae: 221989.1875 - val_loss: 52963897344.0000 - val_mae: 219363.5469\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 54075469824.0000 - mae: 221849.2656 - val_loss: 52954157056.0000 - val_mae: 219437.3906\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 53999673344.0000 - mae: 221708.2656 - val_loss: 52898967552.0000 - val_mae: 219283.3125\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 53901565952.0000 - mae: 221544.7188 - val_loss: 52717314048.0000 - val_mae: 218931.2500\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 53825347584.0000 - mae: 221418.9062 - val_loss: 52598484992.0000 - val_mae: 218636.4531\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 53738213376.0000 - mae: 221266.2031 - val_loss: 52412579840.0000 - val_mae: 218284.7969\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 53655117824.0000 - mae: 221117.2188 - val_loss: 52472942592.0000 - val_mae: 218443.4219\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 53565644800.0000 - mae: 220973.0938 - val_loss: 52301803520.0000 - val_mae: 218181.1094\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 53483364352.0000 - mae: 220826.9219 - val_loss: 52547768320.0000 - val_mae: 218681.2344\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 53400608768.0000 - mae: 220683.0625 - val_loss: 52153585664.0000 - val_mae: 217812.0469\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 53314355200.0000 - mae: 220526.7812 - val_loss: 52052766720.0000 - val_mae: 217672.6562\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 53217746944.0000 - mae: 220360.4062 - val_loss: 51970777088.0000 - val_mae: 217445.3125\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 53132402688.0000 - mae: 220215.9844 - val_loss: 52089278464.0000 - val_mae: 217801.1094\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 53043154944.0000 - mae: 220063.9531 - val_loss: 52026368000.0000 - val_mae: 217683.3125\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 52954734592.0000 - mae: 219911.2656 - val_loss: 51888865280.0000 - val_mae: 217377.3125\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 52870901760.0000 - mae: 219763.1562 - val_loss: 51559895040.0000 - val_mae: 216660.9219\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 52779827200.0000 - mae: 219606.1406 - val_loss: 51788840960.0000 - val_mae: 217164.9531\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 52685717504.0000 - mae: 219434.1719 - val_loss: 51703369728.0000 - val_mae: 217080.5625\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 52586332160.0000 - mae: 219263.8438 - val_loss: 51395903488.0000 - val_mae: 216444.1562\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 52504502272.0000 - mae: 219123.6562 - val_loss: 51502014464.0000 - val_mae: 216645.8281\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 52423536640.0000 - mae: 218975.1406 - val_loss: 51270258688.0000 - val_mae: 216160.4375\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 52327809024.0000 - mae: 218808.9531 - val_loss: 51225296896.0000 - val_mae: 216080.5156\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 52240617472.0000 - mae: 218658.7969 - val_loss: 51291758592.0000 - val_mae: 216387.2031\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 52141289472.0000 - mae: 218482.8594 - val_loss: 51084079104.0000 - val_mae: 215874.5625\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 52060278784.0000 - mae: 218338.0469 - val_loss: 50987954176.0000 - val_mae: 215776.0156\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 51968487424.0000 - mae: 218176.0781 - val_loss: 50670919680.0000 - val_mae: 215072.4844\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 51881328640.0000 - mae: 218016.9688 - val_loss: 50959646720.0000 - val_mae: 215676.2031\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 51795173376.0000 - mae: 217871.5469 - val_loss: 50914721792.0000 - val_mae: 215576.7188\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 51706347520.0000 - mae: 217703.0625 - val_loss: 50566561792.0000 - val_mae: 214855.5000\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 51607777280.0000 - mae: 217544.3281 - val_loss: 50668625920.0000 - val_mae: 215066.7812\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 51515088896.0000 - mae: 217368.8906 - val_loss: 50574798848.0000 - val_mae: 214951.7344\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 51394297856.0000 - mae: 217162.8594 - val_loss: 50427822080.0000 - val_mae: 214613.4219\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 51318181888.0000 - mae: 217024.7812 - val_loss: 50264555520.0000 - val_mae: 214245.2812\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 51239079936.0000 - mae: 216881.3281 - val_loss: 50045231104.0000 - val_mae: 213823.0312\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 51142082560.0000 - mae: 216708.5000 - val_loss: 50026508288.0000 - val_mae: 213761.9062\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 51044777984.0000 - mae: 216534.5469 - val_loss: 50122100736.0000 - val_mae: 214094.0625\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 50949828608.0000 - mae: 216362.1250 - val_loss: 49966518272.0000 - val_mae: 213769.4844\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 50848546816.0000 - mae: 216177.2969 - val_loss: 49883332608.0000 - val_mae: 213575.8750\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 50739163136.0000 - mae: 215994.9375 - val_loss: 49809780736.0000 - val_mae: 213462.5625\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 50680221696.0000 - mae: 215875.4219 - val_loss: 49477689344.0000 - val_mae: 212632.0156\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 50565566464.0000 - mae: 215671.4375 - val_loss: 49509912576.0000 - val_mae: 212808.6719\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 50478211072.0000 - mae: 215510.3906 - val_loss: 49509494784.0000 - val_mae: 212862.7656\n",
      "Epoch 182/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 50370277376.0000 - mae: 215319.5938 - val_loss: 49450369024.0000 - val_mae: 212779.1406\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 50277318656.0000 - mae: 215155.6719 - val_loss: 49379135488.0000 - val_mae: 212582.2188\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 50180194304.0000 - mae: 214984.3125 - val_loss: 49026441216.0000 - val_mae: 211843.7969\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 50074923008.0000 - mae: 214797.2344 - val_loss: 48928866304.0000 - val_mae: 211678.4375\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 49980616704.0000 - mae: 214609.6719 - val_loss: 49121726464.0000 - val_mae: 212103.3281\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 49905803264.0000 - mae: 214476.8750 - val_loss: 49015132160.0000 - val_mae: 211828.4531\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 49809010688.0000 - mae: 214303.3438 - val_loss: 48925036544.0000 - val_mae: 211723.4375\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 49683988480.0000 - mae: 214072.0312 - val_loss: 48721678336.0000 - val_mae: 211289.0000\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 49612718080.0000 - mae: 213942.7500 - val_loss: 48501198848.0000 - val_mae: 210879.5000\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 49508114432.0000 - mae: 213761.3125 - val_loss: 48448458752.0000 - val_mae: 210718.0469\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 49411764224.0000 - mae: 213577.9688 - val_loss: 48559751168.0000 - val_mae: 210982.2969\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 49305108480.0000 - mae: 213380.0938 - val_loss: 48285249536.0000 - val_mae: 210426.4531\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 49208029184.0000 - mae: 213215.7188 - val_loss: 48386015232.0000 - val_mae: 210617.1250\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 49122156544.0000 - mae: 213046.3906 - val_loss: 48010805248.0000 - val_mae: 209950.2969\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 49015488512.0000 - mae: 212850.3750 - val_loss: 48140451840.0000 - val_mae: 210196.4062\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48907866112.0000 - mae: 212652.6875 - val_loss: 47739416576.0000 - val_mae: 209294.0312\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48809283584.0000 - mae: 212475.7188 - val_loss: 48033046528.0000 - val_mae: 209971.3594\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48720306176.0000 - mae: 212306.1875 - val_loss: 47917621248.0000 - val_mae: 209664.4531\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48611401728.0000 - mae: 212109.9062 - val_loss: 47625555968.0000 - val_mae: 209061.4375\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48530862080.0000 - mae: 211948.9375 - val_loss: 47607836672.0000 - val_mae: 209081.3125\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 48415612928.0000 - mae: 211736.7031 - val_loss: 47331663872.0000 - val_mae: 208455.1562\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48305057792.0000 - mae: 211533.6094 - val_loss: 47272669184.0000 - val_mae: 208425.5312\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48217825280.0000 - mae: 211369.9688 - val_loss: 47586734080.0000 - val_mae: 209075.5781\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48114069504.0000 - mae: 211180.2500 - val_loss: 47227711488.0000 - val_mae: 208309.2812\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 48011280384.0000 - mae: 210995.0000 - val_loss: 47213318144.0000 - val_mae: 208209.5938\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 47919771648.0000 - mae: 210809.5156 - val_loss: 47203565568.0000 - val_mae: 208273.9062\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 47811362816.0000 - mae: 210612.1875 - val_loss: 47272398848.0000 - val_mae: 208464.6094\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 47715434496.0000 - mae: 210435.8281 - val_loss: 46877822976.0000 - val_mae: 207550.7188\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 47599206400.0000 - mae: 210219.6719 - val_loss: 46802468864.0000 - val_mae: 207338.5469\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 47487377408.0000 - mae: 210019.7188 - val_loss: 46742835200.0000 - val_mae: 207377.4219\n",
      "Epoch 212/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 47397584896.0000 - mae: 209834.5625 - val_loss: 46453587968.0000 - val_mae: 206728.8750\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 47278526464.0000 - mae: 209619.8281 - val_loss: 46428672000.0000 - val_mae: 206584.6406\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 47200026624.0000 - mae: 209464.7031 - val_loss: 46258233344.0000 - val_mae: 206307.3438\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 47101956096.0000 - mae: 209274.5938 - val_loss: 46444851200.0000 - val_mae: 206768.9531\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 46989148160.0000 - mae: 209060.2812 - val_loss: 46293438464.0000 - val_mae: 206491.4375\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 46883373056.0000 - mae: 208869.5781 - val_loss: 45918638080.0000 - val_mae: 205512.9062\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 46784679936.0000 - mae: 208667.0781 - val_loss: 45773250560.0000 - val_mae: 205283.0000\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 46676881408.0000 - mae: 208481.4844 - val_loss: 45762531328.0000 - val_mae: 205292.4844\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 46577782784.0000 - mae: 208280.8906 - val_loss: 46041382912.0000 - val_mae: 205909.5781\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 46472986624.0000 - mae: 208073.2031 - val_loss: 45655601152.0000 - val_mae: 205121.8906\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 46363271168.0000 - mae: 207873.9062 - val_loss: 45816897536.0000 - val_mae: 205456.9844\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 46260101120.0000 - mae: 207676.9531 - val_loss: 45879586816.0000 - val_mae: 205653.0469\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 46161747968.0000 - mae: 207482.7188 - val_loss: 45374451712.0000 - val_mae: 204456.9844\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 46038409216.0000 - mae: 207253.8906 - val_loss: 45681057792.0000 - val_mae: 205101.6875\n",
      "Epoch 226/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 45950078976.0000 - mae: 207070.8125 - val_loss: 44883398656.0000 - val_mae: 203292.6719\n",
      "Epoch 227/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 45843767296.0000 - mae: 206868.0156 - val_loss: 45018034176.0000 - val_mae: 203675.7656\n",
      "Epoch 228/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 45725933568.0000 - mae: 206646.3281 - val_loss: 45228269568.0000 - val_mae: 204247.5469\n",
      "Epoch 229/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 45614112768.0000 - mae: 206433.1250 - val_loss: 44929933312.0000 - val_mae: 203595.1562\n",
      "Epoch 230/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 45526224896.0000 - mae: 206257.7812 - val_loss: 44722302976.0000 - val_mae: 203117.5781\n",
      "Epoch 231/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 45423886336.0000 - mae: 206053.6094 - val_loss: 44710072320.0000 - val_mae: 203071.2969\n",
      "Epoch 232/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 45298483200.0000 - mae: 205821.4531 - val_loss: 44537217024.0000 - val_mae: 202633.8125\n",
      "Epoch 233/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 45210542080.0000 - mae: 205628.9531 - val_loss: 44539105280.0000 - val_mae: 202790.5156\n",
      "Epoch 234/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 45105614848.0000 - mae: 205424.2812 - val_loss: 44530245632.0000 - val_mae: 202758.9844\n",
      "Epoch 235/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 44995477504.0000 - mae: 205208.5469 - val_loss: 44525072384.0000 - val_mae: 202680.7344\n",
      "Epoch 236/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 44895404032.0000 - mae: 205025.3125 - val_loss: 44103413760.0000 - val_mae: 201801.7500\n",
      "Epoch 237/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 44778283008.0000 - mae: 204800.6875 - val_loss: 43871576064.0000 - val_mae: 201366.0000\n",
      "Epoch 238/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 44680519680.0000 - mae: 204599.0625 - val_loss: 44103569408.0000 - val_mae: 201818.2344\n",
      "Epoch 239/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 44577329152.0000 - mae: 204388.0938 - val_loss: 43921104896.0000 - val_mae: 201360.9062\n",
      "Epoch 240/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 44454244352.0000 - mae: 204153.5781 - val_loss: 43800469504.0000 - val_mae: 201196.7344\n",
      "Epoch 241/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 44355346432.0000 - mae: 203948.1406 - val_loss: 43696607232.0000 - val_mae: 200850.4844\n",
      "Epoch 242/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 44240576512.0000 - mae: 203724.8906 - val_loss: 43657994240.0000 - val_mae: 200768.6875\n",
      "Epoch 243/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 44154728448.0000 - mae: 203558.1094 - val_loss: 43525193728.0000 - val_mae: 200547.6406\n",
      "Epoch 244/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 44041216000.0000 - mae: 203341.8281 - val_loss: 43359174656.0000 - val_mae: 200118.3906\n",
      "Epoch 245/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 43908603904.0000 - mae: 203067.0156 - val_loss: 43437674496.0000 - val_mae: 200382.3594\n",
      "Epoch 246/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 43831721984.0000 - mae: 202909.4844 - val_loss: 42869940224.0000 - val_mae: 199044.7656\n",
      "Epoch 247/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 43713839104.0000 - mae: 202679.8906 - val_loss: 43271106560.0000 - val_mae: 200024.3906\n",
      "Epoch 248/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 43579052032.0000 - mae: 202428.0781 - val_loss: 42947481600.0000 - val_mae: 199214.6250\n",
      "Epoch 249/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 43503521792.0000 - mae: 202250.0625 - val_loss: 43161526272.0000 - val_mae: 199782.3594\n",
      "Epoch 250/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 43383398400.0000 - mae: 202032.3125 - val_loss: 43093454848.0000 - val_mae: 199695.3750\n",
      "Epoch 251/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 43264815104.0000 - mae: 201781.6250 - val_loss: 42539057152.0000 - val_mae: 198348.5469\n",
      "Epoch 252/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 43185442816.0000 - mae: 201595.3125 - val_loss: 42661298176.0000 - val_mae: 198659.2812\n",
      "Epoch 253/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 43064111104.0000 - mae: 201364.2188 - val_loss: 42455801856.0000 - val_mae: 198196.2812\n",
      "Epoch 254/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 42944970752.0000 - mae: 201144.9219 - val_loss: 42656964608.0000 - val_mae: 198710.6875\n",
      "Epoch 255/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 42819739648.0000 - mae: 200879.6875 - val_loss: 42466971648.0000 - val_mae: 198328.9688\n",
      "Epoch 256/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 42746155008.0000 - mae: 200731.7656 - val_loss: 42318675968.0000 - val_mae: 197940.3438\n",
      "Epoch 257/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 42638815232.0000 - mae: 200494.4062 - val_loss: 41838391296.0000 - val_mae: 196826.7500\n",
      "Epoch 258/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 42525425664.0000 - mae: 200273.2656 - val_loss: 42288087040.0000 - val_mae: 197960.1875\n",
      "Epoch 259/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 42396917760.0000 - mae: 200009.6406 - val_loss: 42107101184.0000 - val_mae: 197534.1406\n",
      "Epoch 260/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 42284646400.0000 - mae: 199792.1875 - val_loss: 41771610112.0000 - val_mae: 196704.2344\n",
      "Epoch 261/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 42206736384.0000 - mae: 199608.2500 - val_loss: 41511284736.0000 - val_mae: 196118.2344\n",
      "Epoch 262/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 42082545664.0000 - mae: 199378.6094 - val_loss: 41639710720.0000 - val_mae: 196523.7031\n",
      "Epoch 263/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 41967628288.0000 - mae: 199134.2969 - val_loss: 41243975680.0000 - val_mae: 195543.2344\n",
      "Epoch 264/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 41848066048.0000 - mae: 198886.0781 - val_loss: 41189814272.0000 - val_mae: 195344.7188\n",
      "Epoch 265/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 41737138176.0000 - mae: 198652.8906 - val_loss: 41377300480.0000 - val_mae: 195869.2812\n",
      "Epoch 266/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 41638690816.0000 - mae: 198458.1719 - val_loss: 41360363520.0000 - val_mae: 195815.0312\n",
      "Epoch 267/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 41536036864.0000 - mae: 198238.2812 - val_loss: 40900943872.0000 - val_mae: 194649.8906\n",
      "Epoch 268/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 41434259456.0000 - mae: 198030.2812 - val_loss: 40954703872.0000 - val_mae: 194804.6406\n",
      "Epoch 269/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 41311334400.0000 - mae: 197768.7344 - val_loss: 40667774976.0000 - val_mae: 194253.5156\n",
      "Epoch 270/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 41215025152.0000 - mae: 197576.7969 - val_loss: 40671850496.0000 - val_mae: 194270.6094\n",
      "Epoch 271/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 41094512640.0000 - mae: 197317.2500 - val_loss: 40629293056.0000 - val_mae: 194165.0000\n",
      "Epoch 272/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 40966275072.0000 - mae: 197049.9688 - val_loss: 40879017984.0000 - val_mae: 194767.2969\n",
      "Epoch 273/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 40874586112.0000 - mae: 196839.1250 - val_loss: 40561246208.0000 - val_mae: 193967.0781\n",
      "Epoch 274/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 40756953088.0000 - mae: 196613.9844 - val_loss: 40301240320.0000 - val_mae: 193360.5938\n",
      "Epoch 275/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 40645861376.0000 - mae: 196380.6875 - val_loss: 40551448576.0000 - val_mae: 193999.4375\n",
      "Epoch 276/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 40524861440.0000 - mae: 196128.2500 - val_loss: 40301465600.0000 - val_mae: 193397.8906\n",
      "Epoch 277/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 40439730176.0000 - mae: 195911.3281 - val_loss: 40241029120.0000 - val_mae: 193243.0469\n",
      "Epoch 278/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 40314617856.0000 - mae: 195673.9688 - val_loss: 40095182848.0000 - val_mae: 192907.0156\n",
      "Epoch 279/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 40188497920.0000 - mae: 195423.6250 - val_loss: 39770705920.0000 - val_mae: 192041.4531\n",
      "Epoch 280/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 40107261952.0000 - mae: 195227.3281 - val_loss: 39970209792.0000 - val_mae: 192542.2969\n",
      "Epoch 281/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 40004943872.0000 - mae: 195023.6719 - val_loss: 39925112832.0000 - val_mae: 192562.9844\n",
      "Epoch 282/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 39857688576.0000 - mae: 194707.8125 - val_loss: 39558352896.0000 - val_mae: 191569.0469\n",
      "Epoch 283/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 39779123200.0000 - mae: 194525.8438 - val_loss: 39542738944.0000 - val_mae: 191632.3438\n",
      "Epoch 284/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 39632117760.0000 - mae: 194230.7969 - val_loss: 39568871424.0000 - val_mae: 191689.8125\n",
      "Epoch 285/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 39542087680.0000 - mae: 194002.5312 - val_loss: 38924144640.0000 - val_mae: 190094.4375\n",
      "Epoch 286/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 39422615552.0000 - mae: 193770.5469 - val_loss: 39129505792.0000 - val_mae: 190578.7500\n",
      "Epoch 287/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 39325102080.0000 - mae: 193535.4844 - val_loss: 38898343936.0000 - val_mae: 190104.4062\n",
      "Epoch 288/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 39218556928.0000 - mae: 193334.0469 - val_loss: 39372718080.0000 - val_mae: 191257.9688\n",
      "Epoch 289/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 39094632448.0000 - mae: 193057.0312 - val_loss: 38955331584.0000 - val_mae: 190214.1562\n",
      "Epoch 290/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 38979981312.0000 - mae: 192813.6250 - val_loss: 38689280000.0000 - val_mae: 189597.9531\n",
      "Epoch 291/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 38863790080.0000 - mae: 192555.0156 - val_loss: 38693478400.0000 - val_mae: 189624.0781\n",
      "Epoch 292/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 38768287744.0000 - mae: 192360.3594 - val_loss: 38961004544.0000 - val_mae: 190301.3281\n",
      "Epoch 293/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 38651252736.0000 - mae: 192089.0312 - val_loss: 38305452032.0000 - val_mae: 188524.8594\n",
      "Epoch 294/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 38525542400.0000 - mae: 191812.0938 - val_loss: 38196133888.0000 - val_mae: 188285.1094\n",
      "Epoch 295/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 38421774336.0000 - mae: 191589.4375 - val_loss: 38264320000.0000 - val_mae: 188531.9844\n",
      "Epoch 296/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 38317453312.0000 - mae: 191350.2656 - val_loss: 37880037376.0000 - val_mae: 187560.6406\n",
      "Epoch 297/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 38201602048.0000 - mae: 191083.2344 - val_loss: 38398992384.0000 - val_mae: 188911.0781\n",
      "Epoch 298/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 38084993024.0000 - mae: 190828.2500 - val_loss: 37375217664.0000 - val_mae: 186241.5156\n",
      "Epoch 299/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 37980528640.0000 - mae: 190597.4375 - val_loss: 37962543104.0000 - val_mae: 187905.6094\n",
      "Epoch 300/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 37857624064.0000 - mae: 190352.5781 - val_loss: 37916069888.0000 - val_mae: 187751.0625\n",
      "Epoch 301/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 37761515520.0000 - mae: 190125.2344 - val_loss: 37013282816.0000 - val_mae: 185392.6719\n",
      "Epoch 302/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 37646917632.0000 - mae: 189864.1094 - val_loss: 37722808320.0000 - val_mae: 187230.7344\n",
      "Epoch 303/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 37536034816.0000 - mae: 189634.0000 - val_loss: 37532336128.0000 - val_mae: 186750.4062\n",
      "Epoch 304/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 37414957056.0000 - mae: 189354.7031 - val_loss: 37141712896.0000 - val_mae: 185849.3438\n",
      "Epoch 305/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 37314220032.0000 - mae: 189118.5938 - val_loss: 37006045184.0000 - val_mae: 185462.0625\n",
      "Epoch 306/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 37187055616.0000 - mae: 188847.3906 - val_loss: 37127049216.0000 - val_mae: 185745.7656\n",
      "Epoch 307/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 37055025152.0000 - mae: 188557.6875 - val_loss: 37128781824.0000 - val_mae: 185825.3125\n",
      "Epoch 308/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 36949467136.0000 - mae: 188311.6719 - val_loss: 36765990912.0000 - val_mae: 184832.6094\n",
      "Epoch 309/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 36880003072.0000 - mae: 188159.2500 - val_loss: 36388134912.0000 - val_mae: 183840.4688\n",
      "Epoch 310/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 36732129280.0000 - mae: 187816.6562 - val_loss: 36658507776.0000 - val_mae: 184632.9219\n",
      "Epoch 311/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 36639805440.0000 - mae: 187620.1719 - val_loss: 37027962880.0000 - val_mae: 185553.6719\n",
      "Epoch 312/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 36513255424.0000 - mae: 187293.4219 - val_loss: 36639887360.0000 - val_mae: 184575.2344\n",
      "Epoch 313/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 36401639424.0000 - mae: 187058.4219 - val_loss: 36385628160.0000 - val_mae: 183911.2344\n",
      "Epoch 314/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 36305293312.0000 - mae: 186825.4375 - val_loss: 36290920448.0000 - val_mae: 183670.2188\n",
      "Epoch 315/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 36180103168.0000 - mae: 186540.7344 - val_loss: 36338647040.0000 - val_mae: 183883.3750\n",
      "Epoch 316/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 36071260160.0000 - mae: 186293.2812 - val_loss: 35920445440.0000 - val_mae: 182700.5000\n",
      "Epoch 317/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 35960332288.0000 - mae: 186028.8750 - val_loss: 35915358208.0000 - val_mae: 182769.0938\n",
      "Epoch 318/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 35854372864.0000 - mae: 185795.0312 - val_loss: 35963514880.0000 - val_mae: 182830.4531\n",
      "Epoch 319/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 35747622912.0000 - mae: 185497.6406 - val_loss: 35685253120.0000 - val_mae: 182086.3281\n",
      "Epoch 320/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 35622223872.0000 - mae: 185231.6719 - val_loss: 35501293568.0000 - val_mae: 181634.7031\n",
      "Epoch 321/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 35479052288.0000 - mae: 184916.3750 - val_loss: 35531051008.0000 - val_mae: 181694.9531\n",
      "Epoch 322/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 35408121856.0000 - mae: 184753.1875 - val_loss: 35496816640.0000 - val_mae: 181676.8125\n",
      "Epoch 323/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 35265826816.0000 - mae: 184429.3750 - val_loss: 35339952128.0000 - val_mae: 181196.3594\n",
      "Epoch 324/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 35169468416.0000 - mae: 184196.0938 - val_loss: 35546648576.0000 - val_mae: 181825.1094\n",
      "Epoch 325/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 35046273024.0000 - mae: 183919.2031 - val_loss: 35214995456.0000 - val_mae: 180943.5469\n",
      "Epoch 326/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 34944143360.0000 - mae: 183644.5312 - val_loss: 34619977728.0000 - val_mae: 179338.5000\n",
      "Epoch 327/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 34841047040.0000 - mae: 183424.4531 - val_loss: 34630115328.0000 - val_mae: 179341.8594\n",
      "Epoch 328/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 34738946048.0000 - mae: 183158.8438 - val_loss: 34750218240.0000 - val_mae: 179685.9688\n",
      "Epoch 329/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 34616057856.0000 - mae: 182876.9688 - val_loss: 34539515904.0000 - val_mae: 179160.9844\n",
      "Epoch 330/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 34483396608.0000 - mae: 182552.3906 - val_loss: 34706243584.0000 - val_mae: 179565.5312\n",
      "Epoch 331/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 34370076672.0000 - mae: 182318.0625 - val_loss: 34275139584.0000 - val_mae: 178349.7031\n",
      "Epoch 332/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 34302412800.0000 - mae: 182114.6094 - val_loss: 34613276672.0000 - val_mae: 179262.2500\n",
      "Epoch 333/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 34193971200.0000 - mae: 181883.1250 - val_loss: 34489229312.0000 - val_mae: 178883.7812\n",
      "Epoch 334/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 34060288000.0000 - mae: 181526.6719 - val_loss: 34264406016.0000 - val_mae: 178372.2344\n",
      "Epoch 335/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 33944797184.0000 - mae: 181252.0625 - val_loss: 33863688192.0000 - val_mae: 177285.4375\n",
      "Epoch 336/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 33847021568.0000 - mae: 180993.7969 - val_loss: 33399007232.0000 - val_mae: 175978.4375\n",
      "Epoch 337/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 33713455104.0000 - mae: 180725.8438 - val_loss: 33648963584.0000 - val_mae: 176682.1562\n",
      "Epoch 338/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 33620322304.0000 - mae: 180478.8906 - val_loss: 33795569664.0000 - val_mae: 177133.9844\n",
      "Epoch 339/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 33494124544.0000 - mae: 180175.5000 - val_loss: 33861308416.0000 - val_mae: 177285.4375\n",
      "Epoch 340/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 33409550336.0000 - mae: 179958.6094 - val_loss: 33625395200.0000 - val_mae: 176627.9844\n",
      "Epoch 341/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 33285218304.0000 - mae: 179668.6094 - val_loss: 33519073280.0000 - val_mae: 176371.9375\n",
      "Epoch 342/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 33155436544.0000 - mae: 179337.2969 - val_loss: 33177014272.0000 - val_mae: 175406.8125\n",
      "Epoch 343/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 33055971328.0000 - mae: 179098.7031 - val_loss: 33630222336.0000 - val_mae: 176663.6250\n",
      "Epoch 344/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 32925734912.0000 - mae: 178795.5625 - val_loss: 32905865216.0000 - val_mae: 174610.3125\n",
      "Epoch 345/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 32823771136.0000 - mae: 178518.7812 - val_loss: 32930443264.0000 - val_mae: 174669.0156\n",
      "Epoch 346/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 32733437952.0000 - mae: 178294.4531 - val_loss: 33096294400.0000 - val_mae: 175167.6406\n",
      "Epoch 347/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 32607393792.0000 - mae: 177986.2812 - val_loss: 33389772800.0000 - val_mae: 175955.2969\n",
      "Epoch 348/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 32484270080.0000 - mae: 177672.9531 - val_loss: 32994471936.0000 - val_mae: 174914.6875\n",
      "Epoch 349/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 32412028928.0000 - mae: 177477.5781 - val_loss: 32692158464.0000 - val_mae: 174038.2656\n",
      "Epoch 350/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 32292214784.0000 - mae: 177178.6250 - val_loss: 32234151936.0000 - val_mae: 172743.7500\n",
      "Epoch 351/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 32169521152.0000 - mae: 176871.8750 - val_loss: 32222486528.0000 - val_mae: 172713.2969\n",
      "Epoch 352/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 32049086464.0000 - mae: 176590.7656 - val_loss: 32080934912.0000 - val_mae: 172303.4219\n",
      "Epoch 353/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 31953352704.0000 - mae: 176318.7812 - val_loss: 32221376512.0000 - val_mae: 172717.5469\n",
      "Epoch 354/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 31842625536.0000 - mae: 176032.7031 - val_loss: 32139945984.0000 - val_mae: 172497.8281\n",
      "Epoch 355/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 31725010944.0000 - mae: 175747.2969 - val_loss: 31839182848.0000 - val_mae: 171647.8125\n",
      "Epoch 356/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 31614988288.0000 - mae: 175458.7188 - val_loss: 32207443968.0000 - val_mae: 172714.7969\n",
      "Epoch 357/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 31506743296.0000 - mae: 175194.7188 - val_loss: 31646599168.0000 - val_mae: 171063.1562\n",
      "Epoch 358/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 31368058880.0000 - mae: 174859.7344 - val_loss: 31552647168.0000 - val_mae: 170806.2656\n",
      "Epoch 359/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 31294382080.0000 - mae: 174641.6562 - val_loss: 31602376704.0000 - val_mae: 170955.5312\n",
      "Epoch 360/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 31168446464.0000 - mae: 174290.9844 - val_loss: 31409977344.0000 - val_mae: 170342.0938\n",
      "Epoch 361/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 31079825408.0000 - mae: 174074.6250 - val_loss: 31508924416.0000 - val_mae: 170685.6094\n",
      "Epoch 362/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 30951006208.0000 - mae: 173751.8281 - val_loss: 31600775168.0000 - val_mae: 170965.4375\n",
      "Epoch 363/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 30837331968.0000 - mae: 173433.8438 - val_loss: 31299174400.0000 - val_mae: 170081.7188\n",
      "Epoch 364/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 30748776448.0000 - mae: 173200.9844 - val_loss: 31137181696.0000 - val_mae: 169611.7812\n",
      "Epoch 365/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 30645161984.0000 - mae: 172954.8594 - val_loss: 31155802112.0000 - val_mae: 169667.4062\n",
      "Epoch 366/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 30526361600.0000 - mae: 172652.0312 - val_loss: 30953484288.0000 - val_mae: 169023.6406\n",
      "Epoch 367/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 30392356864.0000 - mae: 172294.3594 - val_loss: 30858852352.0000 - val_mae: 168758.5000\n",
      "Epoch 368/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 30297329664.0000 - mae: 172058.8125 - val_loss: 30721269760.0000 - val_mae: 168307.8750\n",
      "Epoch 369/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 30185066496.0000 - mae: 171751.2188 - val_loss: 31063076864.0000 - val_mae: 169397.1094\n",
      "Epoch 370/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 30100224000.0000 - mae: 171500.4062 - val_loss: 30351212544.0000 - val_mae: 167264.1875\n",
      "Epoch 371/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 29962889216.0000 - mae: 171188.3594 - val_loss: 30914441216.0000 - val_mae: 168914.6562\n",
      "Epoch 372/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 29851686912.0000 - mae: 170851.8438 - val_loss: 30451484672.0000 - val_mae: 167513.3125\n",
      "Epoch 373/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 29756383232.0000 - mae: 170597.5000 - val_loss: 30484295680.0000 - val_mae: 167595.8281\n",
      "Epoch 374/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 29625917440.0000 - mae: 170276.5938 - val_loss: 29788465152.0000 - val_mae: 165585.8594\n",
      "Epoch 375/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 29537667072.0000 - mae: 170025.3750 - val_loss: 30406060032.0000 - val_mae: 167349.7656\n",
      "Epoch 376/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 29411809280.0000 - mae: 169654.1250 - val_loss: 30053715968.0000 - val_mae: 166293.7500\n",
      "Epoch 377/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 29340362752.0000 - mae: 169465.5312 - val_loss: 29733658624.0000 - val_mae: 165315.3906\n",
      "Epoch 378/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 29207406592.0000 - mae: 169108.5000 - val_loss: 29892775936.0000 - val_mae: 165747.1562\n",
      "Epoch 379/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 29098606592.0000 - mae: 168800.0625 - val_loss: 29949243392.0000 - val_mae: 165956.0938\n",
      "Epoch 380/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 28997468160.0000 - mae: 168551.5938 - val_loss: 29541713920.0000 - val_mae: 164740.2031\n",
      "Epoch 381/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 28889870336.0000 - mae: 168242.2500 - val_loss: 29364535296.0000 - val_mae: 164147.4844\n",
      "Epoch 382/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 28762476544.0000 - mae: 167927.7656 - val_loss: 29408047104.0000 - val_mae: 164311.8750\n",
      "Epoch 383/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 28649123840.0000 - mae: 167579.4688 - val_loss: 29606209536.0000 - val_mae: 164940.1562\n",
      "Epoch 384/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 28566274048.0000 - mae: 167370.7812 - val_loss: 29611288576.0000 - val_mae: 164918.4531\n",
      "Epoch 385/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 28440686592.0000 - mae: 167029.6406 - val_loss: 29282252800.0000 - val_mae: 163972.8906\n",
      "Epoch 386/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 28359581696.0000 - mae: 166777.9375 - val_loss: 28740945920.0000 - val_mae: 162271.7812\n",
      "Epoch 387/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 28241100800.0000 - mae: 166453.9531 - val_loss: 29052526592.0000 - val_mae: 163205.3594\n",
      "Epoch 388/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 28123559936.0000 - mae: 166118.3281 - val_loss: 28965844992.0000 - val_mae: 162868.9844\n",
      "Epoch 389/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 28011456512.0000 - mae: 165812.0469 - val_loss: 29030758400.0000 - val_mae: 163079.0469\n",
      "Epoch 390/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 27935385600.0000 - mae: 165623.0000 - val_loss: 28300615680.0000 - val_mae: 160809.8594\n",
      "Epoch 391/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 27802343424.0000 - mae: 165241.7188 - val_loss: 28242501632.0000 - val_mae: 160633.6406\n",
      "Epoch 392/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 27697055744.0000 - mae: 164943.2812 - val_loss: 28231942144.0000 - val_mae: 160551.7969\n",
      "Epoch 393/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 27595896832.0000 - mae: 164611.6562 - val_loss: 28150188032.0000 - val_mae: 160311.8281\n",
      "Epoch 394/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 27511554048.0000 - mae: 164350.5000 - val_loss: 28788736000.0000 - val_mae: 162361.2812\n",
      "Epoch 395/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 27398041600.0000 - mae: 164063.1719 - val_loss: 28172797952.0000 - val_mae: 160349.1406\n",
      "Epoch 396/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 27295430656.0000 - mae: 163764.4844 - val_loss: 28285337600.0000 - val_mae: 160767.4375\n",
      "Epoch 397/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 27171155968.0000 - mae: 163401.3438 - val_loss: 27921108992.0000 - val_mae: 159602.1094\n",
      "Epoch 398/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 27089612800.0000 - mae: 163155.1719 - val_loss: 28304300032.0000 - val_mae: 160793.1875\n",
      "Epoch 399/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 26975840256.0000 - mae: 162836.7344 - val_loss: 27687245824.0000 - val_mae: 158869.2656\n",
      "Epoch 400/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 26845640704.0000 - mae: 162453.0469 - val_loss: 28126701568.0000 - val_mae: 160188.9531\n",
      "Epoch 401/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 26729625600.0000 - mae: 162142.3594 - val_loss: 27616632832.0000 - val_mae: 158618.2656\n",
      "Epoch 402/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 26652489728.0000 - mae: 161901.9375 - val_loss: 27080910848.0000 - val_mae: 156869.2344\n",
      "Epoch 403/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 26552811520.0000 - mae: 161596.1250 - val_loss: 27551242240.0000 - val_mae: 158278.4219\n",
      "Epoch 404/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 26442606592.0000 - mae: 161297.6094 - val_loss: 27536809984.0000 - val_mae: 158308.2500\n",
      "Epoch 405/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 26344837120.0000 - mae: 160954.7500 - val_loss: 27618576384.0000 - val_mae: 158541.8281\n",
      "Epoch 406/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 26232137728.0000 - mae: 160660.9062 - val_loss: 27131955200.0000 - val_mae: 156937.6719\n",
      "Epoch 407/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 26114254848.0000 - mae: 160320.8906 - val_loss: 27622180864.0000 - val_mae: 158484.6406\n",
      "Epoch 408/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 26038831104.0000 - mae: 160079.2500 - val_loss: 26737702912.0000 - val_mae: 155624.2812\n",
      "Epoch 409/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 25914415104.0000 - mae: 159715.8750 - val_loss: 27213688832.0000 - val_mae: 157220.0000\n",
      "Epoch 410/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 25821143040.0000 - mae: 159421.7812 - val_loss: 27300509696.0000 - val_mae: 157380.5156\n",
      "Epoch 411/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 25740032000.0000 - mae: 159174.1875 - val_loss: 27148072960.0000 - val_mae: 156907.7969\n",
      "Epoch 412/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 25599391744.0000 - mae: 158774.0781 - val_loss: 26959101952.0000 - val_mae: 156250.3438\n",
      "Epoch 413/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 25516609536.0000 - mae: 158522.4219 - val_loss: 26437812224.0000 - val_mae: 154650.9062\n",
      "Epoch 414/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 25382989824.0000 - mae: 158135.2969 - val_loss: 26595082240.0000 - val_mae: 155136.1719\n",
      "Epoch 415/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 25284395008.0000 - mae: 157819.8438 - val_loss: 26335571968.0000 - val_mae: 154347.0000\n",
      "Epoch 416/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 25187555328.0000 - mae: 157506.6094 - val_loss: 26644867072.0000 - val_mae: 155120.3281\n",
      "Epoch 417/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 25111306240.0000 - mae: 157268.3594 - val_loss: 26573002752.0000 - val_mae: 155005.8125\n",
      "Epoch 418/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 24947148800.0000 - mae: 156829.0781 - val_loss: 26232434688.0000 - val_mae: 153980.1250\n",
      "Epoch 419/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 24891949056.0000 - mae: 156609.7188 - val_loss: 25605453824.0000 - val_mae: 151899.6094\n",
      "Epoch 420/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 24774572032.0000 - mae: 156259.2656 - val_loss: 26072059904.0000 - val_mae: 153355.4062\n",
      "Epoch 421/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 24658872320.0000 - mae: 155910.5625 - val_loss: 25717258240.0000 - val_mae: 152190.0781\n",
      "Epoch 422/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 24553361408.0000 - mae: 155576.4844 - val_loss: 25679298560.0000 - val_mae: 151923.2656\n",
      "Epoch 423/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 24488142848.0000 - mae: 155316.9531 - val_loss: 25222641664.0000 - val_mae: 150514.5625\n",
      "Epoch 424/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 24363147264.0000 - mae: 154973.9844 - val_loss: 25922252800.0000 - val_mae: 152821.5000\n",
      "Epoch 425/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 24287920128.0000 - mae: 154698.6562 - val_loss: 25965527040.0000 - val_mae: 152866.1562\n",
      "Epoch 426/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 24168960000.0000 - mae: 154390.0625 - val_loss: 25393190912.0000 - val_mae: 150927.7344\n",
      "Epoch 427/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 24063375360.0000 - mae: 154007.7656 - val_loss: 25132742656.0000 - val_mae: 150078.8750\n",
      "Epoch 428/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 23966283776.0000 - mae: 153739.1250 - val_loss: 25396312064.0000 - val_mae: 150967.4219\n",
      "Epoch 429/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 23874592768.0000 - mae: 153442.0469 - val_loss: 25772736512.0000 - val_mae: 152242.6562\n",
      "Epoch 430/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 23742818304.0000 - mae: 153055.2500 - val_loss: 25261279232.0000 - val_mae: 150458.1250\n",
      "Epoch 431/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 23648335872.0000 - mae: 152694.4531 - val_loss: 24397316096.0000 - val_mae: 147498.0469\n",
      "Epoch 432/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 23545956352.0000 - mae: 152418.9062 - val_loss: 24793165824.0000 - val_mae: 148859.5625\n",
      "Epoch 433/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 23463043072.0000 - mae: 152142.3594 - val_loss: 24731656192.0000 - val_mae: 148641.8594\n",
      "Epoch 434/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 23328784384.0000 - mae: 151705.5625 - val_loss: 24642275328.0000 - val_mae: 148399.8125\n",
      "Epoch 435/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 23287293952.0000 - mae: 151513.5469 - val_loss: 24729821184.0000 - val_mae: 148517.6875\n",
      "Epoch 436/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 23177066496.0000 - mae: 151153.6875 - val_loss: 24280426496.0000 - val_mae: 147055.1719\n",
      "Epoch 437/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 23039457280.0000 - mae: 150715.2031 - val_loss: 24477026304.0000 - val_mae: 147729.2969\n",
      "Epoch 438/500\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 22935320576.0000 - mae: 150423.7031 - val_loss: 24470339584.0000 - val_mae: 147595.9844\n",
      "Epoch 439/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 22851465216.0000 - mae: 150121.9688 - val_loss: 24330188800.0000 - val_mae: 147138.0156\n",
      "Epoch 440/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 22795767808.0000 - mae: 149924.3594 - val_loss: 23763288064.0000 - val_mae: 145101.5469\n",
      "Epoch 441/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 22672152576.0000 - mae: 149535.4688 - val_loss: 23887933440.0000 - val_mae: 145682.8594\n",
      "Epoch 442/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 22566060032.0000 - mae: 149184.2188 - val_loss: 24136609792.0000 - val_mae: 146534.2031\n",
      "Epoch 443/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 22439010304.0000 - mae: 148800.7500 - val_loss: 24002412544.0000 - val_mae: 145951.1094\n",
      "Epoch 444/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 22367096832.0000 - mae: 148495.9219 - val_loss: 23902724096.0000 - val_mae: 145573.2812\n",
      "Epoch 445/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 22265720832.0000 - mae: 148142.4062 - val_loss: 23753187328.0000 - val_mae: 145218.1562\n",
      "Epoch 446/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 22160463872.0000 - mae: 147852.8750 - val_loss: 24045477888.0000 - val_mae: 146128.4062\n",
      "Epoch 447/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 22041231360.0000 - mae: 147442.7188 - val_loss: 23784321024.0000 - val_mae: 145286.4688\n",
      "Epoch 448/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21963732992.0000 - mae: 147155.1719 - val_loss: 23512276992.0000 - val_mae: 144355.2500\n",
      "Epoch 449/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21885972480.0000 - mae: 146817.4844 - val_loss: 23662905344.0000 - val_mae: 144598.6250\n",
      "Epoch 450/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21770858496.0000 - mae: 146461.1875 - val_loss: 23151892480.0000 - val_mae: 142756.2969\n",
      "Epoch 451/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21687304192.0000 - mae: 146179.9531 - val_loss: 23655389184.0000 - val_mae: 144589.0781\n",
      "Epoch 452/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21573244928.0000 - mae: 145879.2656 - val_loss: 23528949760.0000 - val_mae: 144193.2188\n",
      "Epoch 453/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21461188608.0000 - mae: 145449.5469 - val_loss: 23473723392.0000 - val_mae: 144092.8906\n",
      "Epoch 454/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21368184832.0000 - mae: 145193.7969 - val_loss: 22962956288.0000 - val_mae: 142276.0781\n",
      "Epoch 455/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 21260503040.0000 - mae: 144798.5938 - val_loss: 22830358528.0000 - val_mae: 141877.5312\n",
      "Epoch 456/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21189410816.0000 - mae: 144471.7656 - val_loss: 22797719552.0000 - val_mae: 141585.3906\n",
      "Epoch 457/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 21081448448.0000 - mae: 144152.0312 - val_loss: 22311346176.0000 - val_mae: 139770.6094\n",
      "Epoch 458/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 21000681472.0000 - mae: 143911.8125 - val_loss: 22707912704.0000 - val_mae: 141193.7969\n",
      "Epoch 459/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20877359104.0000 - mae: 143463.6719 - val_loss: 22130640896.0000 - val_mae: 139023.6250\n",
      "Epoch 460/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20776144896.0000 - mae: 143102.9062 - val_loss: 22320277504.0000 - val_mae: 139866.9375\n",
      "Epoch 461/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20683464704.0000 - mae: 142758.2344 - val_loss: 22338643968.0000 - val_mae: 139876.8906\n",
      "Epoch 462/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20585912320.0000 - mae: 142426.6719 - val_loss: 22432591872.0000 - val_mae: 139956.6094\n",
      "Epoch 463/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20489877504.0000 - mae: 142112.9844 - val_loss: 22561642496.0000 - val_mae: 140801.2656\n",
      "Epoch 464/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20416131072.0000 - mae: 141804.5625 - val_loss: 21843548160.0000 - val_mae: 138215.8125\n",
      "Epoch 465/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 20306735104.0000 - mae: 141425.0938 - val_loss: 21764812800.0000 - val_mae: 137908.4531\n",
      "Epoch 466/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20199282688.0000 - mae: 141098.3594 - val_loss: 21943666688.0000 - val_mae: 138257.1406\n",
      "Epoch 467/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 20112650240.0000 - mae: 140757.5312 - val_loss: 22020106240.0000 - val_mae: 138684.4688\n",
      "Epoch 468/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19984179200.0000 - mae: 140330.0469 - val_loss: 21511290880.0000 - val_mae: 136691.6719\n",
      "Epoch 469/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19908956160.0000 - mae: 140037.9688 - val_loss: 21363281920.0000 - val_mae: 136111.0938\n",
      "Epoch 470/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 19817510912.0000 - mae: 139725.4062 - val_loss: 21266946048.0000 - val_mae: 135784.3125\n",
      "Epoch 471/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19729274880.0000 - mae: 139373.4688 - val_loss: 21161322496.0000 - val_mae: 135623.3750\n",
      "Epoch 472/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19627034624.0000 - mae: 139021.8906 - val_loss: 21101338624.0000 - val_mae: 135283.4531\n",
      "Epoch 473/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19538419712.0000 - mae: 138656.4531 - val_loss: 21511419904.0000 - val_mae: 136741.9219\n",
      "Epoch 474/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 19466772480.0000 - mae: 138401.3438 - val_loss: 21339555840.0000 - val_mae: 136274.9531\n",
      "Epoch 475/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19351388160.0000 - mae: 138079.6562 - val_loss: 21074526208.0000 - val_mae: 134974.9531\n",
      "Epoch 476/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19253176320.0000 - mae: 137697.3438 - val_loss: 20631216128.0000 - val_mae: 133587.1719\n",
      "Epoch 477/500\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 19145459712.0000 - mae: 137265.6406 - val_loss: 20933771264.0000 - val_mae: 134717.6094\n",
      "Epoch 478/500\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 19070814208.0000 - mae: 137010.7969 - val_loss: 20542488576.0000 - val_mae: 133374.4688\n",
      "Epoch 479/500\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 18959915008.0000 - mae: 136634.7500 - val_loss: 20566398976.0000 - val_mae: 133187.9375\n",
      "Epoch 480/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 18852294656.0000 - mae: 136206.1094 - val_loss: 20477343744.0000 - val_mae: 132991.0156\n",
      "Epoch 481/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 18791397376.0000 - mae: 135949.4062 - val_loss: 20232609792.0000 - val_mae: 132067.7969\n",
      "Epoch 482/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 18652610560.0000 - mae: 135517.2031 - val_loss: 20623071232.0000 - val_mae: 133672.7656\n",
      "Epoch 483/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 18557122560.0000 - mae: 135119.3750 - val_loss: 20359016448.0000 - val_mae: 132483.0781\n",
      "Epoch 484/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 18481053696.0000 - mae: 134824.8438 - val_loss: 20300052480.0000 - val_mae: 132307.6875\n",
      "Epoch 485/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 18394034176.0000 - mae: 134491.6094 - val_loss: 20411686912.0000 - val_mae: 132820.8125\n",
      "Epoch 486/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 18289784832.0000 - mae: 134146.4062 - val_loss: 20281155584.0000 - val_mae: 132341.1875\n",
      "Epoch 487/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 18184802304.0000 - mae: 133751.0625 - val_loss: 20633864192.0000 - val_mae: 133818.1094\n",
      "Epoch 488/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 18084618240.0000 - mae: 133408.3594 - val_loss: 19883257856.0000 - val_mae: 130925.3516\n",
      "Epoch 489/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 18011494400.0000 - mae: 133156.5938 - val_loss: 19915872256.0000 - val_mae: 131019.6484\n",
      "Epoch 490/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 17892696064.0000 - mae: 132671.8125 - val_loss: 19373023232.0000 - val_mae: 128854.9922\n",
      "Epoch 491/500\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 17836736512.0000 - mae: 132390.9531 - val_loss: 19450050560.0000 - val_mae: 129104.3359\n",
      "Epoch 492/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17730310144.0000 - mae: 132033.0625 - val_loss: 19229857792.0000 - val_mae: 128249.5938\n",
      "Epoch 493/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17637058560.0000 - mae: 131680.1719 - val_loss: 19262291968.0000 - val_mae: 128352.0156\n",
      "Epoch 494/500\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 17522755584.0000 - mae: 131208.5312 - val_loss: 18923636736.0000 - val_mae: 127055.8828\n",
      "Epoch 495/500\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 17448685568.0000 - mae: 130928.5469 - val_loss: 19058319360.0000 - val_mae: 127521.8203\n",
      "Epoch 496/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 17340743680.0000 - mae: 130564.0547 - val_loss: 18865870848.0000 - val_mae: 126804.1094\n",
      "Epoch 497/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 17230682112.0000 - mae: 130160.2188 - val_loss: 18701750272.0000 - val_mae: 126272.9219\n",
      "Epoch 498/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 17135612928.0000 - mae: 129805.5078 - val_loss: 18931695616.0000 - val_mae: 127073.0859\n",
      "Epoch 499/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 17084878848.0000 - mae: 129574.4922 - val_loss: 19010222080.0000 - val_mae: 127582.8828\n",
      "Epoch 500/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 16976813056.0000 - mae: 129107.9375 - val_loss: 18446714880.0000 - val_mae: 125078.7344\n",
      "Minimum validation loss: 18446714880.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=[input_shape]),\n",
    "\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(1),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping], # put your callbacks in a list\n",
    "    # verbose=0,  # turn off training log\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step\n",
      "number of good predictions for Sequential = 846314\n",
      "which is 37397.87892178524%\n"
     ]
    }
   ],
   "source": [
    "print_percent_of_good_predictions([model], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step\n",
      "number of good predictions for Sequential = 846314\n",
      "which is 37397.87892178524%\n"
     ]
    }
   ],
   "source": [
    "error = NUM_OF_HOURS * 60 * 60\n",
    "predictions = model.predict(X_test)\n",
    "predictions_time_diff = np.abs(y_test - predictions)\n",
    "num_of_good_predictions = (predictions_time_diff < error).sum()\n",
    "percent_of_good_predictions = num_of_good_predictions / len(predictions_time_diff)\n",
    "print(f'number of good predictions for {type(model).__name__} = {num_of_good_predictions}')\n",
    "print(f'which is {percent_of_good_predictions * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70085.0625    ,  15140.0625    ,  40110.0625    , ...,\n",
       "         19853.0625    ,  19819.0625    , 121169.0625    ],\n",
       "       [170641.58203125, 115696.58203125, 140666.58203125, ...,\n",
       "        120409.58203125, 120375.58203125, 221725.58203125],\n",
       "       [108229.078125  ,  53284.078125  ,  78254.078125  , ...,\n",
       "         57997.078125  ,  57963.078125  , 159313.078125  ],\n",
       "       ...,\n",
       "       [200521.41796875, 145576.41796875, 170546.41796875, ...,\n",
       "        150289.41796875, 150255.41796875, 251605.41796875],\n",
       "       [ 61557.921875  ,   6612.921875  ,  31582.921875  , ...,\n",
       "         11325.921875  ,  11291.921875  , 112641.921875  ],\n",
       "       [ 95861.5       ,  40916.5       ,  65886.5       , ...,\n",
       "         45629.5       ,  45595.5       , 146945.5       ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions_time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2263, 2263)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions_time_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>purchase_datetime_delta</th>\n",
       "      <th>516</th>\n",
       "      <th>620</th>\n",
       "      <th>Kraków</th>\n",
       "      <th>Poznań</th>\n",
       "      <th>Radom</th>\n",
       "      <th>Szczecin</th>\n",
       "      <th>Warszawa</th>\n",
       "      <th>...</th>\n",
       "      <th>1627</th>\n",
       "      <th>1628</th>\n",
       "      <th>1629</th>\n",
       "      <th>1630</th>\n",
       "      <th>1631</th>\n",
       "      <th>1632</th>\n",
       "      <th>1633</th>\n",
       "      <th>1634</th>\n",
       "      <th>1635</th>\n",
       "      <th>1653</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10825</th>\n",
       "      <td>0.013589</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.660933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>0.027859</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.558801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>0.119751</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>0.913933</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>0.124076</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.659243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>0.134886</td>\n",
       "      <td>0.023667</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>0.032173</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.177023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.563015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8928</th>\n",
       "      <td>0.836941</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.762100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>0.092714</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.213929</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>0.719751</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.903028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2263 rows × 594 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  weight_kg  purchase_datetime_delta  516  620  Kraków  Poznań  \\\n",
       "10825  0.013589   0.000467                 0.660933    0    0       0       0   \n",
       "3593   0.027859   0.001333                 0.558801    0    0       0       0   \n",
       "5653   0.119751   0.013733                 0.913933    1    0       0       0   \n",
       "4854   0.124076   0.226667                 0.659243    0    0       0       1   \n",
       "3864   0.134886   0.023667                 0.498738    0    1       0       0   \n",
       "...         ...        ...                      ...  ...  ...     ...     ...   \n",
       "6667   0.032173   0.008667                 0.177023    1    0       0       0   \n",
       "721    0.632184   0.680000                 0.563015    0    0       1       0   \n",
       "8928   0.836941   0.001733                 0.762100    0    0       0       1   \n",
       "8521   0.092714   0.166667                 0.213929    1    0       0       0   \n",
       "5647   0.719751   0.166667                 0.903028    0    1       0       0   \n",
       "\n",
       "       Radom  Szczecin  Warszawa  ...  1627  1628  1629  1630  1631  1632  \\\n",
       "10825      1         0         0  ...     0     0     0     0     0     0   \n",
       "3593       0         0         0  ...     0     0     0     0     0     0   \n",
       "5653       0         0         0  ...     0     0     0     0     0     0   \n",
       "4854       0         0         0  ...     0     0     0     0     0     0   \n",
       "3864       1         0         0  ...     0     0     0     0     0     0   \n",
       "...      ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "6667       0         1         0  ...     0     0     0     0     0     0   \n",
       "721        0         0         0  ...     0     0     0     0     0     0   \n",
       "8928       0         0         0  ...     0     0     0     0     0     0   \n",
       "8521       0         0         0  ...     0     0     0     0     0     0   \n",
       "5647       0         0         0  ...     0     0     0     0     0     0   \n",
       "\n",
       "       1633  1634  1635  1653  \n",
       "10825     0     0     0     0  \n",
       "3593      0     0     0     0  \n",
       "5653      0     0     0     0  \n",
       "4854      0     0     0     0  \n",
       "3864      0     0     0     0  \n",
       "...     ...   ...   ...   ...  \n",
       "6667      0     0     0     0  \n",
       "721       0     0     0     0  \n",
       "8928      0     0     0     0  \n",
       "8521      0     0     0     0  \n",
       "5647      0     0     0     0  \n",
       "\n",
       "[2263 rows x 594 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>Sequential prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225013.0</td>\n",
       "      <td>154927.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170068.0</td>\n",
       "      <td>54371.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195038.0</td>\n",
       "      <td>116783.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279415.0</td>\n",
       "      <td>67744.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331221.0</td>\n",
       "      <td>193452.281250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  Sequential prediction\n",
       "0  225013.0          154927.937500\n",
       "1  170068.0           54371.417969\n",
       "2  195038.0          116783.921875\n",
       "3  279415.0           67744.406250\n",
       "4  331221.0          193452.281250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2263 entries, 0 to 2262\n",
      "Data columns (total 2 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   y_test                 2263 non-null   float64\n",
      " 1   Sequential prediction  2263 non-null   float32\n",
      "dtypes: float32(1), float64(1)\n",
      "memory usage: 26.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>Sequential prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2263.000000</td>\n",
       "      <td>2263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>231077.817941</td>\n",
       "      <td>106598.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79705.119199</td>\n",
       "      <td>87085.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>33091.000000</td>\n",
       "      <td>-91713.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174344.000000</td>\n",
       "      <td>35943.382812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>222482.000000</td>\n",
       "      <td>101533.054688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>281067.000000</td>\n",
       "      <td>163545.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>535390.000000</td>\n",
       "      <td>419300.093750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y_test  Sequential prediction\n",
       "count    2263.000000            2263.000000\n",
       "mean   231077.817941          106598.437500\n",
       "std     79705.119199           87085.703125\n",
       "min     33091.000000          -91713.875000\n",
       "25%    174344.000000           35943.382812\n",
       "50%    222482.000000          101533.054688\n",
       "75%    281067.000000          163545.570312\n",
       "max    535390.000000          419300.093750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_df = create_df_with_predictions([model], X_test, y_test)\n",
    "display_predictions(y_pred_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
